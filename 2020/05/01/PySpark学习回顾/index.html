<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/faviconY.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="1. 前言 三人行必有我师焉 – 中国古代谚语  本文是在GitHub上无意间找到的有关PySpark的宝贵学习资料，很全面。希望借此对之前的学习有更加深入的理解！ 2. 为什么是 Spark 和 Python 磨刀不误砍柴工。 – 中国古代谚语  我想从以下两个部分回答这个问题： 2.1. 为什么是 Spark我认为 Apache Spark™ 官网的以下四个主要原因足以说服您使用 Spark。">
<meta name="keywords" content="PySpark">
<meta property="og:type" content="article">
<meta property="og:title" content="PySpark学习回顾">
<meta property="og:url" content="http://yoursite.com/2020/05/01/PySpark学习回顾/index.html">
<meta property="og:site_name" content="颜">
<meta property="og:description" content="1. 前言 三人行必有我师焉 – 中国古代谚语  本文是在GitHub上无意间找到的有关PySpark的宝贵学习资料，很全面。希望借此对之前的学习有更加深入的理解！ 2. 为什么是 Spark 和 Python 磨刀不误砍柴工。 – 中国古代谚语  我想从以下两个部分回答这个问题： 2.1. 为什么是 Spark我认为 Apache Spark™ 官网的以下四个主要原因足以说服您使用 Spark。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/72748fa31cb48a5062a2fc7949bd0b45.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/d3b112475692c0421480c01cd029cf09.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b9eb842264e6a48a42ecf5f142e32414.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/348c0d7bc8db0d630042e5faffd2d647.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/7166a4887b7f211527c9e45a072e23d2.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c9c3087ea25e6c3f848030b33b06de8f.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/fdfe96b0b4fdfbfd862a698dc64ce34a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7721ad6f461509452813013157c7a5e.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b8c9ccb17235ad37b2b0fee18853efe6.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/edb67528127916e7e274addf9ad96029.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/8973b73843e90120de5f556d5084eb49.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/90a1240e7489f989b9a4e5739b1efbd5.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/067197a5eeb69cc2f3d828a92ebcf52e.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c51fb942d508d4161e72d0075a5284e7.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/f18ecec7a6c176301d7370e41a0a60dd.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/197517339d2ce744dd0a46c607e84534.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/6f2adb68d3f0a7f1f3af2ef044441071.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/f4e95f92187a42f257864cd22193c8ad.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/0ff87df50cf4610da54dd94b51c6d809.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/0ebcb4677d2131e71e039be8ea955cff.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/ec9e0b7231caed693477682311612304.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1478d9b0743fdc3b0c6ad079b88034ec.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/69ff1f1b7a8e2162d5395fa62c35e8b6.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c03bdd903e4bd06d018711d1dece0c35.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/e1164e5922bbcc2db8e6b23c145b8f75.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/8f58cf98a539286a53e41582f194fbed.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/585d98b9749f0661bc9077e01f28eb15.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/791424a3e5f6e2f4372471d96e5b4676.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/afa87c5126806e604709f243ab72848b.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/afa87c5126806e604709f243ab72848b.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/bab25b7785bf747bc1caa1442874df74.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c089ca6ef2f36b0394d7bcf41db78030.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/61bccf1d55cc6636fce9585573c9981a.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/3152173a8fd696819c7a2c2b8c6ef005.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/c8a2ccec457f128649ad30a2ba066a48.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/16fd7a4c078cf22fee09b636dc10d55c.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/8dc8e70e19ec4318b12b16f1c5bdb879.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/95594348fc6d49d2819be3d412a27e55.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/fef76f108c095f250d8e9efb4cfcb710.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b288f19072faa2f8f373d5a8910c080b.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4a1a112aa8490f7c8410b710845e8c7a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c789e9bbaa3506dc90047b5cd487a42a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/3f26c9365c0603f014f3bba403ed27fb.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1a8a8647a66b744ccd5c9137adb66255.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/5a13655c0030372e1b06cd77ff1e53e0.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1cef776388e6c2cba3cf00cab2199e3d.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/6eb508bad184c89094f5045a5bf2e31c.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4fb175e4e5682ef75a156dfba37beeea.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/0539212d2d3e4c28b27805e3c8783cab.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/2a4a130bcfb223ced98c0de613bd076a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/cb63c877ea3af266bb0f5ad6ba5e0b1d.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/0eb5759f21246505752043bb890ab6bf.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/38cff4d0c27588f71d4ed00223dcc4a2.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/7f8b8ddc9f821d1c5a27849bc02e355f.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/aa2fbf6676b8fd4f67229d35f1c7c537.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1428271961e4c95f6508f59083d5a645.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/aa2fbf6676b8fd4f67229d35f1c7c537.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4b454255e179a3626e205ce324184acf.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/91d663abfef497e13ec41f9300a5c354.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/59ebd939c24bf4d59d82b0daf4874daf.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/80a25ad6329d3836f4e625a1c93e7898.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/c4660874124a448ac14209f4a59e367a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/82a22af158d760e46ae93ba1663a6487.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/fad9e18cebad821450ed0f34abdb3988.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/2d776487e1a2ee4683c3c6f51fca7e48.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/3b99ee07cd783026d41b65651ee5d293.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b8bf446d4a625497f28f2347b7ca0c92.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/d2f9799d371fde446e6dc8292ba07393.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/d09c46ec94d638e4ddcecfbba1c11ea8.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/d003fed20e7f2d040ccc24412cb854d1.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/501025688da0cf9e2b3937cd7da9580d.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/d142da9aae51c6d3c3c736fc82252862.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/16dd8d60ea9b042c3ce0652c9f0571e8.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/a5fda7453d5707d5e8985434c789ba48.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/77c47cf9cfec8ec740c5a18dc4386670.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/875e532ac3b299876d209507d595df14.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/d4b34834b440d5d60f25912180e7e130.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/aef64ee73dc1b1a03a152855f685113e.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/ad37847dfd8d9f3d99f646966f32cf30.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/7bb886fc0ea7d5d1144002edd99e0c7f.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/86176a13e0a00622dbc982348d7ca623.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/189ce8661099fd6f1118f978d53cf85b.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/1c57212c22a6a7777decfa1971418148.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/94b77459ef6ab620703ddb014430c700.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/94b77459ef6ab620703ddb014430c700.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/3c62f7e72a479ae0b82768c51bdc2830.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/3c62f7e72a479ae0b82768c51bdc2830.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/aed7e56b0a3e63a84e53c79df4f79b0e.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg">
<meta property="og:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/0e33aec96020afa0297be6d91db0d5d8.jpg">
<meta property="og:image" content="http://yoursite.com/2020/05/01/PySpark学习回顾/img/9b41f0fbb97ef7ddd6383753e6ad1c26.jpg">
<meta property="og:updated_time" content="2020-05-28T10:58:22.592Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PySpark学习回顾">
<meta name="twitter:description" content="1. 前言 三人行必有我师焉 – 中国古代谚语  本文是在GitHub上无意间找到的有关PySpark的宝贵学习资料，很全面。希望借此对之前的学习有更加深入的理解！ 2. 为什么是 Spark 和 Python 磨刀不误砍柴工。 – 中国古代谚语  我想从以下两个部分回答这个问题： 2.1. 为什么是 Spark我认为 Apache Spark™ 官网的以下四个主要原因足以说服您使用 Spark。">
<meta name="twitter:image" content="g:/PYthonLearning/learning-pyspark-zh-master/docs/img/72748fa31cb48a5062a2fc7949bd0b45.jpg">





  
  
  <link rel="canonical" href="http://yoursite.com/2020/05/01/PySpark学习回顾/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>PySpark学习回顾 | 颜</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">颜</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">控制、PMSM、Python、...</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/01/PySpark学习回顾/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shiwei-Yan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="颜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">PySpark学习回顾

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-05-01 00:00:00" itemprop="dateCreated datePublished" datetime="2020-05-01T00:00:00+08:00">2020-05-01</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-05-28 18:58:22" itemprop="dateModified" datetime="2020-05-28T18:58:22+08:00">2020-05-28</time>
              </span>
            
          

          

          
            
            
          

          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
                 阅读次数： 
                <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
              </span>
            </span>
          

          

          <br>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span title="本文字数">183k</span>
            </span>
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span title="阅读时长">2:47</span>
            </span>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><blockquote>
<p><strong>三人行必有我师焉</strong> – 中国古代谚语</p>
</blockquote>
<p>本文是在GitHub上无意间找到的有关PySpark的宝贵学习资料，很全面。希望借此对之前的学习有更加深入的理解！</p>
<h1 id="2-为什么是-Spark-和-Python"><a href="#2-为什么是-Spark-和-Python" class="headerlink" title="2. 为什么是 Spark 和 Python"></a>2. 为什么是 Spark 和 Python</h1><blockquote>
<p><strong>磨刀不误砍柴工。</strong> – 中国古代谚语</p>
</blockquote>
<p>我想从以下两个部分回答这个问题：</p>
<h2 id="2-1-为什么是-Spark"><a href="#2-1-为什么是-Spark" class="headerlink" title="2.1. 为什么是 Spark"></a>2.1. 为什么是 Spark</h2><p>我认为 <a href="http://spark.apache.org/" target="_blank" rel="noopener">Apache Spark™</a> 官网的以下四个主要原因足以说服您使用 Spark。</p>
<ol>
<li><p>速度</p>
<p>在内存中运行程序比 Hadoop MapReduce 快 100 倍，或者比磁盘上运行快 10 倍。</p>
<p>Apache Spark 拥有先进的 DAG 执行引擎，支持非循环数据流和内存计算。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/72748fa31cb48a5062a2fc7949bd0b45.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/logistic-regression.png"></p>
<p>Hadoop 和 Spark 中的逻辑回归</p>
</blockquote>
</li>
<li><p>易于使用</p>
<p>使用 Java，Scala，Python，R 快速编写应用。</p>
<p>Spark 提供 80 多个高级操作符，可以轻松构建并行应用。 您可以从 Scala，Python 和 R shell 中以交互方式使用它。</p>
</li>
<li><p>通用性</p>
<p>结合SQL，流式和复杂的分析。</p>
<p>Spark 支持很多库，包括 SQL 和 DataFrames，用于机器学习的 MLlib，GraphX 和 Spark Streaming。您可以在同一个应用中无缝地组合这些库。</p>
<blockquote>
<p><a href="https://runawayhorse001.github.io/LearningApacheSpark/_images/stack.png" target="_blank" rel="noopener"><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d3b112475692c0421480c01cd029cf09.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/stack.png"></a></p>
<p>Spark 技术栈</p>
</blockquote>
</li>
<li><p>随处运行</p>
<p>Spark 在 Hadoop，Mesos，独立或云端运行。 它可以访问各种数据源，包括 HDFS，Cassandra，HBase 和 S3。</p>
<blockquote>
<p><a href="https://runawayhorse001.github.io/LearningApacheSpark/_images/spark-runs-everywhere.png" target="_blank" rel="noopener"><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b9eb842264e6a48a42ecf5f142e32414.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/spark-runs-everywhere.png"></a></p>
<p>Spark 平台</p>
</blockquote>
</li>
</ol>
<h2 id="2-2-为什么是-PySpark"><a href="#2-2-为什么是-PySpark" class="headerlink" title="2.2. 为什么是 PySpark?"></a>2.2. 为什么是 PySpark?</h2><p>无论你喜欢与否，Python 都是最受欢迎的编程语言之一。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/348c0d7bc8db0d630042e5faffd2d647.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/languages.jpg"></p>
<p>KDnuggets 分析/数据科学 2017 软件调查，来自 <a href="http://www.kdnuggets.com/2017/05/poll-analytics-data-science-machine-learning-software-leaders.html" target="_blank" rel="noopener">kdnuggets</a>。</p>
</blockquote>
<h1 id="3-配置运行平台"><a href="#3-配置运行平台" class="headerlink" title="3. 配置运行平台"></a>3. 配置运行平台</h1><blockquote>
<p><strong>工欲善其事，必先利其器。</strong> – 中国古代谚语</p>
</blockquote>
<p>一个好的编程平台可以为您节省大量的麻烦和时间。 在这里，我将仅介绍如何安装我最喜欢的编程平台，并且只展示我在 Linux 系统上设置它的最简单的方法。 如果要在其他操作系统上安装，可以通过搜索引擎。 在本节中，您可以学习如何在相应的编程平台和包上设置 Pyspark。</p>
<h2 id="3-1-在-Databricks-社区云上运行"><a href="#3-1-在-Databricks-社区云上运行" class="headerlink" title="3.1. 在 Databricks 社区云上运行"></a>3.1. 在 Databricks 社区云上运行</h2><p>如果您对 Linux 或 Unix 操作系统没有任何经验，我很乐意建议您在 Databricks 社区云上使用 Spark。 因为你不需要设置 Spark，它对于社区版来说完全是免费的**。 请按照下面列出的步骤操作。</p>
<ol>
<li><p>在 <a href="https://community.cloud.databricks.com/login.html" target="_blank" rel="noopener">https://community.cloud.databricks.com/login.html</a> 建立账户：</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/7166a4887b7f211527c9e45a072e23d2.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/login.png"></p>
</li>
<li><p>使用您的帐户登录，然后您可以创建集群（计算机），表（数据集）和笔记本（代码）。</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c9c3087ea25e6c3f848030b33b06de8f.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/workspace.png"></p>
</li>
<li><p>创建运行代码的集群</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/fdfe96b0b4fdfbfd862a698dc64ce34a.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/cluster.png"></p>
</li>
<li><p>导入你的数据集</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7721ad6f461509452813013157c7a5e.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/table.png"></p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b8c9ccb17235ad37b2b0fee18853efe6.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/dataset1.png"></p>
<blockquote>
<p>注意</p>
<p>您需要保存<code>Uploaded to DBFS</code>中显示的路径: <code>/FileStore/tables/05rmhuqv1489687378010/</code>，由于我们会使用这个路径来上传数据集。</p>
</blockquote>
</li>
<li><p>创建你的笔记本</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/edb67528127916e7e274addf9ad96029.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/notebook.png"> </p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/8973b73843e90120de5f556d5084eb49.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/codenotebook.png"></p>
</li>
</ol>
<p>完成上述 5 个步骤后，您就可以在 Databricks 社区云上运行 Spark 代码了。 我将在 Databricks 社区云上运行以下所有演示。在运行演示代码时，希望您将获得以下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|_c0|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|  1|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">|  2| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">|  3| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|  4|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|  5|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- _c0: integer (nullable = true)</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<h2 id="3-2-在-Mac-和-Ubuntu-上配置-Spark"><a href="#3-2-在-Mac-和-Ubuntu-上配置-Spark" class="headerlink" title="3.2. 在 Mac 和 Ubuntu 上配置 Spark"></a>3.2. 在 Mac 和 Ubuntu 上配置 Spark</h2><h3 id="3-2-1-安装先决条件"><a href="#3-2-1-安装先决条件" class="headerlink" title="3.2.1. 安装先决条件"></a>3.2.1. 安装先决条件</h3><p>我强烈建议您安装 <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">Anaconda</a>，因为它包含大部分先决条件并支持多个操作系统。</p>
<p><strong>安装 Python</strong></p>
<p>转到 Ubuntu 软件中心并按照以下步骤操作：</p>
<ol>
<li>打开 Ubuntu 软件中心</li>
<li>搜索 python</li>
<li>并点击“安装”</li>
</ol>
<p>或者打开终端执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential checkinstall</span><br><span class="line">sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev</span><br><span class="line">                 libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev</span><br><span class="line">sudo apt-get install python</span><br><span class="line">sudo easy_install pip</span><br><span class="line">sudo pip install ipython</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-安装-Java"><a href="#3-2-2-安装-Java" class="headerlink" title="3.2.2. 安装 Java"></a>3.2.2. 安装 Java</h3><p>Java 被许多其他软件使用。 所以你很可能已经安装了它。 您可以在命令提示符中使用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<p>否则，您可以按照<a href="https://java.com/en/download/help/mac_install.xml" target="_blank" rel="noopener">如何为我的 Mac 安装 Java？</a>中的步骤，在 Mac 上安装 java 并在命令提示符中使用以下命令来在 Ubuntu 上安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-add-repository ppa:webupd8team/java</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install oracle-java8-installer</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-安装-JRE"><a href="#3-2-3-安装-JRE" class="headerlink" title="3.2.3. 安装 JRE"></a>3.2.3. 安装 JRE</h3><p>我安装了 ORACLE <a href="http://www.oracle.com/technetwork/java/javase/downloads/index-jsp-138363.html" target="_blank" rel="noopener">Java JDK</a>。</p>
<blockquote>
<p>警告</p>
<p><strong>安装 Java 和 Java SE 运行时环境的步骤非常重要，因为 Spark 是一种用 Java 编写的领域特定语言。</strong></p>
</blockquote>
<p>您可以在命令提示符中使用以下命令检查 Java 是否可用并找到它的版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<p>如果您的 Java 安装成功，您将获得如下的类似结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version &quot;1.8.0_131&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_131-b11)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4-安装-Apache-Spark"><a href="#3-2-4-安装-Apache-Spark" class="headerlink" title="3.2.4. 安装 Apache Spark"></a>3.2.4. 安装 Apache Spark</h3><p>实际上，预构建版本不需要安装。 你在解包时可以使用它。</p>
<ol>
<li>下载：您可以从 <a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">下载 Apache Spark™</a> 获得预构建的 Apache Spark™。</li>
<li>解压缩：将 Apache Spark™ 解压缩到您要安装 Spark 的路径。</li>
<li>测试：测试先决条件：修改路径<code>spark-#.#.#-bin-hadoop#.#/bin</code>并运行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./pyspark</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Python 2.7.13 |Anaconda 4.4.0 (x86_64)| (default, Dec 20 2016, 23:05:08)</span><br><span class="line">[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">Anaconda is brought to you by Continuum Analytics.</span><br><span class="line">Please check out: http://continuum.io/thanks and https://anaconda.org</span><br><span class="line">Using Spark&apos;s default log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR,</span><br><span class="line">use setLogLevel(newLevel).</span><br><span class="line">17/08/30 13:30:12 WARN NativeCodeLoader: Unable to load native-hadoop</span><br><span class="line">library for your platform... using builtin-java classes where applicable</span><br><span class="line">17/08/30 13:30:17 WARN ObjectStore: Failed to get database global_temp,</span><br><span class="line">returning NoSuchObjectException</span><br><span class="line">Welcome to</span><br><span class="line">       ____              __</span><br><span class="line">      / __/__  ___ _____/ /__</span><br><span class="line">     _\ \/ _ \/ _ `/ __/  &apos;_/</span><br><span class="line">    /__ / .__/\_,_/_/ /_/\_\   version 2.1.1</span><br><span class="line">       /_/</span><br><span class="line"></span><br><span class="line">Using Python version 2.7.13 (default, Dec 20 2016 23:05:08)</span><br><span class="line">SparkSession available as &apos;spark&apos;.</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5-配置-Spark"><a href="#3-2-5-配置-Spark" class="headerlink" title="3.2.5. 配置 Spark"></a>3.2.5. 配置 Spark</h3><ol>
<li><p><strong>Mac 操作系统：</strong>在终端打开你的<code>bash_profile</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure>

<p>并将以下行添加到<code>bash_profile</code>（记得改变路径）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为 spark 添加</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=your_spark_installation_path</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVE_PYTHON=<span class="string">"jupyter"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVE_PYTHON_OPTS=<span class="string">"notebook"</span></span><br></pre></td></tr></table></figure>

<p>最后，记得执行你的<code>bash_profile</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Ubuntu 操作系统：</strong>在终端打开<code>bashrc</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>并将以下行添加到<code>bashrc</code>（记得改变路径）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为 spark 添加</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=your_spark_installation_path</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVE_PYTHON=<span class="string">"jupyter"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVE_PYTHON_OPTS=<span class="string">"notebook"</span></span><br></pre></td></tr></table></figure>

<p>最后，记得执行你的<code>bash_profile</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="3-3-在-Windows-上配置-Spark"><a href="#3-3-在-Windows-上配置-Spark" class="headerlink" title="3.3. 在 Windows 上配置 Spark"></a>3.3. 在 Windows 上配置 Spark</h2><p>在 Windows 上安装开源软件对我来说总是一场噩梦。 感谢 Deelesh Mandloi。 您可以按照博客<a href="http://deelesh.github.io/pyspark-windows.html" target="_blank" rel="noopener"> Windows 上的 PySpark 入门</a>中的详细步骤，在 Windows 操作系统上安装 Apache Spark™。</p>
<h2 id="3-4-PySpark-和文本编辑器或-IDE"><a href="#3-4-PySpark-和文本编辑器或-IDE" class="headerlink" title="3.4. PySpark 和文本编辑器或 IDE"></a>3.4. PySpark 和文本编辑器或 IDE</h2><h3 id="3-4-1-PySpark-和-Jupyter-笔记本"><a href="#3-4-1-PySpark-和-Jupyter-笔记本" class="headerlink" title="3.4.1. PySpark 和 Jupyter 笔记本"></a>3.4.1. PySpark 和 Jupyter 笔记本</h3><p>完成<a href="#setup-up-ubuntu">在 Mac 和 Ubuntu 上配置 Spark</a>中的上述设置步骤后，您应该在 Jupyter 笔 记本中编写和运行 PySpark 代码。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/90a1240e7489f989b9a4e5739b1efbd5.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/jupyterWithPySpark.png"></p>
</blockquote>
<h3 id="3-4-2-PySpark-和-Apache-Zeppelin"><a href="#3-4-2-PySpark-和-Apache-Zeppelin" class="headerlink" title="3.4.2. PySpark 和 Apache Zeppelin"></a>3.4.2. PySpark 和 Apache Zeppelin</h3><p>完成<a href="#setup-up-ubuntu">在 Mac 和 Ubuntu 上配置 Spark</a>中的上述设置步骤后，您应该在 Apache Zeppelin 中编写和运行 PySpark 代码。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/067197a5eeb69cc2f3d828a92ebcf52e.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/zeppelin.png"></p>
</blockquote>
<h3 id="3-4-3-PySpark-和-Sublime-Text"><a href="#3-4-3-PySpark-和-Sublime-Text" class="headerlink" title="3.4.3. PySpark 和 Sublime Text"></a>3.4.3. PySpark 和 Sublime Text</h3><p>完成<a href="#setup-up-ubuntu">在 Mac 和 Ubuntu 上配置 Spark</a>中的上述设置步骤后，您应该可以使用 Sublime Text 编写 PySpark 代码,并在终端中将代码作为普通的 python 代码运行。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python test_pyspark.py</span><br></pre></td></tr></table></figure>

<p>然后你应该在你的终端获得输出结果。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c51fb942d508d4161e72d0075a5284e7.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/sublimeWithPySpark.png"></p>
</blockquote>
<h3 id="3-4-4-PySpark-和-Eclipse"><a href="#3-4-4-PySpark-和-Eclipse" class="headerlink" title="3.4.4. PySpark 和 Eclipse"></a>3.4.4. PySpark 和 Eclipse</h3><p>如果要在 Eclipse 上运行 PySpark 代码，则需要为<strong>当前项目</strong>添加<strong>外部库</strong>的路径，如下所示：</p>
<ol>
<li><p>打开你的项目的属性</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/f18ecec7a6c176301d7370e41a0a60dd.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/PyDevProperties.png"></p>
</li>
<li><p>为<strong>外部</strong>添加路径</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/197517339d2ce744dd0a46c607e84534.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/pydevPath.png"></p>
</li>
</ol>
<p>然后你应该足以用 PyDev 在 Eclipse 上运行你的代码。</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/6f2adb68d3f0a7f1f3af2ef044441071.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/pysparkWithEclipse.png"></p>
</blockquote>
<h2 id="3-5-PySparkling-水-Spark-H2O"><a href="#3-5-PySparkling-水-Spark-H2O" class="headerlink" title="3.5. PySparkling 水: Spark + H2O"></a>3.5. PySparkling 水: Spark + H2O</h2><ol>
<li><p>从 <a href="https://s3.amazonaws.com/h2o-release/sparkling-water/rel-2.4/5/index.html" target="_blank" rel="noopener">https://s3.amazonaws.com/h2o-release/sparkling-water/rel-2.4/5/index.html</a> 下载<code>Sparkling Water</code>：</p>
</li>
<li><p>测试 PySparking</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unzip sparkling-water-2.4.5.zip</span><br><span class="line"><span class="built_in">cd</span>  ~/sparkling-water-2.4.5/bin</span><br><span class="line">./pysparkling</span><br></pre></td></tr></table></figure>

<p>如果您有正确设置了 PySpark，那么您将获得以下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Using Spark defined in the SPARK_HOME=/Users/dt216661/spark environmental property</span><br><span class="line"></span><br><span class="line">Python 3.7.1 (default, Dec 14 2018, 13:28:58)</span><br><span class="line">[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">2019-02-15 14:08:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">Using Spark&apos;s default log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span><br><span class="line">2019-02-15 14:08:31 WARN  Utils:66 - Service &apos;SparkUI&apos; could not bind on port 4040\. Attempting port 4041.</span><br><span class="line">2019-02-15 14:08:31 WARN  Utils:66 - Service &apos;SparkUI&apos; could not bind on port 4041\. Attempting port 4042.</span><br><span class="line">17/08/30 13:30:12 WARN NativeCodeLoader: Unable to load native-hadoop</span><br><span class="line">library for your platform... using builtin-java classes where applicable</span><br><span class="line">17/08/30 13:30:17 WARN ObjectStore: Failed to get database global_temp,</span><br><span class="line">returning NoSuchObjectException</span><br><span class="line">Welcome to</span><br><span class="line">       ____              __</span><br><span class="line">      / __/__  ___ _____/ /__</span><br><span class="line">     _\ \/ _ \/ _ `/ __/  &apos;_/</span><br><span class="line">    /__ / .__/\_,_/_/ /_/\_\   version 2.4.0</span><br><span class="line">       /_/</span><br><span class="line"></span><br><span class="line">Using Python version 3.7.1 (default, Dec 14 2018 13:28:58)</span><br><span class="line">SparkSession available as &apos;spark&apos;.</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用 Jupyter notebook <code>pysparkling</code></p>
<p>将以下别名添加到<code>bashrc</code>（Linux 系统）或<code>bash_profile</code>（Mac 系统）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> sparkling=<span class="string">"PYSPARK_DRIVER_PYTHON="</span>ipython<span class="string">" PYSPARK_DRIVER_PYTHON_OPTS=    "</span>notebook<span class="string">" /~/~/sparkling-water-2.4.5/bin/pysparkling"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在终端打开<code>pysparkling</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sparkling</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="3-6-在云上配置-Spark"><a href="#3-6-在云上配置-Spark" class="headerlink" title="3.6. 在云上配置 Spark"></a>3.6. 在云上配置 Spark</h2><p>按照<a href="#setup-up-ubuntu">在 Mac 和 Ubuntu 上配置 Spark</a>中的设置步骤，您可以在云上设置自己的集群，例如 AWS，Google Cloud。 实际上，对于那些云，他们有自己的大数据工具。 你可以直接在任何设置上运行它们，就像 Databricks 社区云一样。 如果您想了解更多详情，请随时与作者联系。</p>
<h2 id="3-7-这一节的示例代码"><a href="#3-7-这一节的示例代码" class="headerlink" title="3.7. 这一节的示例代码"></a>3.7. 这一节的示例代码</h2><p>此部分的代码可在<a href="static/test_pyspark.py"><code>test_pyspark</code></a>下载，Jupyter 笔记本可从<a href="static/test_pyspark.ipynb"><code>test_pyspark_ipynb</code></a>下载。</p>
<ul>
<li>Python 源代码</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 建立 SparkSession</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"Python Spark SQL basic example"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">df = spark.read.format(<span class="string">'com.databricks.spark.csv'</span>).\</span><br><span class="line">                               options(header=<span class="string">'true'</span>, \</span><br><span class="line">                               inferschema=<span class="string">'true'</span>).\</span><br><span class="line">                     load(<span class="string">"/home/feng/Spark/Code/data/Advertising.csv"</span>,header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">df.show(<span class="number">5</span>)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<h1 id="4-Apache-Spark-入门"><a href="#4-Apache-Spark-入门" class="headerlink" title="4. Apache Spark 入门"></a>4. Apache Spark 入门</h1><p><strong>知己知彼，百战百胜。</strong> – 《孙子兵法》</p>
<h2 id="4-1-核心概念"><a href="#4-1-核心概念" class="headerlink" title="4.1. 核心概念"></a>4.1. 核心概念</h2><p>以下大部分内容来自 <a href="reference.html#kirillov2016">[Kirillov2016]</a>。 所以版权属于 <strong>Anton Kirillov</strong>。我向您推荐<a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener"> Apache Spark 核心概念，架构和内部</a>来获取更多详细信息。</p>
<p>在深入研究 Apache Spark 之前，让我们阅读 Apache Spark 的行话。</p>
<ul>
<li>作业：从 HDFS 或本地读取一些输入的代码，对数据执行一些计算并写入一些输出数据。</li>
<li>阶段：工作分为几个阶段。 阶段被分类为映射或归约阶段（如果您已经使用过 Hadoop 并希望关联，则更容易理解）。 阶段基于计算边界划分，所有计算（操作符）不能在单个阶段中更新。 它发生在很多阶段。</li>
<li>任务：每个阶段都有一些任务，每个任务一个分区。 一个任务执行在一个执行器（机器）上的一个数据分区上。</li>
<li>DAG：DAG 代表有向无环图，在本文中是操作符的 DAG。</li>
<li>执行器：负责执行任务的进程。</li>
<li>主机：运行驱动程序的机器</li>
<li>从机：运行执行程序的机器</li>
</ul>
<h2 id="4-2-Spark-组件"><a href="#4-2-Spark-组件" class="headerlink" title="4.2. Spark 组件"></a>4.2. Spark 组件</h2><blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/f4e95f92187a42f257864cd22193c8ad.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/spark-components.png"></p>
</blockquote>
<ol>
<li><p>Spark 驱动</p>
<ul>
<li>隔离进程来执行用户应用</li>
<li>创建<code>SparkContext</code>来调度任务执行并与集群管理器协商</li>
</ul>
</li>
<li><p>执行器</p>
<ul>
<li>运行由驱动调度的任务</li>
<li>在内存、磁盘或者 off-heap 中储存计算结果</li>
<li>与储存系统个交互</li>
</ul>
</li>
<li><p>集群管理器</p>
<ul>
<li>Mesos</li>
<li>YARN</li>
<li>Spark Standalone</li>
</ul>
<p>Spark 驱动包含更多组件，负责将用户代码转换为集群上的实际作业：</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/0ff87df50cf4610da54dd94b51c6d809.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/spark-components1.png"></p>
</li>
</ol>
<ul>
<li><p><code>SparkContext</code></p>
<ul>
<li>表示 spark 集群的连接，可用于在该集群上创建 RDD，累加器和广播变量</li>
</ul>
</li>
<li><p><code>DAGScheduler</code></p>
<ul>
<li>计算机每个作业的阶段的 DAG 并将它们提交给<code>TaskScheduler</code>，来确定任务的首选位置（基于缓存状态或随机文件位置）并找到运行作业的最小调度</li>
</ul>
</li>
<li><p><code>TaskScheduler</code></p>
<ul>
<li>负责将任务发送到集群，运行它们，在发生故障时重试，以及减轻负担</li>
</ul>
</li>
<li><p><code>SchedulerBackend</code></p>
<ul>
<li>用于调度系统的后端接口，允许插入不同的实现（mesos，yarn，standalone，local）</li>
</ul>
</li>
<li><p><code>BlockManager</code></p>
<ul>
<li>提供接口，用于在本地和远程将块放置到各种存储（内存，磁盘和堆外）和检索</li>
</ul>
</li>
</ul>
<h2 id="4-3-架构"><a href="#4-3-架构" class="headerlink" title="4.3. 架构"></a>4.3. 架构</h2><h2 id="4-4-Spark-的工作原理"><a href="#4-4-Spark-的工作原理" class="headerlink" title="4.4. Spark 的工作原理"></a>4.4. Spark 的工作原理</h2><p>Spark 具有较小的代码库，系统分为不同的层。 每一层都有一些责任。 这些层彼此独立。</p>
<p>第一层是解释器，Spark 使用 Scala 解释器，并进行了一些修改。 当您在 spark 控制台中输入代码（创建 RDD 并应用操作符）时，Spark 会创建一个操作符图。 当用户运行操作（如收集）时，图将提交给 DAG 调度器。 DAG 调度器将操作符图分为（映射和归约）阶段。 阶段由基于输入数据的分区的任务组成。 DAG 调度器将操作符连接在一起来优化图。 例如 许多图的操作符可以安排在一个阶段中。 此优化是 Sparks 性能的关键。 DAG 调度器的最终结果是一组阶段。 这些阶段将传递给任务调度器。 任务调度器通过集群管理器启动任务（Spark Standalone/Yarn/Mesos）。 任务调度器不知道阶段之间的依赖关系。</p>
<p><img src="img/0ebcb4677d2131e71e039be8ea955cff.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/work_flow.png"></p>
<h1 id="5-使用-RDD-的编程"><a href="#5-使用-RDD-的编程" class="headerlink" title="5. 使用 RDD 的编程"></a>5. 使用 RDD 的编程</h1><p><strong>知彼知己，百战不殆；不知彼而知己，一胜一负；不知彼，不知己，每战必殆。</strong> – 《孙子兵法》</p>
<p>RDD 表示<strong>弹性分布式数据集</strong>。 Spark 中的 RDD 只是对象集的不可变分布式集合。 每个 RDD 被分成多个分区（具有较小集合的类似模式），可以在集群的不同节点上计算。</p>
<h2 id="5-1-创建-RDD"><a href="#5-1-创建-RDD" class="headerlink" title="5.1. 创建 RDD"></a>5.1. 创建 RDD</h2><p>通常，有两种创建 RDD 的流行方法：加载外部数据集或分发一组对象集合。 以下示例显示了一些使用<code>parallelize()</code>函数创建 RDD 的最简单方法，该方法接受程序中已有的集合，并将其传递给 Spark 上下文。</p>
<p>通过使用<code>parallelize( )</code>函数</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"Python Spark create RDD example"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">df = spark.sparkContext.parallelize([(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">'a b c'</span>),</span><br><span class="line">             (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="string">'d e f'</span>),</span><br><span class="line">             (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="string">'g h i'</span>)]).toDF([<span class="string">'col1'</span>, <span class="string">'col2'</span>, <span class="string">'col3'</span>,<span class="string">'col4'</span>])</span><br></pre></td></tr></table></figure>

<p>然后你将获得 RDD 数据：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df.show()</span><br><span class="line"></span><br><span class="line">+----+----+----+-----+</span><br><span class="line">|col1|col2|col3| col4|</span><br><span class="line">+----+----+----+-----+</span><br><span class="line">|   <span class="number">1</span>|   <span class="number">2</span>|   <span class="number">3</span>|a b c|</span><br><span class="line">|   <span class="number">4</span>|   <span class="number">5</span>|   <span class="number">6</span>|d e f|</span><br><span class="line">|   <span class="number">7</span>|   <span class="number">8</span>|   <span class="number">9</span>|g h i|</span><br><span class="line">+----+----+----+-----+</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"Python Spark create RDD example"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">myData = spark.sparkContext.parallelize([(<span class="number">1</span>,<span class="number">2</span>), (<span class="number">3</span>,<span class="number">4</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">7</span>,<span class="number">8</span>), (<span class="number">9</span>,<span class="number">10</span>)])</span><br></pre></td></tr></table></figure>

<p>然后你将获得 RDD 数据：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">myData.collect()</span><br><span class="line"></span><br><span class="line">[(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>), (<span class="number">9</span>, <span class="number">10</span>)]</span><br></pre></td></tr></table></figure>

<p>通过使用<code>createDataFrame( )</code>函数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"Python Spark create RDD example"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">Employee = spark.createDataFrame([</span><br><span class="line">                        (<span class="string">'1'</span>, <span class="string">'Joe'</span>,   <span class="string">'70000'</span>, <span class="string">'1'</span>),</span><br><span class="line">                        (<span class="string">'2'</span>, <span class="string">'Henry'</span>, <span class="string">'80000'</span>, <span class="string">'2'</span>),</span><br><span class="line">                        (<span class="string">'3'</span>, <span class="string">'Sam'</span>,   <span class="string">'60000'</span>, <span class="string">'2'</span>),</span><br><span class="line">                        (<span class="string">'4'</span>, <span class="string">'Max'</span>,   <span class="string">'90000'</span>, <span class="string">'1'</span>)],</span><br><span class="line">                        [<span class="string">'Id'</span>, <span class="string">'Name'</span>, <span class="string">'Sallary'</span>,<span class="string">'DepartmentId'</span>]</span><br><span class="line">                       )</span><br></pre></td></tr></table></figure>

<p>然后你将获得 RDD 数据：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+---+-----+-------+------------+</span><br><span class="line">| Id| Name|Sallary|DepartmentId|</span><br><span class="line">+---+-----+-------+------------+</span><br><span class="line">|  <span class="number">1</span>|  Joe|  <span class="number">70000</span>|           <span class="number">1</span>|</span><br><span class="line">|  <span class="number">2</span>|Henry|  <span class="number">80000</span>|           <span class="number">2</span>|</span><br><span class="line">|  <span class="number">3</span>|  Sam|  <span class="number">60000</span>|           <span class="number">2</span>|</span><br><span class="line">|  <span class="number">4</span>|  Max|  <span class="number">90000</span>|           <span class="number">1</span>|</span><br><span class="line">+---+-----+-------+------------+</span><br></pre></td></tr></table></figure>

<p>通过使用<code>read</code>和<code>load</code>函数</p>
<p><strong>从 .csv 文件读取数据集</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 建立 SparkSession</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"Python Spark create RDD example"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">df = spark.read.format(<span class="string">'com.databricks.spark.csv'</span>).\</span><br><span class="line">                               options(header=<span class="string">'true'</span>, \</span><br><span class="line">                               inferschema=<span class="string">'true'</span>).\</span><br><span class="line">                load(<span class="string">"/home/feng/Spark/Code/data/Advertising.csv"</span>,header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">df.show(<span class="number">5</span>)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<p>然后你将获得 RDD 数据：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|_c0|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|  <span class="number">1</span>|<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|</span><br><span class="line">|  <span class="number">2</span>| <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|</span><br><span class="line">|  <span class="number">3</span>| <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|</span><br><span class="line">|  <span class="number">4</span>|<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|</span><br><span class="line">|  <span class="number">5</span>|<span class="number">180.8</span>| <span class="number">10.8</span>|     <span class="number">58.4</span>| <span class="number">12.9</span>|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- _c0: integer (nullable = true)</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<p>创建后，RDD 提供两种类型的操作：转换和动作。</p>
<p><strong>从数据库读取数据集</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 建立 SparkSession</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">            .builder \</span><br><span class="line">            .appName(<span class="string">"Python Spark create RDD example"</span>) \</span><br><span class="line">            .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 用户信息</span></span><br><span class="line">user = <span class="string">'your_username'</span></span><br><span class="line">pw   = <span class="string">'your_password'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 数据库信息</span></span><br><span class="line">table_name = <span class="string">'table_name'</span></span><br><span class="line">url = <span class="string">'jdbc:postgresql://##.###.###.##:5432/dataset?user='</span>+user+<span class="string">'&amp;password='</span>+pw</span><br><span class="line">properties =&#123;<span class="string">'driver'</span>: <span class="string">'org.postgresql.Driver'</span>, <span class="string">'password'</span>: pw,<span class="string">'user'</span>: user&#125;</span><br><span class="line"></span><br><span class="line">df = spark.read.jdbc(url=url, table=table_name, properties=properties)</span><br><span class="line"></span><br><span class="line">df.show(<span class="number">5</span>)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<p>然后你将获得 RDD 数据：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|_c0|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">|  <span class="number">1</span>|<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|</span><br><span class="line">|  <span class="number">2</span>| <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|</span><br><span class="line">|  <span class="number">3</span>| <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|</span><br><span class="line">|  <span class="number">4</span>|<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|</span><br><span class="line">|  <span class="number">5</span>|<span class="number">180.8</span>| <span class="number">10.8</span>|     <span class="number">58.4</span>| <span class="number">12.9</span>|</span><br><span class="line">+---+-----+-----+---------+-----+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- _c0: integer (nullable = true)</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>从数据库中读取表，需要相应数据库的正确驱动。 例如，上面的演示需要<code>org.postgresql.Driver</code>，你需要下载它并将它放在你的 spark 安装路径的<code>jars</code>文件夹中。 我从官方网站下载<code>postgresql-42.1.1.jar</code>并将其放在<code>jars</code>文件夹中。</p>
</blockquote>
<p><strong>从 HDFS 读取数据</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.conf <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.context <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext</span><br><span class="line"></span><br><span class="line">sc= SparkContext(<span class="string">'local'</span>,<span class="string">'example'</span>)</span><br><span class="line">hc = HiveContext(sc)</span><br><span class="line">tf1 = sc.textFile(<span class="string">"hdfs://cdhstltest/user/data/demo.CSV"</span>)</span><br><span class="line">print(tf1.first())</span><br><span class="line"></span><br><span class="line">hc.sql(<span class="string">"use intg_cme_w"</span>)</span><br><span class="line">spf = hc.sql(<span class="string">"SELECT * FROM spf LIMIT 100"</span>)</span><br><span class="line">print(spf.show(<span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<h2 id="5-2-Spark-操作"><a href="#5-2-Spark-操作" class="headerlink" title="5.2. Spark 操作"></a>5.2. Spark 操作</h2><blockquote>
<p>警告</p>
<p>以下所有数据均来自J effrey Thompson。 感兴趣的读者可以参考 <a href="https://github.com/jkthompson/pyspark-pictures" target="_blank" rel="noopener">pyspark 图片</a>。</p>
<p>Spark 操作有两种主要类型：转换和动作 <a href="reference.html#karau2015">[Karau2015]</a>。</p>
</blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/ec9e0b7231caed693477682311612304.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/visualapi_006.png"></p>
<blockquote>
<p>注意</p>
<p>有些人定义了三种类型的操作：转换，动作和打乱。</p>
</blockquote>
<h3 id="5-2-1-Spark-转换"><a href="#5-2-1-Spark-转换" class="headerlink" title="5.2.1. Spark 转换"></a>5.2.1. Spark 转换</h3><p>转换从前一个 RDD 构建新的 RDD。 例如，一个常见的转换是过滤匹配谓词的数据。</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1478d9b0743fdc3b0c6ad079b88034ec.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/transforms1.png"></p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/69ff1f1b7a8e2162d5395fa62c35e8b6.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/transforms2.png"></p>
<h3 id="5-2-2-Spark-动作"><a href="#5-2-2-Spark-动作" class="headerlink" title="5.2.2. Spark 动作"></a>5.2.2. Spark 动作</h3><p>另一方面，动作基于 RDD 计算结果，并将其返回到驱动，或将其保存到外部存储系统（例如，HDFS）。</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c03bdd903e4bd06d018711d1dece0c35.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/actions1.png"></p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/e1164e5922bbcc2db8e6b23c145b8f75.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/actions2.png"></p>
<h2 id="5-3-rdd-DataFrame-VS-pd-DataFrame"><a href="#5-3-rdd-DataFrame-VS-pd-DataFrame" class="headerlink" title="5.3. rdd.DataFrame VS pd.DataFrame"></a>5.3. <code>rdd.DataFrame</code> VS <code>pd.DataFrame</code></h2><h3 id="5-3-1-创建DataFrame"><a href="#5-3-1-创建DataFrame" class="headerlink" title="5.3.1. 创建DataFrame"></a>5.3.1. 创建<code>DataFrame</code></h3><p><strong>来自列表</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">my_list = [[<span class="string">'a'</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="string">'b'</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="string">'c'</span>, <span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">col_name = [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>]</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意 columns=</span></span><br><span class="line">pd.DataFrame(my_list,columns= col_name)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">spark.createDataFrame(my_list, col_name).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                  +---+---+---+</span><br><span class="line">                  |  A|  B|  C|</span><br><span class="line">   A  B  C        +---+---+---+</span><br><span class="line"><span class="number">0</span>  a  <span class="number">1</span>  <span class="number">2</span>        |  a|  <span class="number">1</span>|  <span class="number">2</span>|</span><br><span class="line"><span class="number">1</span>  b  <span class="number">2</span>  <span class="number">3</span>        |  b|  <span class="number">2</span>|  <span class="number">3</span>|</span><br><span class="line"><span class="number">2</span>  c  <span class="number">3</span>  <span class="number">4</span>        |  c|  <span class="number">3</span>|  <span class="number">4</span>|</span><br><span class="line">                  +---+---+---+</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>注意<code>pd.DataFrame</code>中的参数<code>columns=</code>，由于默认值将使列表成为行。</p>
</blockquote>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意 columns=</span></span><br><span class="line">pd.DataFrame(my_list, columns= col_name)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">pd.DataFrame(my_list, col_name)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">   A  B  C             <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  a  <span class="number">1</span>  <span class="number">2</span>          A  a  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">1</span>  b  <span class="number">2</span>  <span class="number">3</span>          B  b  <span class="number">2</span>  <span class="number">3</span></span><br><span class="line"><span class="number">2</span>  c  <span class="number">3</span>  <span class="number">4</span>          C  c  <span class="number">3</span>  <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p><strong>来自字典</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'A'</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">     <span class="string">'B'</span>: [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">     <span class="string">'C'</span>: [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(d)<span class="keyword">for</span></span><br><span class="line"><span class="comment"># PySpark 很麻烦</span></span><br><span class="line">spark.createDataFrame(np.array(list(d.values())).T.tolist(),list(d.keys())).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                   +---+---+---+</span><br><span class="line">                   |  A|  B|  C|</span><br><span class="line">   A  B  C         +---+---+---+</span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>         |  <span class="number">0</span>|  <span class="number">1</span>|  <span class="number">1</span>|</span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>         |  <span class="number">1</span>|  <span class="number">0</span>|  <span class="number">0</span>|</span><br><span class="line"><span class="number">2</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span>         |  <span class="number">0</span>|  <span class="number">1</span>|  <span class="number">0</span>|</span><br><span class="line">                   +---+---+---+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-2-加载DataFrame"><a href="#5-3-2-加载DataFrame" class="headerlink" title="5.3.2. 加载DataFrame"></a>5.3.2. 加载<code>DataFrame</code></h3><p><strong>来自数据库</strong></p>
<p>大多数情况下，您需要与同事共享代码，或为了代码审查或质量保证（QA）发布代码。 您肯定不希望在代码中包含您的“用户信息”。 所以你可以将它们保存在<code>login.txt</code>中：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">runawayhorse001</span><br><span class="line">PythonTips</span><br></pre></td></tr></table></figure>

<p>并使用以下代码导入您的“用户信息”：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户信息</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    login = pd.read_csv(<span class="string">r'login.txt'</span>, header=<span class="literal">None</span>)</span><br><span class="line">    user = login[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    pw = login[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    print(<span class="string">'User information is ready!'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Login information is not available!!!'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据库信息</span></span><br><span class="line">host = <span class="string">'##.###.###.##'</span></span><br><span class="line">db_name = <span class="string">'db_name'</span></span><br><span class="line">table_name = <span class="string">'table_name'</span></span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conn = psycopg2.connect(host=host, database=db_name, user=user, password=pw)</span><br><span class="line">cur = conn.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">      select *</span></span><br><span class="line"><span class="string">      from &#123;table_name&#125;</span></span><br><span class="line"><span class="string">      """</span>.format(table_name=table_name)</span><br><span class="line">dp = pd.read_sql(sql, conn)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接数据库</span></span><br><span class="line">url = <span class="string">'jdbc:postgresql://'</span>+host+<span class="string">':5432/'</span>+db_name+<span class="string">'?user='</span>+user+<span class="string">'&amp;password='</span>+pw</span><br><span class="line">properties =&#123;<span class="string">'driver'</span>: <span class="string">'org.postgresql.Driver'</span>, <span class="string">'password'</span>: pw,<span class="string">'user'</span>: user&#125;</span><br><span class="line">ds = spark.read.jdbc(url=url, table=table_name, properties=properties)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>使用 PySpark 从数据库中读取表，需要相应数据库的正确驱动。 例如，上面的演示需要<code>org.postgresql.Driver</code>，你需要下载它并将它放在你的 spark 安装路径的<code>jars</code>文件夹中。 我从官方网站下载<code>postgresql-42.1.1.jar</code>并将其放在<code>jars</code>文件夹中。</p>
</blockquote>
<p><strong>来自<code>.csv</code></strong></p>
<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pd.DataFrame dp: DataFrame pandas</span></span><br><span class="line">dp = pd.read_csv(<span class="string">'Advertising.csv'</span>)</span><br><span class="line"><span class="comment">#rdd.DataFrame. dp: DataFrame spark</span></span><br><span class="line">ds = spark.read.csv(path=<span class="string">'Advertising.csv'</span>,</span><br><span class="line"><span class="comment">#                sep=',',</span></span><br><span class="line"><span class="comment">#                encoding='UTF-8',</span></span><br><span class="line"><span class="comment">#                comment=None,</span></span><br><span class="line">               header=<span class="literal">True</span>,</span><br><span class="line">               inferSchema=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>来自<code>.json</code></strong></p>
<p>数据来自：<a href="http://api.luftdaten.info/static/v1/data.json" target="_blank" rel="noopener">http://api.luftdaten.info/static/v1/data.json</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dp = pd.read_json(<span class="string">"data/data.json"</span>)</span><br><span class="line">ds = spark.read.json(<span class="string">'data/data.json'</span>)</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[[<span class="string">'id'</span>,<span class="string">'timestamp'</span>]].head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds[[<span class="string">'id'</span>,<span class="string">'timestamp'</span>]].show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +----------+-------------------+</span><br><span class="line">                                                |        id|          timestamp|</span><br><span class="line">            id  timestamp                       +----------+-------------------+</span><br><span class="line"><span class="number">0</span>   <span class="number">2994551481</span>  <span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>             |<span class="number">2994551481</span>|<span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">2994551482</span>  <span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>             |<span class="number">2994551482</span>|<span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">2994551483</span>  <span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>             |<span class="number">2994551483</span>|<span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>|</span><br><span class="line"><span class="number">3</span>   <span class="number">2994551484</span>  <span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>             |<span class="number">2994551484</span>|<span class="number">2019</span><span class="number">-02</span><span class="number">-28</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">52</span>|</span><br><span class="line">                                                +----------+-------------------+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-3-前n行"><a href="#5-3-3-前n行" class="headerlink" title="5.3.3. 前n行"></a>5.3.3. 前<code>n</code>行</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                        +-----+-----+---------+-----+</span><br><span class="line">                                        |   TV|Radio|Newspaper|Sales|</span><br><span class="line">      TV  Radio  Newspaper  Sales       +-----+-----+---------+-----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>       <span class="number">69.2</span>   <span class="number">22.1</span>       |<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>       <span class="number">45.1</span>   <span class="number">10.4</span>       | <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>       <span class="number">69.3</span>    <span class="number">9.3</span>       | <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>       <span class="number">58.5</span>   <span class="number">18.5</span>       |<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|</span><br><span class="line">                                        +-----+-----+---------+-----+</span><br><span class="line">                                        only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-4-列名"><a href="#5-3-4-列名" class="headerlink" title="5.3.4. 列名"></a>5.3.4. 列名</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.columns</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.columns</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Index([<span class="string">'TV'</span>, <span class="string">'Radio'</span>, <span class="string">'Newspaper'</span>, <span class="string">'Sales'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line">[<span class="string">'TV'</span>, <span class="string">'Radio'</span>, <span class="string">'Newspaper'</span>, <span class="string">'Sales'</span>]</span><br></pre></td></tr></table></figure>

<h3 id="5-3-5-数据类型"><a href="#5-3-5-数据类型" class="headerlink" title="5.3.5. 数据类型"></a>5.3.5. 数据类型</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.dtypes</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.dtypes</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TV           float64                    [(<span class="string">'TV'</span>, <span class="string">'double'</span>),</span><br><span class="line">Radio        float64                     (<span class="string">'Radio'</span>, <span class="string">'double'</span>),</span><br><span class="line">Newspaper    float64                     (<span class="string">'Newspaper'</span>, <span class="string">'double'</span>),</span><br><span class="line">Sales        float64                     (<span class="string">'Sales'</span>, <span class="string">'double'</span>)]</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>

<h3 id="5-3-6-填充空值"><a href="#5-3-6-填充空值" class="headerlink" title="5.3.6. 填充空值"></a>5.3.6. 填充空值</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">my_list = [[<span class="string">'a'</span>, <span class="number">1</span>, <span class="literal">None</span>], [<span class="string">'b'</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="string">'c'</span>, <span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">dp = pd.DataFrame(my_list,columns=[<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>])</span><br><span class="line">ds = spark.createDataFrame(my_list, [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>])</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">dp.head()</span><br><span class="line">ds.show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                        +------+---+----+</span><br><span class="line">                                        |     A|  B|   C|</span><br><span class="line">        A  B    C                       +------+---+----+</span><br><span class="line"><span class="number">0</span>    male  <span class="number">1</span>  NaN                       |  male|  <span class="number">1</span>|null|</span><br><span class="line"><span class="number">1</span>  female  <span class="number">2</span>  <span class="number">3.0</span>                       |female|  <span class="number">2</span>|   <span class="number">3</span>|</span><br><span class="line"><span class="number">2</span>    male  <span class="number">3</span>  <span class="number">4.0</span>                       |  male|  <span class="number">3</span>|   <span class="number">4</span>|</span><br><span class="line">                                        +------+---+----+</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.fillna(<span class="number">-99</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.fillna(<span class="number">-99</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                        +------+---+----+</span><br><span class="line">                                        |     A|  B|   C|</span><br><span class="line">        A  B    C                       +------+---+----+</span><br><span class="line"><span class="number">0</span>    male  <span class="number">1</span>  <span class="number">-99</span>                       |  male|  <span class="number">1</span>| <span class="number">-99</span>|</span><br><span class="line"><span class="number">1</span>  female  <span class="number">2</span>  <span class="number">3.0</span>                       |female|  <span class="number">2</span>|   <span class="number">3</span>|</span><br><span class="line"><span class="number">2</span>    male  <span class="number">3</span>  <span class="number">4.0</span>                       |  male|  <span class="number">3</span>|   <span class="number">4</span>|</span><br><span class="line">                                        +------+---+----+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-7-替换值"><a href="#5-3-7-替换值" class="headerlink" title="5.3.7. 替换值"></a>5.3.7. 替换值</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 警告：您需要选择特定的列</span></span><br><span class="line">dp.A.replace([<span class="string">'male'</span>, <span class="string">'female'</span>],[<span class="number">1</span>, <span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">dp</span><br><span class="line"><span class="comment"># 警告：不支持混合类型替换</span></span><br><span class="line">ds.na.replace([<span class="string">'male'</span>,<span class="string">'female'</span>],[<span class="string">'1'</span>,<span class="string">'0'</span>]).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                +---+---+----+</span><br><span class="line">                                |  A|  B|   C|</span><br><span class="line">   A  B    C                    +---+---+----+</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>  NaN                    |  <span class="number">1</span>|  <span class="number">1</span>|null|</span><br><span class="line"><span class="number">1</span>  <span class="number">0</span>  <span class="number">2</span>  <span class="number">3.0</span>                    |  <span class="number">0</span>|  <span class="number">2</span>|   <span class="number">3</span>|</span><br><span class="line"><span class="number">2</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">4.0</span>                    |  <span class="number">1</span>|  <span class="number">3</span>|   <span class="number">4</span>|</span><br><span class="line">                                +---+---+----+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-8-重命名列"><a href="#5-3-8-重命名列" class="headerlink" title="5.3.8. 重命名列"></a>5.3.8. 重命名列</h3><p><strong>重命名所有列</strong></p>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp.columns = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>]</span><br><span class="line">dp.head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.toDF(<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+----+----+----+</span><br><span class="line">                                                |    a|   b|   c|   d|</span><br><span class="line">       a     b     c     d                      +-----+----+----+----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>  <span class="number">37.8</span>  <span class="number">69.2</span>  <span class="number">22.1</span>                      |<span class="number">230.1</span>|<span class="number">37.8</span>|<span class="number">69.2</span>|<span class="number">22.1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>  <span class="number">39.3</span>  <span class="number">45.1</span>  <span class="number">10.4</span>                      | <span class="number">44.5</span>|<span class="number">39.3</span>|<span class="number">45.1</span>|<span class="number">10.4</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>  <span class="number">45.9</span>  <span class="number">69.3</span>   <span class="number">9.3</span>                      | <span class="number">17.2</span>|<span class="number">45.9</span>|<span class="number">69.3</span>| <span class="number">9.3</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>  <span class="number">41.3</span>  <span class="number">58.5</span>  <span class="number">18.5</span>                      |<span class="number">151.5</span>|<span class="number">41.3</span>|<span class="number">58.5</span>|<span class="number">18.5</span>|</span><br><span class="line">                                                +-----+----+----+----+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<p><strong>重命名一列或多列</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapping = &#123;<span class="string">'Newspaper'</span>:<span class="string">'C'</span>,<span class="string">'Sales'</span>:<span class="string">'D'</span>&#125;</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp.rename(columns=mapping).head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">new_names = [mapping.get(col,col) <span class="keyword">for</span> col <span class="keyword">in</span> ds.columns]</span><br><span class="line">ds.toDF(*new_names).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                        +-----+-----+----+----+</span><br><span class="line">                                        |   TV|Radio|   C|   D|</span><br><span class="line">      TV  Radio     C     D             +-----+-----+----+----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>  <span class="number">69.2</span>  <span class="number">22.1</span>             |<span class="number">230.1</span>| <span class="number">37.8</span>|<span class="number">69.2</span>|<span class="number">22.1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>  <span class="number">45.1</span>  <span class="number">10.4</span>             | <span class="number">44.5</span>| <span class="number">39.3</span>|<span class="number">45.1</span>|<span class="number">10.4</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>  <span class="number">69.3</span>   <span class="number">9.3</span>             | <span class="number">17.2</span>| <span class="number">45.9</span>|<span class="number">69.3</span>| <span class="number">9.3</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>  <span class="number">58.5</span>  <span class="number">18.5</span>             |<span class="number">151.5</span>| <span class="number">41.3</span>|<span class="number">58.5</span>|<span class="number">18.5</span>|</span><br><span class="line">                                        +-----+-----+----+----+</span><br><span class="line">                                        only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>您还可以使用<code>withColumnRenamed</code>重命名 PySpark 中的一列。</p>
</blockquote>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds.withColumnRenamed(<span class="string">'Newspaper'</span>,<span class="string">'Paper'</span>).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+-----+-----+</span><br><span class="line">|   TV|Radio|Paper|Sales|</span><br><span class="line">+-----+-----+-----+-----+</span><br><span class="line">|<span class="number">230.1</span>| <span class="number">37.8</span>| <span class="number">69.2</span>| <span class="number">22.1</span>|</span><br><span class="line">| <span class="number">44.5</span>| <span class="number">39.3</span>| <span class="number">45.1</span>| <span class="number">10.4</span>|</span><br><span class="line">| <span class="number">17.2</span>| <span class="number">45.9</span>| <span class="number">69.3</span>|  <span class="number">9.3</span>|</span><br><span class="line">|<span class="number">151.5</span>| <span class="number">41.3</span>| <span class="number">58.5</span>| <span class="number">18.5</span>|</span><br><span class="line">+-----+-----+-----+-----+</span><br><span class="line">only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-9-丢弃列"><a href="#5-3-9-丢弃列" class="headerlink" title="5.3.9. 丢弃列"></a>5.3.9. 丢弃列</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop_name = [<span class="string">'Newspaper'</span>,<span class="string">'Sales'</span>]</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.drop(drop_name,axis=<span class="number">1</span>).head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.drop(*drop_name).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                +-----+-----+</span><br><span class="line">                                |   TV|Radio|</span><br><span class="line">      TV  Radio                 +-----+-----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>                 |<span class="number">230.1</span>| <span class="number">37.8</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>                 | <span class="number">44.5</span>| <span class="number">39.3</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>                 | <span class="number">17.2</span>| <span class="number">45.9</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>                 |<span class="number">151.5</span>| <span class="number">41.3</span>|</span><br><span class="line">                                +-----+-----+</span><br><span class="line">                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-10-过滤"><a href="#5-3-10-过滤" class="headerlink" title="5.3.10. 过滤"></a>5.3.10. 过滤</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dp = pd.read_csv(<span class="string">'Advertising.csv'</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds = spark.read.csv(path=<span class="string">'Advertising.csv'</span>,</span><br><span class="line">                    header=<span class="literal">True</span>,</span><br><span class="line">                    inferSchema=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[dp.Newspaper&lt;<span class="number">20</span>].head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds[ds.Newspaper&lt;<span class="number">20</span>].show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|</span><br><span class="line">       TV  Radio  Newspaper  Sales              +-----+-----+---------+-----+</span><br><span class="line"><span class="number">7</span>   <span class="number">120.2</span>   <span class="number">19.6</span>       <span class="number">11.6</span>   <span class="number">13.2</span>              |<span class="number">120.2</span>| <span class="number">19.6</span>|     <span class="number">11.6</span>| <span class="number">13.2</span>|</span><br><span class="line"><span class="number">8</span>     <span class="number">8.6</span>    <span class="number">2.1</span>        <span class="number">1.0</span>    <span class="number">4.8</span>              |  <span class="number">8.6</span>|  <span class="number">2.1</span>|      <span class="number">1.0</span>|  <span class="number">4.8</span>|</span><br><span class="line"><span class="number">11</span>  <span class="number">214.7</span>   <span class="number">24.0</span>        <span class="number">4.0</span>   <span class="number">17.4</span>              |<span class="number">214.7</span>| <span class="number">24.0</span>|      <span class="number">4.0</span>| <span class="number">17.4</span>|</span><br><span class="line"><span class="number">13</span>   <span class="number">97.5</span>    <span class="number">7.6</span>        <span class="number">7.2</span>    <span class="number">9.7</span>              | <span class="number">97.5</span>|  <span class="number">7.6</span>|      <span class="number">7.2</span>|  <span class="number">9.7</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[(dp.Newspaper&lt;<span class="number">20</span>)&amp;(dp.TV&gt;<span class="number">100</span>)].head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds[(ds.Newspaper&lt;<span class="number">20</span>)&amp;(ds.TV&gt;<span class="number">100</span>)].show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|</span><br><span class="line">       TV  Radio  Newspaper  Sales              +-----+-----+---------+-----+</span><br><span class="line"><span class="number">7</span>   <span class="number">120.2</span>   <span class="number">19.6</span>       <span class="number">11.6</span>   <span class="number">13.2</span>              |<span class="number">120.2</span>| <span class="number">19.6</span>|     <span class="number">11.6</span>| <span class="number">13.2</span>|</span><br><span class="line"><span class="number">11</span>  <span class="number">214.7</span>   <span class="number">24.0</span>        <span class="number">4.0</span>   <span class="number">17.4</span>              |<span class="number">214.7</span>| <span class="number">24.0</span>|      <span class="number">4.0</span>| <span class="number">17.4</span>|</span><br><span class="line"><span class="number">19</span>  <span class="number">147.3</span>   <span class="number">23.9</span>       <span class="number">19.1</span>   <span class="number">14.6</span>              |<span class="number">147.3</span>| <span class="number">23.9</span>|     <span class="number">19.1</span>| <span class="number">14.6</span>|</span><br><span class="line"><span class="number">25</span>  <span class="number">262.9</span>    <span class="number">3.5</span>       <span class="number">19.5</span>   <span class="number">12.0</span>              |<span class="number">262.9</span>|  <span class="number">3.5</span>|     <span class="number">19.5</span>| <span class="number">12.0</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-11-添加新列"><a href="#5-3-11-添加新列" class="headerlink" title="5.3.11. 添加新列"></a>5.3.11. 添加新列</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'tv_norm'</span>] = dp.TV/sum(dp.TV)</span><br><span class="line">dp.head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.withColumn(<span class="string">'tv_norm'</span>, ds.TV/ds.groupBy().agg(F.sum(<span class="string">"TV"</span>)).collect()[<span class="number">0</span>][<span class="number">0</span>]).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+--------------------+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|             tv_norm|</span><br><span class="line">      TV  Radio  Newspaper  Sales   tv_norm     +-----+-----+---------+-----+--------------------+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>       <span class="number">69.2</span>   <span class="number">22.1</span>  <span class="number">0.007824</span>     |<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|<span class="number">0.007824268493802813</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>       <span class="number">45.1</span>   <span class="number">10.4</span>  <span class="number">0.001513</span>     | <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|<span class="number">0.001513167961643</span>...|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>       <span class="number">69.3</span>    <span class="number">9.3</span>  <span class="number">0.000585</span>     | <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|<span class="number">5.848649200061207E-4</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>       <span class="number">58.5</span>   <span class="number">18.5</span>  <span class="number">0.005152</span>     |<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|<span class="number">0.005151571824472517</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+--------------------+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'cond'</span>] = dp.apply(<span class="keyword">lambda</span> c: <span class="number">1</span> <span class="keyword">if</span> ((c.TV&gt;<span class="number">100</span>)&amp;(c.Radio&lt;<span class="number">40</span>)) <span class="keyword">else</span> <span class="number">2</span> <span class="keyword">if</span> c.Sales&gt; <span class="number">10</span> <span class="keyword">else</span> <span class="number">3</span>,axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.withColumn(<span class="string">'cond'</span>,F.when((ds.TV&gt;<span class="number">100</span>)&amp;(ds.Radio&lt;<span class="number">40</span>),<span class="number">1</span>)\</span><br><span class="line">                      .when(ds.Sales&gt;<span class="number">10</span>, <span class="number">2</span>)\</span><br><span class="line">                      .otherwise(<span class="number">3</span>)).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+----+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|cond|</span><br><span class="line">      TV  Radio  Newspaper  Sales  cond         +-----+-----+---------+-----+----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>       <span class="number">69.2</span>   <span class="number">22.1</span>     <span class="number">1</span>         |<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|   <span class="number">1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>       <span class="number">45.1</span>   <span class="number">10.4</span>     <span class="number">2</span>         | <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|   <span class="number">2</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>       <span class="number">69.3</span>    <span class="number">9.3</span>     <span class="number">3</span>         | <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|   <span class="number">3</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>       <span class="number">58.5</span>   <span class="number">18.5</span>     <span class="number">2</span>         |<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|   <span class="number">2</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+----+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'log_tv'</span>] = np.log(dp.TV)</span><br><span class="line">dp.head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.withColumn(<span class="string">'log_tv'</span>,F.log(ds.TV)).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+------------------+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|            log_tv|</span><br><span class="line">      TV  Radio  Newspaper  Sales    log_tv     +-----+-----+---------+-----+------------------+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>       <span class="number">69.2</span>   <span class="number">22.1</span>  <span class="number">5.438514</span>     |<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|  <span class="number">5.43851399704132</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>       <span class="number">45.1</span>   <span class="number">10.4</span>  <span class="number">3.795489</span>     | <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>|<span class="number">3.7954891891721947</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>       <span class="number">69.3</span>    <span class="number">9.3</span>  <span class="number">2.844909</span>     | <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>|<span class="number">2.8449093838194073</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>       <span class="number">58.5</span>   <span class="number">18.5</span>  <span class="number">5.020586</span>     |<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>| <span class="number">5.020585624949423</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+------------------+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'tv+10'</span>] = dp.TV.apply(<span class="keyword">lambda</span> x: x+<span class="number">10</span>)</span><br><span class="line">dp.head(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.withColumn(<span class="string">'tv+10'</span>, ds.TV+<span class="number">10</span>).show(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                                                +-----+-----+---------+-----+-----+</span><br><span class="line">                                                |   TV|Radio|Newspaper|Sales|tv+<span class="number">10</span>|</span><br><span class="line">      TV  Radio  Newspaper  Sales  tv+<span class="number">10</span>        +-----+-----+---------+-----+-----+</span><br><span class="line"><span class="number">0</span>  <span class="number">230.1</span>   <span class="number">37.8</span>       <span class="number">69.2</span>   <span class="number">22.1</span>  <span class="number">240.1</span>        |<span class="number">230.1</span>| <span class="number">37.8</span>|     <span class="number">69.2</span>| <span class="number">22.1</span>|<span class="number">240.1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">44.5</span>   <span class="number">39.3</span>       <span class="number">45.1</span>   <span class="number">10.4</span>   <span class="number">54.5</span>        | <span class="number">44.5</span>| <span class="number">39.3</span>|     <span class="number">45.1</span>| <span class="number">10.4</span>| <span class="number">54.5</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">17.2</span>   <span class="number">45.9</span>       <span class="number">69.3</span>    <span class="number">9.3</span>   <span class="number">27.2</span>        | <span class="number">17.2</span>| <span class="number">45.9</span>|     <span class="number">69.3</span>|  <span class="number">9.3</span>| <span class="number">27.2</span>|</span><br><span class="line"><span class="number">3</span>  <span class="number">151.5</span>   <span class="number">41.3</span>       <span class="number">58.5</span>   <span class="number">18.5</span>  <span class="number">161.5</span>        |<span class="number">151.5</span>| <span class="number">41.3</span>|     <span class="number">58.5</span>| <span class="number">18.5</span>|<span class="number">161.5</span>|</span><br><span class="line">                                                +-----+-----+---------+-----+-----+</span><br><span class="line">                                                only showing top <span class="number">4</span> rows</span><br></pre></td></tr></table></figure>

<h3 id="5-3-12-连接"><a href="#5-3-12-连接" class="headerlink" title="5.3.12. 连接"></a>5.3.12. 连接</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">leftp = pd.DataFrame(&#123;<span class="string">'A'</span>: [<span class="string">'A0'</span>, <span class="string">'A1'</span>, <span class="string">'A2'</span>, <span class="string">'A3'</span>],</span><br><span class="line">                    <span class="string">'B'</span>: [<span class="string">'B0'</span>, <span class="string">'B1'</span>, <span class="string">'B2'</span>, <span class="string">'B3'</span>],</span><br><span class="line">                    <span class="string">'C'</span>: [<span class="string">'C0'</span>, <span class="string">'C1'</span>, <span class="string">'C2'</span>, <span class="string">'C3'</span>],</span><br><span class="line">                    <span class="string">'D'</span>: [<span class="string">'D0'</span>, <span class="string">'D1'</span>, <span class="string">'D2'</span>, <span class="string">'D3'</span>]&#125;,</span><br><span class="line">                    index=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">rightp = pd.DataFrame(&#123;<span class="string">'A'</span>: [<span class="string">'A0'</span>, <span class="string">'A1'</span>, <span class="string">'A6'</span>, <span class="string">'A7'</span>],</span><br><span class="line">                       <span class="string">'F'</span>: [<span class="string">'B4'</span>, <span class="string">'B5'</span>, <span class="string">'B6'</span>, <span class="string">'B7'</span>],</span><br><span class="line">                       <span class="string">'G'</span>: [<span class="string">'C4'</span>, <span class="string">'C5'</span>, <span class="string">'C6'</span>, <span class="string">'C7'</span>],</span><br><span class="line">                       <span class="string">'H'</span>: [<span class="string">'D4'</span>, <span class="string">'D5'</span>, <span class="string">'D6'</span>, <span class="string">'D7'</span>]&#125;,</span><br><span class="line">                       index=[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">lefts = spark.createDataFrame(leftp)</span><br><span class="line">rights = spark.createDataFrame(rightp)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    A   B   C   D                   A   F   G   H</span><br><span class="line"><span class="number">0</span>  A0  B0  C0  D0               <span class="number">4</span>  A0  B4  C4  D4</span><br><span class="line"><span class="number">1</span>  A1  B1  C1  D1               <span class="number">5</span>  A1  B5  C5  D5</span><br><span class="line"><span class="number">2</span>  A2  B2  C2  D2               <span class="number">6</span>  A6  B6  C6  D6</span><br><span class="line"><span class="number">3</span>  A3  B3  C3  D3               <span class="number">7</span>  A7  B7  C7  D7</span><br></pre></td></tr></table></figure>

<p><strong>左连接</strong></p>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftp.merge(rightp,on=<span class="string">'A'</span>,how=<span class="string">'left'</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">lefts.join(rights,on=<span class="string">'A'</span>,how=<span class="string">'left'</span>)</span><br><span class="line">     .orderBy(<span class="string">'A'</span>,ascending=<span class="literal">True</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">                                        +---+---+---+---+----+----+----+</span><br><span class="line">                                        |  A|  B|  C|  D|   F|   G|   H|</span><br><span class="line">    A   B   C   D    F    G    H        +---+---+---+---+----+----+----+</span><br><span class="line"><span class="number">0</span>  A0  B0  C0  D0   B4   C4   D4        | A0| B0| C0| D0|  B4|  C4|  D4|</span><br><span class="line"><span class="number">1</span>  A1  B1  C1  D1   B5   C5   D5        | A1| B1| C1| D1|  B5|  C5|  D5|</span><br><span class="line"><span class="number">2</span>  A2  B2  C2  D2  NaN  NaN  NaN        | A2| B2| C2| D2|null|null|null|</span><br><span class="line"><span class="number">3</span>  A3  B3  C3  D3  NaN  NaN  NaN        | A3| B3| C3| D3|null|null|null|</span><br><span class="line">                                        +---+---+---+---+----+----+----+</span><br></pre></td></tr></table></figure>

<p><strong>右连接</strong></p>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftp.merge(rightp,on=<span class="string">'A'</span>,how=<span class="string">'right'</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">lefts.join(rights,on=<span class="string">'A'</span>,how=<span class="string">'right'</span>)</span><br><span class="line">     .orderBy(<span class="string">'A'</span>,ascending=<span class="literal">True</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">                                        +---+----+----+----+---+---+---+</span><br><span class="line">                                        |  A|   B|   C|   D|  F|  G|  H|</span><br><span class="line">    A    B    C    D   F   G   H        +---+----+----+----+---+---+---+</span><br><span class="line"><span class="number">0</span>  A0   B0   C0   D0  B4  C4  D4        | A0|  B0|  C0|  D0| B4| C4| D4|</span><br><span class="line"><span class="number">1</span>  A1   B1   C1   D1  B5  C5  D5        | A1|  B1|  C1|  D1| B5| C5| D5|</span><br><span class="line"><span class="number">2</span>  A6  NaN  NaN  NaN  B6  C6  D6        | A6|null|null|null| B6| C6| D6|</span><br><span class="line"><span class="number">3</span>  A7  NaN  NaN  NaN  B7  C7  D7        | A7|null|null|null| B7| C7| D7|</span><br><span class="line">                                        +---+----+----+----+---+---+---+</span><br></pre></td></tr></table></figure>

<p><strong>内连接</strong></p>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftp.merge(rightp,on=<span class="string">'A'</span>,how=<span class="string">'inner'</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">lefts.join(rights,on=<span class="string">'A'</span>,how=<span class="string">'inner'</span>)</span><br><span class="line">     .orderBy(<span class="string">'A'</span>,ascending=<span class="literal">True</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">                                +---+---+---+---+---+---+---+</span><br><span class="line">                                |  A|  B|  C|  D|  F|  G|  H|</span><br><span class="line">    A   B   C   D   F   G   H   +---+---+---+---+---+---+---+</span><br><span class="line"><span class="number">0</span>  A0  B0  C0  D0  B4  C4  D4   | A0| B0| C0| D0| B4| C4| D4|</span><br><span class="line"><span class="number">1</span>  A1  B1  C1  D1  B5  C5  D5   | A1| B1| C1| D1| B5| C5| D5|</span><br><span class="line">                                +---+---+---+---+---+---+---+</span><br></pre></td></tr></table></figure>

<p><strong>全连接</strong></p>
<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftp.merge(rightp,on=<span class="string">'A'</span>,how=<span class="string">'full'</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">lefts.join(rights,on=<span class="string">'A'</span>,how=<span class="string">'full'</span>)</span><br><span class="line">     .orderBy(<span class="string">'A'</span>,ascending=<span class="literal">True</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">                                        +---+----+----+----+----+----+----+</span><br><span class="line">                                        |  A|   B|   C|   D|   F|   G|   H|</span><br><span class="line">    A    B    C    D    F    G    H     +---+----+----+----+----+----+----+</span><br><span class="line"><span class="number">0</span>  A0   B0   C0   D0   B4   C4   D4     | A0|  B0|  C0|  D0|  B4|  C4|  D4|</span><br><span class="line"><span class="number">1</span>  A1   B1   C1   D1   B5   C5   D5     | A1|  B1|  C1|  D1|  B5|  C5|  D5|</span><br><span class="line"><span class="number">2</span>  A2   B2   C2   D2  NaN  NaN  NaN     | A2|  B2|  C2|  D2|null|null|null|</span><br><span class="line"><span class="number">3</span>  A3   B3   C3   D3  NaN  NaN  NaN     | A3|  B3|  C3|  D3|null|null|null|</span><br><span class="line"><span class="number">4</span>  A6  NaN  NaN  NaN   B6   C6   D6     | A6|null|null|null|  B6|  C6|  D6|</span><br><span class="line"><span class="number">5</span>  A7  NaN  NaN  NaN   B7   C7   D7     | A7|null|null|null|  B7|  C7|  D7|</span><br><span class="line">                                        +---+----+----+----+----+----+----+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-13-连接列"><a href="#5-3-13-连接列" class="headerlink" title="5.3.13. 连接列"></a>5.3.13. 连接列</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">my_list = [(<span class="string">'a'</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">           (<span class="string">'b'</span>, <span class="number">5</span>, <span class="number">6</span>),</span><br><span class="line">           (<span class="string">'c'</span>, <span class="number">8</span>, <span class="number">9</span>),</span><br><span class="line">           (<span class="string">'a'</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">           (<span class="string">'b'</span>, <span class="number">5</span>, <span class="number">6</span>),</span><br><span class="line">           (<span class="string">'c'</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line">col_name = [<span class="string">'col1'</span>, <span class="string">'col2'</span>, <span class="string">'col3'</span>]</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">dp = pd.DataFrame(my_list,columns=col_name)</span><br><span class="line">ds = spark.createDataFrame(my_list,schema=col_name)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  col1  col2  col3</span><br><span class="line"><span class="number">0</span>    a     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line"><span class="number">1</span>    b     <span class="number">5</span>     <span class="number">6</span></span><br><span class="line"><span class="number">2</span>    c     <span class="number">8</span>     <span class="number">9</span></span><br><span class="line"><span class="number">3</span>    a     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line"><span class="number">4</span>    b     <span class="number">5</span>     <span class="number">6</span></span><br><span class="line"><span class="number">5</span>    c     <span class="number">8</span>     <span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'concat'</span>] = dp.apply(<span class="keyword">lambda</span> x:<span class="string">'%s%s'</span>%(x[<span class="string">'col1'</span>],x[<span class="string">'col2'</span>]),axis=<span class="number">1</span>)</span><br><span class="line">dp</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.withColumn(<span class="string">'concat'</span>,F.concat(<span class="string">'col1'</span>,<span class="string">'col2'</span>)).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">                                        +----+----+----+------+</span><br><span class="line">                                        |col1|col2|col3|concat|</span><br><span class="line">  col1  col2  col3 concat               +----+----+----+------+</span><br><span class="line"><span class="number">0</span>    a     <span class="number">2</span>     <span class="number">3</span>     a2               |   a|   <span class="number">2</span>|   <span class="number">3</span>|    a2|</span><br><span class="line"><span class="number">1</span>    b     <span class="number">5</span>     <span class="number">6</span>     b5               |   b|   <span class="number">5</span>|   <span class="number">6</span>|    b5|</span><br><span class="line"><span class="number">2</span>    c     <span class="number">8</span>     <span class="number">9</span>     c8               |   c|   <span class="number">8</span>|   <span class="number">9</span>|    c8|</span><br><span class="line"><span class="number">3</span>    a     <span class="number">2</span>     <span class="number">3</span>     a2               |   a|   <span class="number">2</span>|   <span class="number">3</span>|    a2|</span><br><span class="line"><span class="number">4</span>    b     <span class="number">5</span>     <span class="number">6</span>     b5               |   b|   <span class="number">5</span>|   <span class="number">6</span>|    b5|</span><br><span class="line"><span class="number">5</span>    c     <span class="number">8</span>     <span class="number">9</span>     c8               |   c|   <span class="number">8</span>|   <span class="number">9</span>|    c8|</span><br><span class="line">                                        +----+----+----+------+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-14-分组"><a href="#5-3-14-分组" class="headerlink" title="5.3.14. 分组"></a>5.3.14. 分组</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp.groupby([<span class="string">'col1'</span>]).agg(&#123;<span class="string">'col2'</span>:<span class="string">'min'</span>,<span class="string">'col3'</span>:<span class="string">'mean'</span>&#125;)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.groupBy([<span class="string">'col1'</span>]).agg(&#123;<span class="string">'col2'</span>: <span class="string">'min'</span>, <span class="string">'col3'</span>: <span class="string">'avg'</span>&#125;).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                        +----+---------+---------+</span><br><span class="line">      col2  col3                        |col1|min(col2)|avg(col3)|</span><br><span class="line">col1                                    +----+---------+---------+</span><br><span class="line">a        <span class="number">2</span>     <span class="number">3</span>                        |   c|        <span class="number">8</span>|      <span class="number">9.0</span>|</span><br><span class="line">b        <span class="number">5</span>     <span class="number">6</span>                        |   b|        <span class="number">5</span>|      <span class="number">6.0</span>|</span><br><span class="line">c        <span class="number">8</span>     <span class="number">9</span>                        |   a|        <span class="number">2</span>|      <span class="number">3.0</span>|</span><br><span class="line">                                        +----+---------+---------+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-15-透视"><a href="#5-3-15-透视" class="headerlink" title="5.3.15. 透视"></a>5.3.15. 透视</h3><p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.pivot_table(dp, values=<span class="string">'col3'</span>, index=<span class="string">'col1'</span>, columns=<span class="string">'col2'</span>, aggfunc=np.sum)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ds.groupBy([<span class="string">'col1'</span>]).pivot(<span class="string">'col2'</span>).sum(<span class="string">'col3'</span>).show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                +----+----+----+----+</span><br><span class="line">col2    <span class="number">2</span>     <span class="number">5</span>     <span class="number">8</span>           |col1|   <span class="number">2</span>|   <span class="number">5</span>|   <span class="number">8</span>|</span><br><span class="line">col1                            +----+----+----+----+</span><br><span class="line">a     <span class="number">6.0</span>   NaN   NaN           |   c|null|null|  <span class="number">18</span>|</span><br><span class="line">b     NaN  <span class="number">12.0</span>   NaN           |   b|null|  <span class="number">12</span>|null|</span><br><span class="line">c     NaN   NaN  <span class="number">18.0</span>           |   a|   <span class="number">6</span>|null|null|</span><br><span class="line">                                +----+----+----+----+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-16-窗口"><a href="#5-3-16-窗口" class="headerlink" title="5.3.16. 窗口"></a>5.3.16. 窗口</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'A'</span>:[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>],<span class="string">'B'</span>:[<span class="string">'m'</span>,<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'n'</span>],<span class="string">'C'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>]&#125;</span><br><span class="line">dp = pd.DataFrame(d)</span><br><span class="line">ds = spark.createDataFrame(dp)</span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'rank'</span>] = dp.groupby(<span class="string">'B'</span>)[<span class="string">'C'</span>].rank(<span class="string">'dense'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.window <span class="keyword">import</span> Window</span><br><span class="line">w = Window.partitionBy(<span class="string">'B'</span>).orderBy(ds.C.desc())</span><br><span class="line">ds = ds.withColumn(<span class="string">'rank'</span>,F.rank().over(w))</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">                        +---+---+---+----+</span><br><span class="line">                        |  A|  B|  C|rank|</span><br><span class="line">   A  B  C  rank        +---+---+---+----+</span><br><span class="line"><span class="number">0</span>  a  m  <span class="number">1</span>   <span class="number">2.0</span>        |  b|  m|  <span class="number">2</span>|   <span class="number">1</span>|</span><br><span class="line"><span class="number">1</span>  b  m  <span class="number">2</span>   <span class="number">1.0</span>        |  a|  m|  <span class="number">1</span>|   <span class="number">2</span>|</span><br><span class="line"><span class="number">2</span>  c  n  <span class="number">3</span>   <span class="number">2.0</span>        |  d|  n|  <span class="number">6</span>|   <span class="number">1</span>|</span><br><span class="line"><span class="number">3</span>  d  n  <span class="number">6</span>   <span class="number">1.0</span>        |  c|  n|  <span class="number">3</span>|   <span class="number">2</span>|</span><br><span class="line">                        +---+---+---+----+</span><br></pre></td></tr></table></figure>

<h3 id="5-3-17-rank-VS-dense-rank"><a href="#5-3-17-rank-VS-dense-rank" class="headerlink" title="5.3.17. rank VS dense_rank"></a>5.3.17. <code>rank</code> VS <code>dense_rank</code></h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d =&#123;<span class="string">'Id'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line">    <span class="string">'Score'</span>: [<span class="number">4.00</span>, <span class="number">4.00</span>, <span class="number">3.85</span>, <span class="number">3.65</span>, <span class="number">3.65</span>, <span class="number">3.50</span>]&#125;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">data = pd.DataFrame(d)</span><br><span class="line">dp = data.copy()</span><br><span class="line">ds = spark.createDataFrame(data)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">   Id  Score</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>   <span class="number">4.00</span></span><br><span class="line"><span class="number">1</span>   <span class="number">2</span>   <span class="number">4.00</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>   <span class="number">3.85</span></span><br><span class="line"><span class="number">3</span>   <span class="number">4</span>   <span class="number">3.65</span></span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>   <span class="number">3.65</span></span><br><span class="line"><span class="number">5</span>   <span class="number">6</span>   <span class="number">3.50</span></span><br></pre></td></tr></table></figure>

<p>Python 代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="string">'Rank_dense'</span>] = dp[<span class="string">'Score'</span>].rank(method=<span class="string">'dense'</span>,ascending =<span class="literal">False</span>)</span><br><span class="line">dp[<span class="string">'Rank'</span>] = dp[<span class="string">'Score'</span>].rank(method=<span class="string">'min'</span>,ascending =<span class="literal">False</span>)</span><br><span class="line">dp</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.window <span class="keyword">import</span> Window</span><br><span class="line">w = Window.orderBy(ds.Score.desc())</span><br><span class="line">ds = ds.withColumn(<span class="string">'Rank_spark_dense'</span>,F.dense_rank().over(w))</span><br><span class="line">ds = ds.withColumn(<span class="string">'Rank_spark'</span>,F.rank().over(w))</span><br><span class="line">ds.show()</span><br></pre></td></tr></table></figure>

<p>比较：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">                                +---+-----+----------------+----------+</span><br><span class="line">                                | Id|Score|Rank_spark_dense|Rank_spark|</span><br><span class="line">   Id  Score  Rank_dense  Rank  +---+-----+----------------+----------+</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>   <span class="number">4.00</span>         <span class="number">1.0</span>   <span class="number">1.0</span>  |  <span class="number">1</span>|  <span class="number">4.0</span>|               <span class="number">1</span>|         <span class="number">1</span>|</span><br><span class="line"><span class="number">1</span>   <span class="number">2</span>   <span class="number">4.00</span>         <span class="number">1.0</span>   <span class="number">1.0</span>  |  <span class="number">2</span>|  <span class="number">4.0</span>|               <span class="number">1</span>|         <span class="number">1</span>|</span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>   <span class="number">3.85</span>         <span class="number">2.0</span>   <span class="number">3.0</span>  |  <span class="number">3</span>| <span class="number">3.85</span>|               <span class="number">2</span>|         <span class="number">3</span>|</span><br><span class="line"><span class="number">3</span>   <span class="number">4</span>   <span class="number">3.65</span>         <span class="number">3.0</span>   <span class="number">4.0</span>  |  <span class="number">4</span>| <span class="number">3.65</span>|               <span class="number">3</span>|         <span class="number">4</span>|</span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>   <span class="number">3.65</span>         <span class="number">3.0</span>   <span class="number">4.0</span>  |  <span class="number">5</span>| <span class="number">3.65</span>|               <span class="number">3</span>|         <span class="number">4</span>|</span><br><span class="line"><span class="number">5</span>   <span class="number">6</span>   <span class="number">3.50</span>         <span class="number">4.0</span>   <span class="number">6.0</span>  |  <span class="number">6</span>|  <span class="number">3.5</span>|               <span class="number">4</span>|         <span class="number">6</span>|</span><br><span class="line">                                +---+-----+----------------+----------+</span><br></pre></td></tr></table></figure>

<h1 id="6-统计与线性代数预备"><a href="#6-统计与线性代数预备" class="headerlink" title="6. 统计与线性代数预备"></a>6. 统计与线性代数预备</h1><p><strong>知彼知己，百战不殆；不知彼而知己，一胜一负；不知彼，不知己，每战必殆。</strong> – 《孙子兵法》</p>
<h2 id="6-1-表示法"><a href="#6-1-表示法" class="headerlink" title="6.1. 表示法"></a>6.1. 表示法</h2><ul>
<li>m：样本数</li>
<li>n：特征数</li>
<li><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/8f58cf98a539286a53e41582f194fbed.jpg" alt="y_i">：第<code>i</code>个标签</li>
<li><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/585d98b9749f0661bc9077e01f28eb15.jpg" alt="\hat{y}_i">：第<code>i</code>个预测标签</li>
<li><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/791424a3e5f6e2f4372471d96e5b4676.jpg" alt="{\displaystyle {\bar {\y}}} = {\frac {1}{m}}\sum _{i=1}^{m}y_{i}">：<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/afa87c5126806e604709f243ab72848b.jpg" alt="\y"> 的均值</li>
<li><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/afa87c5126806e604709f243ab72848b.jpg" alt="\y">：标签向量</li>
<li><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/bab25b7785bf747bc1caa1442874df74.jpg" alt="\hat{\y}">：预测标签向量</li>
</ul>
<h2 id="6-2-线性代数预备"><a href="#6-2-线性代数预备" class="headerlink" title="6.2. 线性代数预备"></a>6.2. 线性代数预备</h2><p>由于我在我的数值分析考试笔记中记录了线性代数预备，有兴趣的读者可以参考 <a href="reference.html#feng2014">[Feng2014]</a>了解更多细节。</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c089ca6ef2f36b0394d7bcf41db78030.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/linear_algebra.png"></p>
<p>线性代数预备</p>
<h2 id="6-3-测量公式"><a href="#6-3-测量公式" class="headerlink" title="6.3. 测量公式"></a>6.3. 测量公式</h2><h3 id="6-3-1-平均绝对误差"><a href="#6-3-1-平均绝对误差" class="headerlink" title="6.3.1. 平均绝对误差"></a>6.3.1. 平均绝对误差</h3><p>在统计学中，<strong>MAE</strong>（<a href="https://en.wikipedia.org/wiki/Mean_absolute_error" target="_blank" rel="noopener">平均绝对误差</a>）衡量两个连续变量间的差异。 平均绝对误差由下式给出：</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/61bccf1d55cc6636fce9585573c9981a.jpg" alt="{\displaystyle \mathrm {MAE} ={\frac{1}{m} {\sum _{i=1}^{m}\left|\hat{y}_i-y_i\right|}}.}"></p>
<h3 id="6-3-2-均方误差"><a href="#6-3-2-均方误差" class="headerlink" title="6.3.2. 均方误差"></a>6.3.2. 均方误差</h3><p>在统计中，估计器（估计未观测量的过程）的 <strong>MSE</strong>（<a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_blank" rel="noopener">均方误差</a>）测量了误差或偏差的平方的平均值 - 即估计器与被估计值之间的差异。</p>
<p><img src="img/3152173a8fd696819c7a2c2b8c6ef005.jpg" alt="\text{MSE}=\frac{1}{m}\sum_{i=1}^m\left(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/3152173a8fd696819c7a2c2b8c6ef005.jpg)^2"></p>
<h3 id="6-3-3-均方根误差"><a href="#6-3-3-均方根误差" class="headerlink" title="6.3.3. 均方根误差"></a>6.3.3. 均方根误差</h3><p><img src="img/c8a2ccec457f128649ad30a2ba066a48.jpg" alt="\text{RMSE} = \sqrt{\text{MSE}}=\sqrt{\frac{1}{m}\sum_{i=1}^m\left(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c8a2ccec457f128649ad30a2ba066a48.jpg)^2}"></p>
<h3 id="6-3-4-总体平方和"><a href="#6-3-4-总体平方和" class="headerlink" title="6.3.4. 总体平方和"></a>6.3.4. 总体平方和</h3><p>在统计数据分析中，<strong>TSS</strong>（<a href="https://en.wikipedia.org/wiki/Total_sum_of_squares" target="_blank" rel="noopener">总体平方和</a>）是一个数量，作为呈现此类分析结果的标准方式的一部分。 它被定义为在所有观察中，每个观测值与总体平均值的平方差的总和。</p>
<p><img src="img/16fd7a4c078cf22fee09b636dc10d55c.jpg" alt="\text{TSS} =  \sum_{i=1}^m\left(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/16fd7a4c078cf22fee09b636dc10d55c.jpg)^2"></p>
<h3 id="6-3-5-解释平方和"><a href="#6-3-5-解释平方和" class="headerlink" title="6.3.5. 解释平方和"></a>6.3.5. 解释平方和</h3><p>在统计学中，<strong>ESS</strong>（<a href="https://en.wikipedia.org/wiki/Explained_sum_of_squares" target="_blank" rel="noopener">解释平方和</a>），或者称为模型平方和或回归平方和。</p>
<p>ESS 是预测值和响应变量的均值的差的平方和，由下式给出：</p>
<p><img src="img/8dc8e70e19ec4318b12b16f1c5bdb879.jpg" alt="\text{ESS}= \sum_{i=1}^m\left(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/8dc8e70e19ec4318b12b16f1c5bdb879.jpg)^2"></p>
<h3 id="6-3-6-残差平方和"><a href="#6-3-6-残差平方和" class="headerlink" title="6.3.6. 残差平方和"></a>6.3.6. 残差平方和</h3><p>在统计中，<strong>RSS/SSR</strong>（<a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares" target="_blank" rel="noopener">残差平方和</a>），也称为预测误差平方和 预测（SSE），由下式给出：</p>
<p><img src="img/95594348fc6d49d2819be3d412a27e55.jpg" alt="\text{RSS}= \sum_{i=1}^m\left(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/95594348fc6d49d2819be3d412a27e55.jpg)^2"></p>
<h3 id="6-3-7-判定系数"><a href="#6-3-7-判定系数" class="headerlink" title="6.3.7. 判定系数 "></a>6.3.7. 判定系数 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg" alt="R^2"></h3><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/fef76f108c095f250d8e9efb4cfcb710.jpg" alt="R^{2} := \frac{ESS}{TSS} = 1-{\text{RSS} \over \text{TSS}}.\,"></p>
<blockquote>
<p>注意</p>
<p>一般来说，(<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b288f19072faa2f8f373d5a8910c080b.jpg" alt="\y^{T}{\bar {\y}}={\hat {\y}}^{T}{\bar {\y}}">)，总体平方和，等于解释平方和加上残差平方和，也就是：</p>
</blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4a1a112aa8490f7c8410b710845e8c7a.jpg" alt="\text{TSS} = \text{ESS} + \text{RSS} \text{ if and only if } {\displaystyle \y^{T}{\bar {\y}}={\hat {\y}}^{T}{\bar {\y}}}."></p>
<p>更多细节可以在<a href="https://en.wikipedia.org/wiki/Explained_sum_of_squares" target="_blank" rel="noopener">普通最小二乘模型中的分区</a>中找到。</p>
<h2 id="6-4-混淆矩阵"><a href="#6-4-混淆矩阵" class="headerlink" title="6.4. 混淆矩阵"></a>6.4. 混淆矩阵</h2><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c789e9bbaa3506dc90047b5cd487a42a.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/confusion_matrix.png"></p>
<p>混淆矩阵</p>
<h3 id="6-4-1-召回率"><a href="#6-4-1-召回率" class="headerlink" title="6.4.1. 召回率"></a>6.4.1. 召回率</h3><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/3f26c9365c0603f014f3bba403ed27fb.jpg" alt="\text{Recall}=\frac{\text{TP}}{\text{TP+FN}}"></p>
<h3 id="6-4-2-精确率"><a href="#6-4-2-精确率" class="headerlink" title="6.4.2. 精确率"></a>6.4.2. 精确率</h3><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1a8a8647a66b744ccd5c9137adb66255.jpg" alt="\text{Precision}=\frac{\text{TP}}{\text{TP+FP}}"></p>
<h3 id="6-4-3-准确率"><a href="#6-4-3-准确率" class="headerlink" title="6.4.3. 准确率"></a>6.4.3. 准确率</h3><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/5a13655c0030372e1b06cd77ff1e53e0.jpg" alt="\text{Accuracy }=\frac{\text{TP+TN}}{\text{Total}}"></p>
<h3 id="6-4-4-F1-得分"><a href="#6-4-4-F1-得分" class="headerlink" title="6.4.4. F1 得分"></a>6.4.4. F1 得分</h3><p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1cef776388e6c2cba3cf00cab2199e3d.jpg" alt="\text{F}_1=\frac{2*\text{Recall}*\text{Precision}}{\text{Recall}+ \text{Precision}}"></p>
<h2 id="6-5-统计检验"><a href="#6-5-统计检验" class="headerlink" title="6.5. 统计检验"></a>6.5. 统计检验</h2><h3 id="6-5-1-互相关检验"><a href="#6-5-1-互相关检验" class="headerlink" title="6.5.1. 互相关检验"></a>6.5.1. 互相关检验</h3><ul>
<li>Pearson 互相关: 检验两个连续变量之间的相关度。</li>
<li>Spearman 互相关: 检验两个序数变量之间的相关度（不依赖于正态分布数据的假设）。</li>
<li>卡方: 检验两个类别变量之间的相关度。</li>
</ul>
<h3 id="6-5-2-均值检验的比较"><a href="#6-5-2-均值检验的比较" class="headerlink" title="6.5.2. 均值检验的比较"></a>6.5.2. 均值检验的比较</h3><ul>
<li>配对 T 检验: 检验两个相关变量之间的差异</li>
<li>独立 T 检验: 检验两个独立变量之间的差异</li>
<li>ANOVA: 在考虑结果变量中的任何其他变化之后，检验组均值之间的差异。</li>
</ul>
<h3 id="6-5-3-非配对检验"><a href="#6-5-3-非配对检验" class="headerlink" title="6.5.3. 非配对检验"></a>6.5.3. 非配对检验</h3><ul>
<li>Wilcoxon 秩和检验: 检验两个独立变量之间的差异 - 考虑差异的大小和方向。</li>
<li>Wilcoxon 符号秩检验: 检验两个相关变量之间的差异 - 考虑差异的大小和方向。</li>
<li>符号检验: 检验两个相关变量是否不同 - 忽略变化大小，仅考虑方向。</li>
</ul>
<h1 id="7-数据探索"><a href="#7-数据探索" class="headerlink" title="7. 数据探索"></a>7. 数据探索</h1><p><strong>千里之行，始于足下。</strong> – 《老子》</p>
<p>我不是说，理解你的数据集是数据科学中最困难的事情，但它非常重要且耗时。 数据探索是通过统计和可视化技术来描述数据。 我们探索数据来了解特征并将其带到我们的模型。</p>
<h2 id="7-1-单变量分析"><a href="#7-1-单变量分析" class="headerlink" title="7.1. 单变量分析"></a>7.1. 单变量分析</h2><p>在数学中，单变量是指仅含一个变量的表达式，方程式，函数或多项式。 “Uni”表示“一个”，换句话说，您的数据只有一个变量。 因此，您无需在此步骤中处理原因或关系。单变量分析获取数据，逐个汇总变量（属性）并发现数据中的模式。</p>
<p>单变量数据中发现的模式可以通过多种方式描述，包括集中趋势（均值，众数和中值）和离散度：极差，方差，最大值，最小值，四分位数（包括四分位数极差），方差和标准差。 您还可以使用多个选项来视化和描述单变量数据。 如<code>频率分布表</code>，<code>条形图</code>，<code>直方图</code>，<code>频率多边形</code>，<code>扇形图</code>。</p>
<p>变量可以是分类变量或数值变量，我将演示不同的统计和可视化技术来研究变量的每种类型。</p>
<ul>
<li>Jupyter 笔记本可以从<a href="_static/Data_exploration.ipynb">数据探索</a>下载。</li>
<li>数据可以从 <a href="_static/german_credit.csv">German Credit</a> 下载。</li>
</ul>
<h3 id="7-1-1-数值变量"><a href="#7-1-1-数值变量" class="headerlink" title="7.1.1. 数值变量"></a>7.1.1. 数值变量</h3><p><strong>描述</strong></p>
<p><code>pandas</code>和<code>spark</code>中的<code>describe</code>函数将给出大部分统计结果，例如最小值，中值，最大值，四分位数和标准差。 借助用户定义的函数，您可以获得更多的统计结果。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为选择要展示的变量</span></span><br><span class="line">num_cols = [<span class="string">'Account Balance'</span>,<span class="string">'No of dependents'</span>]</span><br><span class="line">df.select(num_cols).describe().show()</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-------+------------------+-------------------+</span><br><span class="line">|summary|   Account Balance|   No of dependents|</span><br><span class="line">+-------+------------------+-------------------+</span><br><span class="line">|  count|              <span class="number">1000</span>|               <span class="number">1000</span>|</span><br><span class="line">|   mean|             <span class="number">2.577</span>|              <span class="number">1.155</span>|</span><br><span class="line">| stddev|<span class="number">1.2576377271108936</span>|<span class="number">0.36208577175319395</span>|</span><br><span class="line">|    min|                 <span class="number">1</span>|                  <span class="number">1</span>|</span><br><span class="line">|    max|                 <span class="number">4</span>|                  <span class="number">2</span>|</span><br><span class="line">+-------+------------------+-------------------+</span><br></pre></td></tr></table></figure>

<p>您可能会发现 PySpark 中的默认函数不包含四分位数。 以下函数将帮助您在 Pandas 中获得相同的结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">describe_pd</span><span class="params">(df_in, columns, deciles=False)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Function to union the basic stats results and deciles</span></span><br><span class="line"><span class="string">    :param df_in: the input dataframe</span></span><br><span class="line"><span class="string">    :param columns: the cloumn name list of the numerical variable</span></span><br><span class="line"><span class="string">    :param deciles: the deciles output</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return : the numerical describe info. of the input dataframe</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :author: Ming Chen and Wenqiang Feng</span></span><br><span class="line"><span class="string">    :email:  von198@gmail.com</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> deciles:</span><br><span class="line">        percentiles = np.array(range(<span class="number">0</span>, <span class="number">110</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        percentiles = [<span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>]</span><br><span class="line"></span><br><span class="line">    percs = np.transpose([np.percentile(df_in.select(x).collect(), percentiles) <span class="keyword">for</span> x <span class="keyword">in</span> columns])</span><br><span class="line">    percs = pd.DataFrame(percs, columns=columns)</span><br><span class="line">    percs[<span class="string">'summary'</span>] = [str(p) + <span class="string">'%'</span> <span class="keyword">for</span> p <span class="keyword">in</span> percentiles]</span><br><span class="line"></span><br><span class="line">    spark_describe = df_in.describe().toPandas()</span><br><span class="line">    new_df = pd.concat([spark_describe, percs],ignore_index=<span class="literal">True</span>)</span><br><span class="line">    new_df = new_df.round(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> new_df[[<span class="string">'summary'</span>] + columns]</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe_pd(df,num_cols)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+-------+------------------+-----------------+</span><br><span class="line">|summary|   Account Balance| No of dependents|</span><br><span class="line">+-------+------------------+-----------------+</span><br><span class="line">|  count|            <span class="number">1000.0</span>|           <span class="number">1000.0</span>|</span><br><span class="line">|   mean|             <span class="number">2.577</span>|            <span class="number">1.155</span>|</span><br><span class="line">| stddev|<span class="number">1.2576377271108936</span>|<span class="number">0.362085771753194</span>|</span><br><span class="line">|    min|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    max|               <span class="number">4.0</span>|              <span class="number">2.0</span>|</span><br><span class="line">|    <span class="number">25</span>%|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">50</span>%|               <span class="number">2.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">75</span>%|               <span class="number">4.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">+-------+------------------+-----------------+</span><br></pre></td></tr></table></figure>

<p>有时，由于机密数据问题，您无法提供真实数据，您的客户可能会请求更多统计结果，例如“十分位数”。 您可以应用以下函数来实现它。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe_pd(df,num_cols,deciles=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">+-------+------------------+-----------------+</span><br><span class="line">|summary|   Account Balance| No of dependents|</span><br><span class="line">+-------+------------------+-----------------+</span><br><span class="line">|  count|            <span class="number">1000.0</span>|           <span class="number">1000.0</span>|</span><br><span class="line">|   mean|             <span class="number">2.577</span>|            <span class="number">1.155</span>|</span><br><span class="line">| stddev|<span class="number">1.2576377271108936</span>|<span class="number">0.362085771753194</span>|</span><br><span class="line">|    min|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    max|               <span class="number">4.0</span>|              <span class="number">2.0</span>|</span><br><span class="line">|     <span class="number">0</span>%|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">10</span>%|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">20</span>%|               <span class="number">1.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">30</span>%|               <span class="number">2.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">40</span>%|               <span class="number">2.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">50</span>%|               <span class="number">2.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">60</span>%|               <span class="number">3.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">70</span>%|               <span class="number">4.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">80</span>%|               <span class="number">4.0</span>|              <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">90</span>%|               <span class="number">4.0</span>|              <span class="number">2.0</span>|</span><br><span class="line">|   <span class="number">100</span>%|               <span class="number">4.0</span>|              <span class="number">2.0</span>|</span><br><span class="line">+-------+------------------+-----------------+</span><br></pre></td></tr></table></figure>

<ul>
<li><p>偏度和峰度</p>
<p>这个小节来自维基百科<a href="https://en.wikipedia.org/wiki/Skewness" target="_blank" rel="noopener">偏度</a>。</p>
<p>在概率论和统计学中，偏度是实值随机变量概率分布关于其均值的不对称性的度量。 偏度值可以是正数或负数，或者是未定义的。对于单峰分布，负偏度通常表示尾部位于分布的左侧，而正偏度表示尾部位于右侧。</p>
<p>考虑下图中的两个分布。 在每个图中，分布右侧的值与左侧的值不同。 这些逐渐变细的一端称为尾部，它们提供了一种可视方法来确定分布中的两种偏斜中的哪一种：</p>
<ol>
<li>负偏度：左尾较长；分布的质量集中在图的右侧。尽管曲线本身看起来是向右倾斜的，但这种分布成为左倾的。左是指尾部向左侧延伸，并且通常，平均值偏向数据的典型中心的左侧。 左倾分布通常表现为右倾曲线。</li>
<li>正偏度：右尾更长; 分布的质量集中在图的左侧。尽管曲线本身看起来是向左倾斜的，但这种分布成为右倾的。右边是指尾部向右侧延伸，通常，平均值偏向于典型数据中心的右侧。 右倾分布通常表现为左倾曲线。</li>
</ol>
<p>这一小节来自维基百科<a href="https://en.wikipedia.org/wiki/Kurtosis" target="_blank" rel="noopener">峰度</a>。</p>
<p>在概率论和统计学中，峰度（kyrtos 或 kurtos，意思是“弯曲的，拱形的”）是实值随机变量的概率分布的“尾部”的度量。 与偏度概念类似，峰度描述概率分布形状，正如偏度一样，有不同的方法来量化它的理论分布，和相应的方法来估计它来自一个样本总体。</p>
</li>
</ul>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/6eb508bad184c89094f5045a5bf2e31c.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/skewed.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col, skewness, kurtosis</span><br><span class="line">df.select(skewness(var),kurtosis(var)).show()</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+---------------------+---------------------+</span><br><span class="line">|skewness(Age (years))|kurtosis(Age (years))|</span><br><span class="line">+---------------------+---------------------+</span><br><span class="line">|   <span class="number">1.0231743160548064</span>|   <span class="number">0.6114371688367672</span>|</span><br><span class="line">+---------------------+---------------------+</span><br></pre></td></tr></table></figure>

<blockquote>
<p>警告</p>
</blockquote>
<p><strong>有时统计量可能产生误导！</strong></p>
<p>F. J. Anscombe 曾经说到执行计算和制作图表。 应研究两种结果；每个都有助于理解。 图<a href="#fig-misleading">相同统计量的不同图表</a>（Datasaurus，和 12 个其他东西）中的这 13 个数据集各自具有相同的汇总统计量（<code>x/y</code>均值，<code>x/y</code>标准差和 Pearson 相关性），虽然外观完全不同。 这项工作描述了我们开发的技术，用于创建此数据集，以及其他类似的数据集。 更多细节和有趣的结果可以在<a href="https://www.autodeskresearch.com/publications/samestats" target="_blank" rel="noopener">相同统计量和不同图表</a>中找到。</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4fb175e4e5682ef75a156dfba37beeea.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/misleading.png"></p>
<p>相同统计量和不同图表</p>
<p><strong>直方图</strong></p>
<blockquote>
<p>警告</p>
<p><strong>直方图经常和条形图混淆！</strong></p>
</blockquote>
<p>直方图和条形图之间的根本区别，将帮助您轻松识别两者，条形图中的条形之间存在间隙，但在直方图中，条形彼此相邻。 感兴趣的读者可以参考<a href="https://keydifferences.com/difference-between-histogram-and-bar-graph.html" target="_blank" rel="noopener">直方图和条形图之间的差异</a>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">var = <span class="string">'Age (years)'</span></span><br><span class="line">x = data1[var]</span><br><span class="line">bins = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line"><span class="comment"># 数据直方图</span></span><br><span class="line">plt.hist(x, bins, alpha=<span class="number">0.8</span>, histtype=<span class="string">'bar'</span>, color=<span class="string">'gold'</span>,</span><br><span class="line">         ec=<span class="string">'black'</span>,weights=np.zeros_like(x) + <span class="number">100</span>\. / x.size)</span><br><span class="line"></span><br><span class="line">plt.xlabel(var)</span><br><span class="line">plt.ylabel(<span class="string">'percentage'</span>)</span><br><span class="line">plt.xticks(bins)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig.savefig(var+<span class="string">".pdf"</span>, bbox_inches=<span class="string">'tight'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/0539212d2d3e4c28b27805e3c8783cab.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/his_s.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">var = <span class="string">'Age (years)'</span></span><br><span class="line">x = data1[var]</span><br><span class="line">bins = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################################</span></span><br><span class="line">hist, bin_edges = np.histogram(x,bins,</span><br><span class="line">                               weights=np.zeros_like(x) + <span class="number">100</span>\. / x.size)</span><br><span class="line"><span class="comment"># 生成直方图</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制高度与 x 轴上的整数的直方图</span></span><br><span class="line">ax.bar(range(len(hist)),hist,width=<span class="number">1</span>,alpha=<span class="number">0.8</span>,ec =<span class="string">'black'</span>, color=<span class="string">'gold'</span>)</span><br><span class="line"><span class="comment"># 将刻度设在条形中间</span></span><br><span class="line">ax.set_xticks([<span class="number">0.5</span>+i <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)])</span><br><span class="line"><span class="comment"># 将 xticklabels 设置为一个字符串，告诉我们桶的边缘是什么</span></span><br><span class="line">labels =[<span class="string">'&#123;&#125;'</span>.format(int(bins[i+<span class="number">1</span>])) <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)]</span><br><span class="line">labels.insert(<span class="number">0</span>,<span class="string">'0'</span>)</span><br><span class="line">ax.set_xticklabels(labels)</span><br><span class="line">plt.xlabel(var)</span><br><span class="line">plt.ylabel(<span class="string">'percentage'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################################</span></span><br><span class="line"></span><br><span class="line">hist, bin_edges = np.histogram(x,bins) <span class="comment"># 生成直方图</span></span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 绘制高度与 x 轴上的整数的直方图</span></span><br><span class="line">ax.bar(range(len(hist)),hist,width=<span class="number">1</span>,alpha=<span class="number">0.8</span>,ec =<span class="string">'black'</span>, color=<span class="string">'gold'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将刻度设在条形中间</span></span><br><span class="line">ax.set_xticks([<span class="number">0.5</span>+i <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 xticklabels 设置为一个字符串，告诉我们桶的边缘是什么</span></span><br><span class="line">labels =[<span class="string">'&#123;&#125;'</span>.format(int(bins[i+<span class="number">1</span>])) <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)]</span><br><span class="line">labels.insert(<span class="number">0</span>,<span class="string">'0'</span>)</span><br><span class="line">ax.set_xticklabels(labels)</span><br><span class="line">plt.xlabel(var)</span><br><span class="line">plt.ylabel(<span class="string">'count'</span>)</span><br><span class="line">plt.suptitle(<span class="string">'Histogram of &#123;&#125;: Left with percentage output;Right with count output'</span></span><br><span class="line">             .format(var), size=<span class="number">16</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig.savefig(var+<span class="string">".pdf"</span>, bbox_inches=<span class="string">'tight'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/2a4a130bcfb223ced98c0de613bd076a.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/his_d.png"></p>
<p>有时，有些人会要求您绘制不等宽度的条形（直方图的无效参数）。 你仍然可以通过以下方法实现它。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">var = <span class="string">'Credit Amount'</span></span><br><span class="line">plot_data = df.select(var).toPandas()</span><br><span class="line">x= plot_data[var]</span><br><span class="line"></span><br><span class="line">bins =[<span class="number">0</span>,<span class="number">200</span>,<span class="number">400</span>,<span class="number">600</span>,<span class="number">700</span>,<span class="number">800</span>,<span class="number">900</span>,<span class="number">1000</span>,<span class="number">2000</span>,<span class="number">3000</span>,<span class="number">4000</span>,<span class="number">5000</span>,<span class="number">6000</span>,<span class="number">10000</span>,<span class="number">25000</span>]</span><br><span class="line"></span><br><span class="line">hist, bin_edges = np.histogram(x,bins,weights=np.zeros_like(x) + <span class="number">100</span>\. / x.size) <span class="comment"># make the histogram</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 绘制高度与 x 轴上的整数的直方图</span></span><br><span class="line">ax.bar(range(len(hist)),hist,width=<span class="number">1</span>,alpha=<span class="number">0.8</span>,ec =<span class="string">'black'</span>,color = <span class="string">'gold'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将刻度设在条形中间</span></span><br><span class="line">ax.set_xticks([<span class="number">0.5</span>+i <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 xticklabels 设置为一个字符串，告诉我们桶的边缘是什么</span></span><br><span class="line"><span class="comment">#labels =['&#123;&#125;k'.format(int(bins[i+1]/1000)) for i,j in enumerate(hist)]</span></span><br><span class="line">labels =[<span class="string">'&#123;&#125;'</span>.format(bins[i+<span class="number">1</span>]) <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(hist)]</span><br><span class="line">labels.insert(<span class="number">0</span>,<span class="string">'0'</span>)</span><br><span class="line">ax.set_xticklabels(labels)</span><br><span class="line"><span class="comment">#plt.text(-0.6, -1.4,'0')</span></span><br><span class="line">plt.xlabel(var)</span><br><span class="line">plt.ylabel(<span class="string">'percentage'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/cb63c877ea3af266bb0f5ad6ba5e0b1d.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/unequal.png"></p>
<p><strong>箱形图和提琴图</strong></p>
<p>请注意，虽然提琴图与 Tukey（1977）的箱形图密切相关，但提琴图可以显示比箱形图更多的信息。 当我们进行探索性分析时，没有样本的知识。 因此，样本分布不能假设为正态分布，并且通常当您获得大数据时，正态分布将在箱形图中显示一些溢出。</p>
<p>然而，对于较小的样本大小，提琴图可能会产生误导，其中即使在为标准正常数据生成时，密度图也可能显示出有趣的特征（以及其中的分组差异）。 一些作者建议样本量应大于 250（例如，<code>n&gt; 250</code>或理想情况甚至更大）。其中核密度图提供了分布的合理准确表示，可能表现诸如双峰性或其他形式的细微差别，它在箱形图中是不可见的或不太清楚。 更多细节可以在[箱形图和小提琴图的简单比较]中找到(<a href="https://figshare.com/articles/A_simple_comparison_of_box_plots_and_violin_plots/1544525)。" target="_blank" rel="noopener">https://figshare.com/articles/A_simple_comparison_of_box_plots_and_violin_plots/1544525)。</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = df.select(var).toPandas()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">ax = sns.boxplot(data=x)</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax = sns.violinplot(data=x)</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/0eb5759f21246505752043bb890ab6bf.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/box_vio.png"></p>
<h3 id="7-1-2-类别变量"><a href="#7-1-2-类别变量" class="headerlink" title="7.1.2. 类别变量"></a>7.1.2. 类别变量</h3><p>与数值变量相比，分类变量更容易进行探索。</p>
<p><strong>频率表</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> rank,sum,col</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Window</span><br><span class="line"></span><br><span class="line">window = Window.rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)</span><br><span class="line"><span class="comment"># withColumn('Percent %',F.format_string("%5.0f%%\n",col('Credit_num')*100/col('total'))).\</span></span><br><span class="line">tab = df.select([<span class="string">'age_class'</span>,<span class="string">'Credit Amount'</span>]).\</span><br><span class="line">   groupBy(<span class="string">'age_class'</span>).\</span><br><span class="line">   agg(F.count(<span class="string">'Credit Amount'</span>).alias(<span class="string">'Credit_num'</span>),</span><br><span class="line">       F.mean(<span class="string">'Credit Amount'</span>).alias(<span class="string">'Credit_avg'</span>),</span><br><span class="line">       F.min(<span class="string">'Credit Amount'</span>).alias(<span class="string">'Credit_min'</span>),</span><br><span class="line">       F.max(<span class="string">'Credit Amount'</span>).alias(<span class="string">'Credit_max'</span>)).\</span><br><span class="line">   withColumn(<span class="string">'total'</span>,sum(col(<span class="string">'Credit_num'</span>)).over(window)).\</span><br><span class="line">   withColumn(<span class="string">'Percent'</span>,col(<span class="string">'Credit_num'</span>)*<span class="number">100</span>/col(<span class="string">'total'</span>)).\</span><br><span class="line">   drop(col(<span class="string">'total'</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---------+----------+------------------+----------+----------+-------+</span><br><span class="line">|age_class|Credit_num|        Credit_avg|Credit_min|Credit_max|Percent|</span><br><span class="line">+---------+----------+------------------+----------+----------+-------+</span><br><span class="line">|    <span class="number">45</span><span class="number">-54</span>|       <span class="number">120</span>|<span class="number">3183.0666666666666</span>|       <span class="number">338</span>|     <span class="number">12612</span>|   <span class="number">12.0</span>|</span><br><span class="line">|      &lt;<span class="number">25</span>|       <span class="number">150</span>| <span class="number">2970.733333333333</span>|       <span class="number">276</span>|     <span class="number">15672</span>|   <span class="number">15.0</span>|</span><br><span class="line">|    <span class="number">55</span><span class="number">-64</span>|        <span class="number">56</span>| <span class="number">3493.660714285714</span>|       <span class="number">385</span>|     <span class="number">15945</span>|    <span class="number">5.6</span>|</span><br><span class="line">|    <span class="number">35</span><span class="number">-44</span>|       <span class="number">254</span>| <span class="number">3403.771653543307</span>|       <span class="number">250</span>|     <span class="number">15857</span>|   <span class="number">25.4</span>|</span><br><span class="line">|    <span class="number">25</span><span class="number">-34</span>|       <span class="number">397</span>| <span class="number">3298.823677581864</span>|       <span class="number">343</span>|     <span class="number">18424</span>|   <span class="number">39.7</span>|</span><br><span class="line">|      <span class="number">65</span>+|        <span class="number">23</span>|<span class="number">3210.1739130434785</span>|       <span class="number">571</span>|     <span class="number">14896</span>|    <span class="number">2.3</span>|</span><br><span class="line">+---------+----------+------------------+----------+----------+-------+</span><br></pre></td></tr></table></figure>

<p><strong>扇形图</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制的数据</span></span><br><span class="line">labels = plot_data.age_class</span><br><span class="line">sizes =  plot_data.Percent</span><br><span class="line">colors = [<span class="string">'gold'</span>, <span class="string">'yellowgreen'</span>, <span class="string">'lightcoral'</span>,<span class="string">'blue'</span>, <span class="string">'lightskyblue'</span>,<span class="string">'green'</span>,<span class="string">'red'</span>]</span><br><span class="line">explode = (<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)  <span class="comment"># explode 1st slice</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.pie(sizes, explode=explode, labels=labels, colors=colors,</span><br><span class="line">        autopct=<span class="string">'%1.1f%%'</span>, shadow=<span class="literal">True</span>, startangle=<span class="number">140</span>)</span><br><span class="line"></span><br><span class="line">plt.axis(<span class="string">'equal'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/38cff4d0c27588f71d4ed00223dcc4a2.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/pie.png"></p>
<p><strong>条形图</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">labels = plot_data.age_class</span><br><span class="line">missing = plot_data.Percent</span><br><span class="line">ind = [x <span class="keyword">for</span> x, _ <span class="keyword">in</span> enumerate(labels)]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.bar(ind, missing, width=<span class="number">0.8</span>, label=<span class="string">'missing'</span>, color=<span class="string">'gold'</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(ind, labels)</span><br><span class="line">plt.ylabel(<span class="string">"percentage"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/7f8b8ddc9f821d1c5a27849bc02e355f.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/bar.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">labels = [<span class="string">'missing'</span>, <span class="string">'&lt;25'</span>, <span class="string">'25-34'</span>, <span class="string">'35-44'</span>, <span class="string">'45-54'</span>,<span class="string">'55-64'</span>,<span class="string">'65+'</span>]</span><br><span class="line">missing = np.array([<span class="number">0.000095</span>, <span class="number">0.024830</span>, <span class="number">0.028665</span>, <span class="number">0.029477</span>, <span class="number">0.031918</span>,<span class="number">0.037073</span>,<span class="number">0.026699</span>])</span><br><span class="line">man = np.array([<span class="number">0.000147</span>, <span class="number">0.036311</span>, <span class="number">0.038684</span>, <span class="number">0.044761</span>, <span class="number">0.051269</span>, <span class="number">0.059542</span>, <span class="number">0.054259</span>])</span><br><span class="line">women = np.array([<span class="number">0.004035</span>, <span class="number">0.032935</span>, <span class="number">0.035351</span>, <span class="number">0.041778</span>, <span class="number">0.048437</span>, <span class="number">0.056236</span>,<span class="number">0.048091</span>])</span><br><span class="line">ind = [x <span class="keyword">for</span> x, _ <span class="keyword">in</span> enumerate(labels)]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.bar(ind, women, width=<span class="number">0.8</span>, label=<span class="string">'women'</span>, color=<span class="string">'gold'</span>, bottom=man+missing)</span><br><span class="line">plt.bar(ind, man, width=<span class="number">0.8</span>, label=<span class="string">'man'</span>, color=<span class="string">'silver'</span>, bottom=missing)</span><br><span class="line">plt.bar(ind, missing, width=<span class="number">0.8</span>, label=<span class="string">'missing'</span>, color=<span class="string">'#CD853F'</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(ind, labels)</span><br><span class="line">plt.ylabel(<span class="string">"percentage"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.title(<span class="string">"demo"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/aa2fbf6676b8fd4f67229d35f1c7c537.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/stacked.png"></p>
<h2 id="7-2-多变量分析"><a href="#7-2-多变量分析" class="headerlink" title="7.2. 多变量分析"></a>7.2. 多变量分析</h2><p>在本节中，我将仅演示双变量分析。 由于多变量分析由双变量派生。</p>
<h3 id="7-2-1-数值-VS-数值"><a href="#7-2-1-数值-VS-数值" class="headerlink" title="7.2.1. 数值 VS 数值"></a>7.2.1. 数值 VS 数值</h3><p><strong>相关矩阵</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.stat <span class="keyword">import</span> Statistics</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">corr_data = df.select(num_cols)</span><br><span class="line"></span><br><span class="line">col_names = corr_data.columns</span><br><span class="line">features = corr_data.rdd.map(<span class="keyword">lambda</span> row: row[<span class="number">0</span>:])</span><br><span class="line">corr_mat=Statistics.corr(features, method=<span class="string">"pearson"</span>)</span><br><span class="line">corr_df = pd.DataFrame(corr_mat)</span><br><span class="line">corr_df.index, corr_df.columns = col_names, col_names</span><br><span class="line"></span><br><span class="line">print(corr_df.to_string())</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+--------------------+</span><br><span class="line">|     Account Balance|    No of dependents|</span><br><span class="line">+--------------------+--------------------+</span><br><span class="line">|                 <span class="number">1.0</span>|<span class="number">-0.01414542650320914</span>|</span><br><span class="line">|<span class="number">-0.01414542650320914</span>|                 <span class="number">1.0</span>|</span><br><span class="line">+--------------------+--------------------+</span><br></pre></td></tr></table></figure>

<p><strong>散点图</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set(style=<span class="string">"ticks"</span>)</span><br><span class="line"></span><br><span class="line">df = sns.load_dataset(<span class="string">"iris"</span>)</span><br><span class="line">sns.pairplot(df, hue=<span class="string">"species"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1428271961e4c95f6508f59083d5a645.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/pairplot.png"></p>
<h3 id="7-2-2-类别-VS-类别"><a href="#7-2-2-类别-VS-类别" class="headerlink" title="7.2.2. 类别 VS 类别"></a>7.2.2. 类别 VS 类别</h3><p><strong>卡方检验</strong></p>
<blockquote>
<p>警告</p>
<p><code>pyspark.ml.stat</code> 只在 Spark 2.4.0 中可用。</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.stat <span class="keyword">import</span> ChiSquareTest</span><br><span class="line"></span><br><span class="line">data = [(<span class="number">0.0</span>, Vectors.dense(<span class="number">0.5</span>, <span class="number">10.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">1.5</span>, <span class="number">20.0</span>)),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense(<span class="number">1.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">40.0</span>)),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">40.0</span>))]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">r = ChiSquareTest.test(df, <span class="string">"features"</span>, <span class="string">"label"</span>).head()</span><br><span class="line">print(<span class="string">"pValues: "</span> + str(r.pValues))</span><br><span class="line">print(<span class="string">"degreesOfFreedom: "</span> + str(r.degreesOfFreedom))</span><br><span class="line">print(<span class="string">"statistics: "</span> + str(r.statistics))</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pValues: [<span class="number">0.687289278791</span>,<span class="number">0.682270330336</span>]</span><br><span class="line">degreesOfFreedom: [<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">statistics: [<span class="number">0.75</span>,<span class="number">1.5</span>]</span><br></pre></td></tr></table></figure>

<p><strong>交叉表</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.stat.crosstab(<span class="string">"age_class"</span>, <span class="string">"Occupation"</span>).show()</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+---+---+---+---+</span><br><span class="line">|age_class_Occupation|  <span class="number">1</span>|  <span class="number">2</span>|  <span class="number">3</span>|  <span class="number">4</span>|</span><br><span class="line">+--------------------+---+---+---+---+</span><br><span class="line">|                 &lt;<span class="number">25</span>|  <span class="number">4</span>| <span class="number">34</span>|<span class="number">108</span>|  <span class="number">4</span>|</span><br><span class="line">|               <span class="number">55</span><span class="number">-64</span>|  <span class="number">1</span>| <span class="number">15</span>| <span class="number">31</span>|  <span class="number">9</span>|</span><br><span class="line">|               <span class="number">25</span><span class="number">-34</span>|  <span class="number">7</span>| <span class="number">61</span>|<span class="number">269</span>| <span class="number">60</span>|</span><br><span class="line">|               <span class="number">35</span><span class="number">-44</span>|  <span class="number">4</span>| <span class="number">58</span>|<span class="number">143</span>| <span class="number">49</span>|</span><br><span class="line">|                 <span class="number">65</span>+|  <span class="number">5</span>|  <span class="number">3</span>|  <span class="number">6</span>|  <span class="number">9</span>|</span><br><span class="line">|               <span class="number">45</span><span class="number">-54</span>|  <span class="number">1</span>| <span class="number">29</span>| <span class="number">73</span>| <span class="number">17</span>|</span><br><span class="line">+--------------------+---+---+---+---+</span><br></pre></td></tr></table></figure>

<p><strong>堆栈图</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">labels = [<span class="string">'missing'</span>, <span class="string">'&lt;25'</span>, <span class="string">'25-34'</span>, <span class="string">'35-44'</span>, <span class="string">'45-54'</span>,<span class="string">'55-64'</span>,<span class="string">'65+'</span>]</span><br><span class="line">missing = np.array([<span class="number">0.000095</span>, <span class="number">0.024830</span>, <span class="number">0.028665</span>, <span class="number">0.029477</span>, <span class="number">0.031918</span>,<span class="number">0.037073</span>,<span class="number">0.026699</span>])</span><br><span class="line">man = np.array([<span class="number">0.000147</span>, <span class="number">0.036311</span>, <span class="number">0.038684</span>, <span class="number">0.044761</span>, <span class="number">0.051269</span>, <span class="number">0.059542</span>, <span class="number">0.054259</span>])</span><br><span class="line">women = np.array([<span class="number">0.004035</span>, <span class="number">0.032935</span>, <span class="number">0.035351</span>, <span class="number">0.041778</span>, <span class="number">0.048437</span>, <span class="number">0.056236</span>,<span class="number">0.048091</span>])</span><br><span class="line">ind = [x <span class="keyword">for</span> x, _ <span class="keyword">in</span> enumerate(labels)]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.bar(ind, women, width=<span class="number">0.8</span>, label=<span class="string">'women'</span>, color=<span class="string">'gold'</span>, bottom=man+missing)</span><br><span class="line">plt.bar(ind, man, width=<span class="number">0.8</span>, label=<span class="string">'man'</span>, color=<span class="string">'silver'</span>, bottom=missing)</span><br><span class="line">plt.bar(ind, missing, width=<span class="number">0.8</span>, label=<span class="string">'missing'</span>, color=<span class="string">'#CD853F'</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(ind, labels)</span><br><span class="line">plt.ylabel(<span class="string">"percentage"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.title(<span class="string">"demo"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="img/aa2fbf6676b8fd4f67229d35f1c7c537.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/stacked.png"></p>
<h1 id="8-回归"><a href="#8-回归" class="headerlink" title="8. 回归"></a>8. 回归</h1><blockquote>
<p><strong>千里之行，始于足下。</strong> – 《老子》</p>
</blockquote>
<p>在统计建模中，回归分析侧重于研究因变量与一个或多个自变量之间的关系。<a href="https://en.wikipedia.org/wiki/Regression_analysis" target="_blank" rel="noopener">维基百科的回归分析</a>。</p>
<p>在数据挖掘中，回归是一种模型，用于表示标签（或目标，它是数值变量）的值与一个或多个特征（或预测变量，它们可以是数值和分类变量）之间的关系。</p>
<h2 id="8-1-线性回归"><a href="#8-1-线性回归" class="headerlink" title="8.1. 线性回归"></a>8.1. 线性回归</h2><h3 id="8-1-1-简介"><a href="#8-1-1-简介" class="headerlink" title="8.1.1. 简介"></a>8.1.1. 简介</h3><p>给定数据集 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4b454255e179a3626e205ce324184acf.jpg" alt="{\displaystyle \{\,x_{i1},\ldots ,x_{in},y_{i}\}_{i=1}^{m}}">，它包含<code>n</code>个特征（变量）和<code>m</code>个样本（数据点），在简单线性回归模型中，使用<code>j</code>个自变量建模<code>m</code>个数据点 ：<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/91d663abfef497e13ec41f9300a5c354.jpg" alt="{\displaystyle x_{ij}}">，公式由下式给出：</p>
<blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/59ebd939c24bf4d59d82b0daf4874daf.jpg" alt="y_i = \beta_0 + \beta_j x_{ij}, \text{where}, i= 1, \cdots m, j= 1, \cdots n."></p>
</blockquote>
<p>在矩阵表示法中，数据集写为 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/80a25ad6329d3836f4e625a1c93e7898.jpg" alt="\X = [\x_1,\cdots, \x_n]">，其中 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/c4660874124a448ac14209f4a59e367a.jpg" alt="\x_j = {\displaystyle \{x_{ij}\}_{i=1}^{m}}">，<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/82a22af158d760e46ae93ba1663a6487.jpg" alt="\y = {\displaystyle \{y_{i}\}_{i=1}^{m}}">，并且 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/fad9e18cebad821450ed0f34abdb3988.jpg" alt="\Bbeta^\top = {\displaystyle \{\beta_{j}\}_{j=1}^{n}}">。之后矩阵形式的方程写为：</p>
<blockquote>
<p>(1)<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/2d776487e1a2ee4683c3c6f51fca7e48.jpg" alt="\y = \X \Bbeta."></p>
</blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/3b99ee07cd783026d41b65651ee5d293.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/fm.png"></p>
<p>特征矩阵和标签</p>
<h3 id="8-1-2-如何求解"><a href="#8-1-2-如何求解" class="headerlink" title="8.1.2. 如何求解"></a>8.1.2. 如何求解</h3><ol>
<li><p>直接法 （更多信息请参考我的<a href="http://web.utk.edu/~wfeng1/doc/PrelimNum.pdf" target="_blank" rel="noopener">数值分析预备笔记</a>）。</p>
<ul>
<li><p>对于方阵或长方阵</p>
<ul>
<li>奇异值分解</li>
<li>格兰施密特正交化</li>
<li>QR 分解</li>
</ul>
</li>
<li><p>对于方阵</p>
<ul>
<li>LU 分解</li>
<li>Cholesky 分解</li>
<li>正则分割</li>
</ul>
</li>
</ul>
</li>
<li><p>迭代方法</p>
<ul>
<li><p>静态案例迭代法</p>
<ul>
<li>Jacobi 方法</li>
<li>Gauss-Seidel 方法</li>
<li>Richardson 方法</li>
<li>连续过度放松 (SOR) 方法</li>
</ul>
</li>
<li><p>动态案例迭代法</p>
<ul>
<li>Chebyshev 迭代法</li>
<li>最小残差法</li>
<li>最小修正迭代法</li>
<li>最速下降法</li>
<li>共轭梯度法</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="8-1-3-普通最小二乘"><a href="#8-1-3-普通最小二乘" class="headerlink" title="8.1.3. 普通最小二乘"></a>8.1.3. 普通最小二乘</h3><p>在数学中，<a href="#equation-eq-ax">（1）</a>是一个超定系统。 普通最小二乘法可用于找到超定系统的近似解。 对于系统超定系统<a href="#equation-eq-ax">（1）</a>，从问题中获得最小二乘公式</p>
<p>(2)<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b8bf446d4a625497f28f2347b7ca0c92.jpg" alt="{\displaystyle \min _{\Bbeta}  ||\X \Bbeta-\y||} ,"></p>
<p>其解决方案可以用正规方程式编写：</p>
<p>(3)<img src="img/d2f9799d371fde446e6dc8292ba07393.jpg" alt="\Bbeta  = (G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d2f9799d371fde446e6dc8292ba07393.jpg)^{-1}\X^T\y"></p>
<p>其中 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d09c46ec94d638e4ddcecfbba1c11ea8.jpg" alt="{\displaystyle {\mathrm {T} }}"> 表示矩阵转置，假设 <img src="img/d003fed20e7f2d040ccc24412cb854d1.jpg" alt="{\displaystyle (G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d003fed20e7f2d040ccc24412cb854d1.jpg)^{-1}}"> 存在（也就是假设 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/501025688da0cf9e2b3937cd7da9580d.jpg" alt="\X"> 是列满秩的）。</p>
<blockquote>
<p>注意</p>
<p>实际上，<a href="#equation-eq-solax">(3)</a> 可以用下面的方式导出：将 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d142da9aae51c6d3c3c736fc82252862.jpg" alt="\X^T"> 和 <a href="#equation-eq-ax">(1)</a> 相乘，之后在之前结果的两边乘上 <img src="img/16dd8d60ea9b042c3ce0652c9f0571e8.jpg" alt="(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/16dd8d60ea9b042c3ce0652c9f0571e8.jpg)^{-1}">。你也可以对 <a href="#equation-eq-minax">(2)</a> 应用极值定理，并寻找 <a href="#equation-eq-solax">(3)</a> 的解。</p>
</blockquote>
<h3 id="8-1-4-梯度下降"><a href="#8-1-4-梯度下降" class="headerlink" title="8.1.4. 梯度下降"></a>8.1.4. 梯度下降</h3><p>让我们使用下列假设：</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/a5fda7453d5707d5e8985434c789ba48.jpg" alt="h_\Bbeta = \beta_0 + \beta_j \x_{j}, \text{where}, j= 1, \cdots n."></p>
<p>之后求解 <a href="#equation-eq-minax">(2)</a> 等价于最小化下面的损失函数：</p>
<h3 id="8-1-5-损失函数"><a href="#8-1-5-损失函数" class="headerlink" title="8.1.5. 损失函数"></a>8.1.5. 损失函数</h3><p>(4)<img src="img/77c47cf9cfec8ec740c5a18dc4386670.jpg" alt="J(G:/PYthonLearning/learning-pyspark-zh-master/docs/img/77c47cf9cfec8ec740c5a18dc4386670.jpg) = \frac{1}{2m}\sum_{i=1}^m \left( h_\Bbeta(x^{(i)})-y^{(i)}) \right)^2"></p>
<blockquote>
<p>注意</p>
<p>我们倾向求解 <a href="#equation-eq-lreg-cost">(4)</a> 而不是 <a href="#equation-eq-minax">(2)</a> 的原因是，<a href="#equation-eq-lreg-cost">(4)</a> 是凸的，并且属性良好，例如它是个唯一可解，对于足够小的学习率是能量稳定的。如果读者对非凸损失函数（能量）案例感兴趣，可以参考 <a href="reference.html#feng2016psd">[Feng2016PSD]</a>。</p>
</blockquote>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/875e532ac3b299876d209507d595df14.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/gradient1d.png"></p>
<p>一维中的梯度下降</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/d4b34834b440d5d60f25912180e7e130.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/gradient2d.png"></p>
<p>二维中的梯度下降</p>
<h3 id="8-1-6-批量梯度下降"><a href="#8-1-6-批量梯度下降" class="headerlink" title="8.1.6. 批量梯度下降"></a>8.1.6. 批量梯度下降</h3><p>梯度下降是用于找到函数最小值的一阶迭代优化算法。 它沿着最陡峭的方向搜索，该方向由“梯度的相反数”（参见图<a href="#fig-gd1d"> 1D 中的梯度下降</a>和<a href="#fig-gd2d"> 2D 中的梯度下降</a>）和学习率（搜索步长）<img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/aef64ee73dc1b1a03a152855f685113e.jpg" alt="\ alpha"> 定义。</p>
<h3 id="8-1-7-随机梯度下降"><a href="#8-1-7-随机梯度下降" class="headerlink" title="8.1.7. 随机梯度下降"></a>8.1.7. 随机梯度下降</h3><h3 id="8-1-8-小批量梯度下降"><a href="#8-1-8-小批量梯度下降" class="headerlink" title="8.1.8. 小批量梯度下降"></a>8.1.8. 小批量梯度下降</h3><h3 id="8-1-9-示例"><a href="#8-1-9-示例" class="headerlink" title="8.1.9. 示例"></a>8.1.9. 示例</h3><ul>
<li>Jupyter 笔记本可以从<a href="_static/LinearRegression.ipynb">线性回归</a> 下载，它不使用流水线实现。</li>
<li>upyter 笔记本可以从<a href="_static/LinearRegressionWpipeline.ipynb">带流水线的线性回归</a>，它使用流水线实现。</li>
<li>我下面仅仅展示流水线风格的代码。</li>
<li>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.LinearRegression.html" target="_blank" rel="noopener">线性回归 API</a>。</li>
</ul>
<p>建立 spark 上下文和 SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark regression example&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                       options(header=&apos;true&apos;, \</span><br><span class="line">                       inferschema=&apos;true&apos;).\</span><br><span class="line">            load(&quot;../data/Advertising.csv&quot;,header=True);</span><br></pre></td></tr></table></figure>

<p>检查数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<p>之后我们会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<p>您还可以从数据帧中获取统计结果（不幸的是，它仅适用于数字）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|summary|               TV|             Radio|         Newspaper|             Sales|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|  count|              200|               200|               200|               200|</span><br><span class="line">|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|</span><br><span class="line">| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|</span><br><span class="line">|    min|              0.7|               0.0|               0.3|               1.6|</span><br><span class="line">|    max|            296.4|              49.6|             114.0|              27.0|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/ad37847dfd8d9f3d99f646966f32cf30.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/ad.png"></p>
<p>销售分布</p>
<p>将数据转换为密集向量（<strong>特征</strong>和<strong>标签</strong>）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># I provide two ways to build the features and labels</span><br><span class="line"></span><br><span class="line"># method 1 (good for small feature):</span><br><span class="line">#def transData(row):</span><br><span class="line">#    return Row(label=row[&quot;Sales&quot;],</span><br><span class="line">#               features=Vectors.dense([row[&quot;TV&quot;],</span><br><span class="line">#                                       row[&quot;Radio&quot;],</span><br><span class="line">#                                       row[&quot;Newspaper&quot;]]))</span><br><span class="line"></span><br><span class="line"># Method 2 (good for large features):</span><br><span class="line">def transData(data):</span><br><span class="line">return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>强烈建议您尝试使用我的<code>get_dummy</code>函数来处理数据集中的分类数据。</p>
</blockquote>
<p>监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<p>无监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">    :param df: the dataframe</span><br><span class="line">    :param categoricalCols: the name list of the categorical data</span><br><span class="line">    :param continuousCols:  the name list of the numerical data</span><br><span class="line">    :return k: feature matrix</span><br><span class="line"></span><br><span class="line">    :author: Wenqiang Feng</span><br><span class="line">    :email:  von198@gmail.com</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;)</span><br></pre></td></tr></table></figure>

<p>将数据集转换为数据帧</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed= transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+</span><br><span class="line">|         features|label|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>您会发现 Spark 中所有监督机器学习算法都基于<strong>特征</strong>和<strong>标签</strong>（Spark 中的无监督机器学习算法基于<strong>特征</strong>）。 也就是说，当您在管道架构中准备好<strong>特征</strong>和<strong>标签</strong>时，您可以使用 Spark 中的所有机器学习算法。</p>
</blockquote>
<p>处理类别变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.regression import LinearRegression</span><br><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"></span><br><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># We specify maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line"></span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                               outputCol=&quot;indexedFeatures&quot;,\</span><br><span class="line">                               maxCategories=4).fit(transformed)</span><br><span class="line"></span><br><span class="line">data = featureIndexer.transform(transformed)</span><br></pre></td></tr></table></figure>

<p>现在你可以这样检查数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.show(5,True)</span><br></pre></td></tr></table></figure>

<p>你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|         features|label|  indexedFeatures|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>将数据分割为训练和测试集（留出 40% 用于测试）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = transformed.randomSplit([0.6, 0.4])</span><br></pre></td></tr></table></figure>

<p>您可以按照以下方式检查您的训练和测试数据（在我看来，在原型阶段始终跟踪您的数据总是很好）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-----+---------------+</span><br><span class="line">|       features|label|indexedFeatures|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|</span><br><span class="line">| [5.4,29.9,9.4]|  5.3| [5.4,29.9,9.4]|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|</span><br><span class="line">|[7.8,38.9,50.6]|  6.6|[7.8,38.9,50.6]|</span><br><span class="line">|  [8.6,2.1,1.0]|  4.8|  [8.6,2.1,1.0]|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|        features|label| indexedFeatures|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|  [0.7,39.6,8.7]|  1.6|  [0.7,39.6,8.7]|</span><br><span class="line">|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|</span><br><span class="line">|[11.7,36.9,45.2]|  7.3|[11.7,36.9,45.2]|</span><br><span class="line">|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|</span><br><span class="line">|[16.9,43.7,89.4]|  8.7|[16.9,43.7,89.4]|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>拟合普通最小二乘回归模型</p>
<p>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.LinearRegression.html" target="_blank" rel="noopener">线性回归 API</a>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Import LinearRegression class</span><br><span class="line">from pyspark.ml.regression import LinearRegression</span><br><span class="line"></span><br><span class="line"># Define LinearRegression algorithm</span><br><span class="line">lr = LinearRegression()</span><br></pre></td></tr></table></figure>

<p>流水线架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexer and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, lr])</span><br><span class="line"></span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<p>模型总结</p>
<p>Spark 不擅长数据和模型的汇总。 我为 PySpark 中线性回归写了一个汇总函数，其格式与 <strong>R</strong> 的输出类似。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def modelsummary(model):</span><br><span class="line">    import numpy as np</span><br><span class="line">    print (&quot;Note: the last rows are the information for Intercept&quot;)</span><br><span class="line">    print (&quot;##&quot;,&quot;-------------------------------------------------&quot;)</span><br><span class="line">    print (&quot;##&quot;,&quot;  Estimate   |   Std.Error | t Values  |  P-value&quot;)</span><br><span class="line">    coef = np.append(list(model.coefficients),model.intercept)</span><br><span class="line">    Summary=model.summary</span><br><span class="line"></span><br><span class="line">    for i in range(len(Summary.pValues)):</span><br><span class="line">        print (&quot;##&quot;,&apos;&#123;:10.6f&#125;&apos;.format(coef[i]),\</span><br><span class="line">        &apos;&#123;:10.6f&#125;&apos;.format(Summary.coefficientStandardErrors[i]),\</span><br><span class="line">        &apos;&#123;:8.3f&#125;&apos;.format(Summary.tValues[i]),\</span><br><span class="line">        &apos;&#123;:10.6f&#125;&apos;.format(Summary.pValues[i]))</span><br><span class="line"></span><br><span class="line">    print (&quot;##&quot;,&apos;---&apos;)</span><br><span class="line">    print (&quot;##&quot;,&quot;Mean squared error: % .6f&quot; \</span><br><span class="line">           % Summary.meanSquaredError, &quot;, RMSE: % .6f&quot; \</span><br><span class="line">           % Summary.rootMeanSquaredError )</span><br><span class="line">    print (&quot;##&quot;,&quot;Multiple R-squared: %f&quot; % Summary.r2, &quot;, \</span><br><span class="line">            Total iterations: %i&quot;% Summary.totalIterations)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelsummary(model.stages[-1])</span><br></pre></td></tr></table></figure>

<p>你会得到以下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Note: the last rows are the information for Intercept</span><br><span class="line">(&apos;##&apos;, &apos;-------------------------------------------------&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  Estimate   |   Std.Error | t Values  |  P-value&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  0.044186&apos;, &apos;  0.001663&apos;, &apos;  26.573&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  0.206311&apos;, &apos;  0.010846&apos;, &apos;  19.022&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  0.001963&apos;, &apos;  0.007467&apos;, &apos;   0.263&apos;, &apos;  0.793113&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  2.596154&apos;, &apos;  0.379550&apos;, &apos;   6.840&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;---&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;Mean squared error:  2.588230&apos;, &apos;, RMSE:  1.608798&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;Multiple R-squared: 0.911869&apos;, &apos;,             Total iterations: 1&apos;)</span><br></pre></td></tr></table></figure>

<p>做出预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-----+------------------+</span><br><span class="line">|        features|label|        prediction|</span><br><span class="line">+----------------+-----+------------------+</span><br><span class="line">|  [0.7,39.6,8.7]|  1.6| 10.81405928637388|</span><br><span class="line">|  [8.4,27.2,2.1]|  5.7| 8.583086404079918|</span><br><span class="line">|[11.7,36.9,45.2]|  7.3|10.814712818232422|</span><br><span class="line">|[13.2,15.9,49.6]|  5.6| 6.557106943899219|</span><br><span class="line">|[16.9,43.7,89.4]|  8.7|12.534151375058645|</span><br><span class="line">+----------------+-----+------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = RegressionEvaluator(labelCol=&quot;label&quot;,</span><br><span class="line">                                predictionCol=&quot;prediction&quot;,</span><br><span class="line">                                metricName=&quot;rmse&quot;)</span><br><span class="line"></span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Root Mean Squared Error (RMSE) on test data = %g&quot; % rmse)</span><br></pre></td></tr></table></figure>

<p>最终的均方根误差（RMSE）如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Root Mean Squared Error (RMSE) on test data = 1.63114</span><br></pre></td></tr></table></figure>

<p>您还可以检查测试数据的 ![R^2](img/1ac835166928f502b55a31636602602a.jpg） 值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_true = predictions.select(&quot;label&quot;).toPandas()</span><br><span class="line">y_pred = predictions.select(&quot;prediction&quot;).toPandas()</span><br><span class="line"></span><br><span class="line">import sklearn.metrics</span><br><span class="line">r2_score = sklearn.metrics.r2_score(y_true, y_pred)</span><br><span class="line">print(&apos;r2_score: &#123;0&#125;&apos;.format(r2_score))</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score: 0.854486655585</span><br></pre></td></tr></table></figure>

<blockquote>
<p>警告</p>
<p>你应该知道，模型不包含截距时，大多数软件使用不同的公式来计算 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg" alt="R^2"> 值。你可以从<a href="https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo" target="_blank" rel="noopener"> StackExchange 上的讨论</a>获得更多信息。</p>
</blockquote>
<h2 id="8-2-广义线性回归"><a href="#8-2-广义线性回归" class="headerlink" title="8.2. 广义线性回归"></a>8.2. 广义线性回归</h2><h3 id="8-2-1-介绍"><a href="#8-2-1-介绍" class="headerlink" title="8.2.1. 介绍"></a>8.2.1. 介绍</h3><h3 id="8-2-2-如何求解"><a href="#8-2-2-如何求解" class="headerlink" title="8.2.2. 如何求解"></a>8.2.2. 如何求解</h3><h3 id="8-2-3-示例"><a href="#8-2-3-示例" class="headerlink" title="8.2.3. 示例"></a>8.2.3. 示例</h3><ul>
<li>Jupyter 笔记本可以从<a href="_static/GLM.ipynb">广义线性回归</a>下载。</li>
<li>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.GeneralizedLinearRegression.html" target="_blank" rel="noopener">广义线性回归 API</a>。</li>
</ul>
<p>建立 spark 上下文和 SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark regression example&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                       options(header=&apos;true&apos;, \</span><br><span class="line">                       inferschema=&apos;true&apos;).\</span><br><span class="line">            load(&quot;../data/Advertising.csv&quot;,header=True);</span><br></pre></td></tr></table></figure>

<p>查看数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<p>您还可以从数据帧中获取统计结果（不幸的是，它仅适用于数字）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|summary|               TV|             Radio|         Newspaper|             Sales|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|  count|              200|               200|               200|               200|</span><br><span class="line">|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|</span><br><span class="line">| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|</span><br><span class="line">|    min|              0.7|               0.0|               0.3|               1.6|</span><br><span class="line">|    max|            296.4|              49.6|             114.0|              27.0|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量（<strong>特征</strong>和<strong>标签</strong>）</p>
<blockquote>
<p>注意</p>
</blockquote>
<p>强烈建议您尝试使用我的<code>get_dummy</code>函数来处理数据集中的分类数据。</p>
<p>监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<p>无监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">    :param df: the dataframe</span><br><span class="line">    :param categoricalCols: the name list of the categorical data</span><br><span class="line">    :param continuousCols:  the name list of the numerical data</span><br><span class="line">    :return k: feature matrix</span><br><span class="line"></span><br><span class="line">    :author: Wenqiang Feng</span><br><span class="line">    :email:  von198@gmail.com</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># I provide two ways to build the features and labels</span><br><span class="line"></span><br><span class="line"># method 1 (good for small feature):</span><br><span class="line">#def transData(row):</span><br><span class="line">#    return Row(label=row[&quot;Sales&quot;],</span><br><span class="line">#               features=Vectors.dense([row[&quot;TV&quot;],</span><br><span class="line">#                                       row[&quot;Radio&quot;],</span><br><span class="line">#                                       row[&quot;Newspaper&quot;]]))</span><br><span class="line"></span><br><span class="line"># Method 2 (good for large features):</span><br><span class="line">def transData(data):</span><br><span class="line">return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed= transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+</span><br><span class="line">|         features|label|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>您会发现 Spark 中所有监督机器学习算法都基于<strong>特征</strong>和<strong>标签</strong>（Spark 中的无监督机器学习算法基于<strong>特征</strong>）。 也就是说，当您在管道架构中准备好<strong>特征</strong>和<strong>标签</strong>时，您可以使用 Spark 中的所有机器学习算法。</p>
</blockquote>
<p>将数据转换为密集向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># convert the data to dense vector</span><br><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\</span><br><span class="line">           toDF([&apos;label&apos;,&apos;features&apos;])</span><br><span class="line"></span><br><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line">data= transData(df)</span><br><span class="line">data.show()</span><br></pre></td></tr></table></figure>

<p>处理类别变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.regression import LinearRegression</span><br><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"></span><br><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># We specify maxCategories so features with &gt; 4</span><br><span class="line"># distinct values are treated as continuous.</span><br><span class="line"></span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                               outputCol=&quot;indexedFeatures&quot;,\</span><br><span class="line">                               maxCategories=4).fit(transformed)</span><br><span class="line"></span><br><span class="line">data = featureIndexer.transform(transformed)</span><br></pre></td></tr></table></figure>

<p>When you check you data at this point, you will get</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|         features|label|  indexedFeatures|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>将数据分割为训练和测试集（留出 40% 用于测试）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = transformed.randomSplit([0.6, 0.4])</span><br></pre></td></tr></table></figure>

<p>您可以按照以下方式检查您的训练和测试数据（在我看来，在原型阶段始终跟踪您的数据总是很好）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-----+----------------+</span><br><span class="line">|        features|label| indexedFeatures|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|</span><br><span class="line">| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|</span><br><span class="line">|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|</span><br><span class="line">| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|</span><br><span class="line">|[11.7,36.9,45.2]|  7.3|[11.7,36.9,45.2]|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">|       features|label|indexedFeatures|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">| [0.7,39.6,8.7]|  1.6| [0.7,39.6,8.7]|</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|</span><br><span class="line">|  [8.6,2.1,1.0]|  4.8|  [8.6,2.1,1.0]|</span><br><span class="line">|[17.2,4.1,31.6]|  5.9|[17.2,4.1,31.6]|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>拟合广义线性回归模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Import LinearRegression class</span><br><span class="line">from pyspark.ml.regression import GeneralizedLinearRegression</span><br><span class="line"></span><br><span class="line"># Define LinearRegression algorithm</span><br><span class="line">glr = GeneralizedLinearRegression(family=&quot;gaussian&quot;, link=&quot;identity&quot;,\</span><br><span class="line">                                  maxIter=10, regParam=0.3)</span><br></pre></td></tr></table></figure>

<p>流水线架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexer and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, glr])</span><br><span class="line"></span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<p>模型总结</p>
<p>Spark 不擅长数据和模型的汇总。 我为 PySpark 中线性回归写了一个汇总函数，其格式与 <strong>R</strong> 输出类似。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def modelsummary(model):</span><br><span class="line">    import numpy as np</span><br><span class="line">    print (&quot;Note: the last rows are the information for Intercept&quot;)</span><br><span class="line">    print (&quot;##&quot;,&quot;-------------------------------------------------&quot;)</span><br><span class="line">    print (&quot;##&quot;,&quot;  Estimate   |   Std.Error | t Values  |  P-value&quot;)</span><br><span class="line">    coef = np.append(list(model.coefficients),model.intercept)</span><br><span class="line">    Summary=model.summary</span><br><span class="line"></span><br><span class="line">    for i in range(len(Summary.pValues)):</span><br><span class="line">        print (&quot;##&quot;,&apos;&#123;:10.6f&#125;&apos;.format(coef[i]),\</span><br><span class="line">        &apos;&#123;:10.6f&#125;&apos;.format(Summary.coefficientStandardErrors[i]),\</span><br><span class="line">        &apos;&#123;:8.3f&#125;&apos;.format(Summary.tValues[i]),\</span><br><span class="line">        &apos;&#123;:10.6f&#125;&apos;.format(Summary.pValues[i]))</span><br><span class="line"></span><br><span class="line">    print (&quot;##&quot;,&apos;---&apos;)</span><br><span class="line">#     print (&quot;##&quot;,&quot;Mean squared error: % .6f&quot; \</span><br><span class="line">#            % Summary.meanSquaredError, &quot;, RMSE: % .6f&quot; \</span><br><span class="line">#            % Summary.rootMeanSquaredError )</span><br><span class="line">#     print (&quot;##&quot;,&quot;Multiple R-squared: %f&quot; % Summary.r2, &quot;, \</span><br><span class="line">#             Total iterations: %i&quot;% Summary.totalIterations)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelsummary(model.stages[-1])</span><br></pre></td></tr></table></figure>

<p>你会得到以下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Note: the last rows are the information for Intercept</span><br><span class="line">(&apos;##&apos;, &apos;-------------------------------------------------&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  Estimate   |   Std.Error | t Values  |  P-value&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  0.042857&apos;, &apos;  0.001668&apos;, &apos;  25.692&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  0.199922&apos;, &apos;  0.009881&apos;, &apos;  20.232&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos; -0.001957&apos;, &apos;  0.006917&apos;, &apos;  -0.283&apos;, &apos;  0.777757&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;  3.007515&apos;, &apos;  0.406389&apos;, &apos;   7.401&apos;, &apos;  0.000000&apos;)</span><br><span class="line">(&apos;##&apos;, &apos;---&apos;)</span><br></pre></td></tr></table></figure>

<p>做出预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-----+------------------+</span><br><span class="line">|       features|label|        prediction|</span><br><span class="line">+---------------+-----+------------------+</span><br><span class="line">| [0.7,39.6,8.7]|  1.6|10.937383732327625|</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| 5.491166258750164|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|   8.8571603947873|</span><br><span class="line">|  [8.6,2.1,1.0]|  4.8| 3.793966281660073|</span><br><span class="line">|[17.2,4.1,31.6]|  5.9| 4.502507124763654|</span><br><span class="line">+---------------+-----+------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = RegressionEvaluator(labelCol=&quot;label&quot;,</span><br><span class="line">                                predictionCol=&quot;prediction&quot;,</span><br><span class="line">                                metricName=&quot;rmse&quot;)</span><br><span class="line"></span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Root Mean Squared Error (RMSE) on test data = %g&quot; % rmse)</span><br></pre></td></tr></table></figure>

<p>最终的均方根误差（RMSE）如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Root Mean Squared Error (RMSE) on test data = 1.89857</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_true = predictions.select(&quot;label&quot;).toPandas()</span><br><span class="line">y_pred = predictions.select(&quot;prediction&quot;).toPandas()</span><br><span class="line"></span><br><span class="line">import sklearn.metrics</span><br><span class="line">r2_score = sklearn.metrics.r2_score(y_true, y_pred)</span><br><span class="line">print(&apos;r2_score: &#123;0&#125;&apos;.format(r2_score))</span><br></pre></td></tr></table></figure>

<p>之后你会得到 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg" alt="R^2"> 值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score: 0.87707391843</span><br></pre></td></tr></table></figure>

<h2 id="8-3-决策树回归"><a href="#8-3-决策树回归" class="headerlink" title="8.3. 决策树回归"></a>8.3. 决策树回归</h2><h3 id="8-3-1-介绍"><a href="#8-3-1-介绍" class="headerlink" title="8.3.1. 介绍"></a>8.3.1. 介绍</h3><h3 id="8-3-2-如何求解"><a href="#8-3-2-如何求解" class="headerlink" title="8.3.2. 如何求解"></a>8.3.2. 如何求解</h3><h3 id="8-3-3-示例"><a href="#8-3-3-示例" class="headerlink" title="8.3.3. 示例"></a>8.3.3. 示例</h3><ul>
<li>Jupyter 笔记本可以从<a href="_static/DecisionTreeR.ipynb">决策树回归</a>下载。</li>
<li>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.DecisionTreeRegressor.html" target="_blank" rel="noopener">决策树回归 API</a>。</li>
</ul>
<p>建立 spark 上下文和 SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark regression example&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                       options(header=&apos;true&apos;, \</span><br><span class="line">                       inferschema=&apos;true&apos;).\</span><br><span class="line">            load(&quot;../data/Advertising.csv&quot;,header=True);</span><br></pre></td></tr></table></figure>

<p>检查数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<p>您还可以从数据帧中获取统计结果（不幸的是，它仅适用于数字）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|summary|               TV|             Radio|         Newspaper|             Sales|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|  count|              200|               200|               200|               200|</span><br><span class="line">|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|</span><br><span class="line">| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|</span><br><span class="line">|    min|              0.7|               0.0|               0.3|               1.6|</span><br><span class="line">|    max|            296.4|              49.6|             114.0|              27.0|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量（<strong>特征</strong>和<strong>标签</strong>）</p>
<blockquote>
<p>注意</p>
<p>强烈建议您尝试使用我的<code>get_dummy</code>函数来处理数据集中的分类数据。</p>
</blockquote>
<p>监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<p>无监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">    :param df: the dataframe</span><br><span class="line">    :param categoricalCols: the name list of the categorical data</span><br><span class="line">    :param continuousCols:  the name list of the numerical data</span><br><span class="line">    :return k: feature matrix</span><br><span class="line"></span><br><span class="line">    :author: Wenqiang Feng</span><br><span class="line">    :email:  von198@gmail.com</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># I provide two ways to build the features and labels</span><br><span class="line"></span><br><span class="line"># method 1 (good for small feature):</span><br><span class="line">#def transData(row):</span><br><span class="line">#    return Row(label=row[&quot;Sales&quot;],</span><br><span class="line">#               features=Vectors.dense([row[&quot;TV&quot;],</span><br><span class="line">#                                       row[&quot;Radio&quot;],</span><br><span class="line">#                                       row[&quot;Newspaper&quot;]]))</span><br><span class="line"></span><br><span class="line"># Method 2 (good for large features):</span><br><span class="line">def transData(data):</span><br><span class="line">return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed= transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+</span><br><span class="line">|         features|label|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>您会发现 Spark 中所有监督机器学习算法都基于<strong>特征</strong>和<strong>标签</strong>（Spark 中的无监督机器学习算法基于<strong>特征</strong>）。 也就是说，当您在管道架构中准备好<strong>特征</strong>和<strong>标签</strong>时，您可以使用 Spark 中的所有机器学习算法。</p>
</blockquote>
<p>将数据转换为密集向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># convert the data to dense vector</span><br><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\</span><br><span class="line">           toDF([&apos;label&apos;,&apos;features&apos;])</span><br><span class="line"></span><br><span class="line">transformed = transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<p>处理类别变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.regression import LinearRegression</span><br><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"></span><br><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># We specify maxCategories so features with &gt; 4</span><br><span class="line"># distinct values are treated as continuous.</span><br><span class="line"></span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                               outputCol=&quot;indexedFeatures&quot;,\</span><br><span class="line">                               maxCategories=4).fit(transformed)</span><br><span class="line"></span><br><span class="line">data = featureIndexer.transform(transformed)</span><br></pre></td></tr></table></figure>

<p>When you check you data at this point, you will get</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|         features|label|  indexedFeatures|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>将数据分割为训练和测试集（留出 40% 用于测试）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = transformed.randomSplit([0.6, 0.4])</span><br></pre></td></tr></table></figure>

<p>您可以按照以下方式检查您的训练和测试数据（在我看来，在原型阶段始终跟踪您的数据总是很好）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<p>之后你会得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-----+---------------+</span><br><span class="line">|       features|label|indexedFeatures|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|</span><br><span class="line">| [8.4,27.2,2.1]|  5.7| [8.4,27.2,2.1]|</span><br><span class="line">|  [8.6,2.1,1.0]|  4.8|  [8.6,2.1,1.0]|</span><br><span class="line">|[8.7,48.9,75.0]|  7.2|[8.7,48.9,75.0]|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|        features|label| indexedFeatures|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|  [0.7,39.6,8.7]|  1.6|  [0.7,39.6,8.7]|</span><br><span class="line">|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|</span><br><span class="line">| [7.8,38.9,50.6]|  6.6| [7.8,38.9,50.6]|</span><br><span class="line">|[17.2,45.9,69.3]|  9.3|[17.2,45.9,69.3]|</span><br><span class="line">|[18.7,12.1,23.4]|  6.7|[18.7,12.1,23.4]|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>拟合决策树回归模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.regression import DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line"># Train a DecisionTree model.</span><br><span class="line">dt = DecisionTreeRegressor(featuresCol=&quot;indexedFeatures&quot;)</span><br></pre></td></tr></table></figure>

<p>流水线架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexer and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, dt])</span><br><span class="line"></span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<p>做出预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----+----------------+</span><br><span class="line">|prediction|label|        features|</span><br><span class="line">+----------+-----+----------------+</span><br><span class="line">|       7.2|  1.6|  [0.7,39.6,8.7]|</span><br><span class="line">|       7.3|  5.3|  [5.4,29.9,9.4]|</span><br><span class="line">|       7.2|  6.6| [7.8,38.9,50.6]|</span><br><span class="line">|      8.64|  9.3|[17.2,45.9,69.3]|</span><br><span class="line">|      6.45|  6.7|[18.7,12.1,23.4]|</span><br><span class="line">+----------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = RegressionEvaluator(labelCol=&quot;label&quot;,</span><br><span class="line">                                predictionCol=&quot;prediction&quot;,</span><br><span class="line">                                metricName=&quot;rmse&quot;)</span><br><span class="line"></span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Root Mean Squared Error (RMSE) on test data = %g&quot; % rmse)</span><br></pre></td></tr></table></figure>

<p>最终的均方根误差（RMSE）如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Root Mean Squared Error (RMSE) on test data = 1.50999</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_true = predictions.select(&quot;label&quot;).toPandas()</span><br><span class="line">y_pred = predictions.select(&quot;prediction&quot;).toPandas()</span><br><span class="line"></span><br><span class="line">import sklearn.metrics</span><br><span class="line">r2_score = sklearn.metrics.r2_score(y_true, y_pred)</span><br><span class="line">print(&apos;r2_score: &#123;0&#125;&apos;.format(r2_score))</span><br></pre></td></tr></table></figure>

<p>之后你会得到 <img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1ac835166928f502b55a31636602602a.jpg" alt="R^2"> 值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score: 0.911024318967</span><br></pre></td></tr></table></figure>

<p>你可以检查特征上的重要性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.stages[1].featureImportances</span><br></pre></td></tr></table></figure>

<p>您将获得每个特征的权重</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparseVector(3, &#123;0: 0.6811, 1: 0.3187, 2: 0.0002&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="8-4-随机森林回归"><a href="#8-4-随机森林回归" class="headerlink" title="8.4. 随机森林回归"></a>8.4. 随机森林回归</h2><h3 id="8-4-1-简介"><a href="#8-4-1-简介" class="headerlink" title="8.4.1. 简介"></a>8.4.1. 简介</h3><h3 id="8-4-2-如何求解"><a href="#8-4-2-如何求解" class="headerlink" title="8.4.2. 如何求解"></a>8.4.2. 如何求解</h3><h3 id="8-4-3-示例"><a href="#8-4-3-示例" class="headerlink" title="8.4.3. 示例"></a>8.4.3. 示例</h3><ul>
<li>Jupyter 笔记本可以从<a href="_static/RandomForestR.ipynb">随机森林回归</a>下载。</li>
<li>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.RandomForestRegressor.html" target="_blank" rel="noopener">随机森林回归 API</a>。</li>
</ul>
<p>建立 spark 上下文和 SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark RandomForest Regression example&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                               options(header=&apos;true&apos;, \</span><br><span class="line">                               inferschema=&apos;true&apos;).\</span><br><span class="line">                               load(&quot;../data/Advertising.csv&quot;,header=True);</span><br><span class="line"></span><br><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br><span class="line"></span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|summary|               TV|             Radio|         Newspaper|             Sales|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|  count|              200|               200|               200|               200|</span><br><span class="line">|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|</span><br><span class="line">| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|</span><br><span class="line">|    min|              0.7|               0.0|               0.3|               1.6|</span><br><span class="line">|    max|            296.4|              49.6|             114.0|              27.0|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量（<strong>特征</strong>和<strong>标签</strong>）</p>
<blockquote>
<p>注意</p>
<p>强烈建议您尝试使用我的<code>get_dummy</code>函数来处理数据集中的分类数据。</p>
</blockquote>
<p>监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<p>无监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">    :param df: the dataframe</span><br><span class="line">    :param categoricalCols: the name list of the categorical data</span><br><span class="line">    :param continuousCols:  the name list of the numerical data</span><br><span class="line">    :return k: feature matrix</span><br><span class="line"></span><br><span class="line">    :author: Wenqiang Feng</span><br><span class="line">    :email:  von198@gmail.com</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># convert the data to dense vector</span><br><span class="line">#def transData(row):</span><br><span class="line">#    return Row(label=row[&quot;Sales&quot;],</span><br><span class="line">#               features=Vectors.dense([row[&quot;TV&quot;],</span><br><span class="line">#                                       row[&quot;Radio&quot;],</span><br><span class="line">#                                       row[&quot;Newspaper&quot;]]))</span><br><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed= transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+</span><br><span class="line">|         features|label|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>处理类别变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.regression import LinearRegression</span><br><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"></span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                               outputCol=&quot;indexedFeatures&quot;,\</span><br><span class="line">                               maxCategories=4).fit(transformed)</span><br><span class="line"></span><br><span class="line">data = featureIndexer.transform(transformed)</span><br><span class="line">data.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|         features|label|  indexedFeatures|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>将数据分割为训练和测试集（留出 40% 用于测试）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-----+----------------+</span><br><span class="line">|        features|label| indexedFeatures|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|  [0.7,39.6,8.7]|  1.6|  [0.7,39.6,8.7]|</span><br><span class="line">|   [8.6,2.1,1.0]|  4.8|   [8.6,2.1,1.0]|</span><br><span class="line">| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|</span><br><span class="line">|[11.7,36.9,45.2]|  7.3|[11.7,36.9,45.2]|</span><br><span class="line">|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">|       features|label|indexedFeatures|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|</span><br><span class="line">| [5.4,29.9,9.4]|  5.3| [5.4,29.9,9.4]|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|</span><br><span class="line">|[7.8,38.9,50.6]|  6.6|[7.8,38.9,50.6]|</span><br><span class="line">| [8.4,27.2,2.1]|  5.7| [8.4,27.2,2.1]|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>拟合随机森林回归模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Import LinearRegression class</span><br><span class="line">from pyspark.ml.regression import RandomForestRegressor</span><br><span class="line"></span><br><span class="line"># Define LinearRegression algorithm</span><br><span class="line">rf = RandomForestRegressor() # featuresCol=&quot;indexedFeatures&quot;,numTrees=2, maxDepth=2, seed=42</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>如果你决定使用<code>indexedFeatures</code>特征，你需要添加参数<code>featuresCol=&quot;indexedFeatures&quot;</code>。</p>
</blockquote>
<p>流水线架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexer and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, rf])</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<p>做出预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;, &quot;prediction&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---------------+-----+------------------+</span><br><span class="line">|       features|label|        prediction|</span><br><span class="line">+---------------+-----+------------------+</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| 8.155439814814816|</span><br><span class="line">| [5.4,29.9,9.4]|  5.3|10.412769901394899|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5| 12.13735648148148|</span><br><span class="line">|[7.8,38.9,50.6]|  6.6|11.321796703296704|</span><br><span class="line">| [8.4,27.2,2.1]|  5.7|12.071421957671957|</span><br><span class="line">+---------------+-----+------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = RegressionEvaluator(</span><br><span class="line">    labelCol=&quot;label&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;rmse&quot;)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Root Mean Squared Error (RMSE) on test data = %g&quot; % rmse)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Root Mean Squared Error (RMSE) on test data = 2.35912</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sklearn.metrics</span><br><span class="line">r2_score = sklearn.metrics.r2_score(y_true, y_pred)</span><br><span class="line">print(&apos;r2_score: &#123;:4.3f&#125;&apos;.format(r2_score))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score: 0.831</span><br></pre></td></tr></table></figure>

<p>特征重要性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.stages[-1].featureImportances</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparseVector(3, &#123;0: 0.4994, 1: 0.3196, 2: 0.181&#125;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.stages[-1].trees</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[DecisionTreeRegressionModel (uid=dtr_c75f1c75442c) of depth 5 with 43 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_70fc2d441581) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_bc8464f545a7) of depth 5 with 31 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_a8a7e5367154) of depth 5 with 59 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_3ea01314fcbc) of depth 5 with 47 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_be9a04ac22a6) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_38610d47328a) of depth 5 with 51 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_bf14aea0ad3b) of depth 5 with 49 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_cde24ebd6bb6) of depth 5 with 39 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_a1fc9bd4fbeb) of depth 5 with 57 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_37798d6db1ba) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_c078b73ada63) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_fd00e3a070ad) of depth 5 with 55 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_9d01d5fb8604) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_8bd8bdddf642) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_e53b7bae30f8) of depth 5 with 49 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_808a869db21c) of depth 5 with 47 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_64d0916bceb0) of depth 5 with 33 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_0891055fff94) of depth 5 with 55 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_19c8bbad26c2) of depth 5 with 51 nodes]</span><br></pre></td></tr></table></figure>

<h2 id="8-5-梯度提升树回归"><a href="#8-5-梯度提升树回归" class="headerlink" title="8.5. 梯度提升树回归"></a>8.5. 梯度提升树回归</h2><h3 id="8-5-1-简介"><a href="#8-5-1-简介" class="headerlink" title="8.5.1. 简介"></a>8.5.1. 简介</h3><h3 id="8-5-2-如何求解"><a href="#8-5-2-如何求解" class="headerlink" title="8.5.2. 如何求解"></a>8.5.2. 如何求解</h3><h3 id="8-5-3-示例"><a href="#8-5-3-示例" class="headerlink" title="8.5.3. 示例"></a>8.5.3. 示例</h3><ul>
<li>Jupyter 笔记本可以从<a href="_static/GLM.ipynb">梯度提升树回归</a>。</li>
<li>参数的更多信息请见<a href="http://takwatanabe.me/pyspark/generated/generated/ml.regression.GBTRegressor.html" target="_blank" rel="noopener">梯度提升树回归 API</a>。</li>
</ul>
<p>建立 spark 上下文和 SparkSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark GBTRegressor example&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<p>加载数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                               options(header=&apos;true&apos;, \</span><br><span class="line">                               inferschema=&apos;true&apos;).\</span><br><span class="line">                               load(&quot;../data/Advertising.csv&quot;,header=True);</span><br><span class="line"></span><br><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|   TV|Radio|Newspaper|Sales|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">|230.1| 37.8|     69.2| 22.1|</span><br><span class="line">| 44.5| 39.3|     45.1| 10.4|</span><br><span class="line">| 17.2| 45.9|     69.3|  9.3|</span><br><span class="line">|151.5| 41.3|     58.5| 18.5|</span><br><span class="line">|180.8| 10.8|     58.4| 12.9|</span><br><span class="line">+-----+-----+---------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- TV: double (nullable = true)</span><br><span class="line"> |-- Radio: double (nullable = true)</span><br><span class="line"> |-- Newspaper: double (nullable = true)</span><br><span class="line"> |-- Sales: double (nullable = true)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">df.describe().show()</span><br><span class="line"></span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|summary|               TV|             Radio|         Newspaper|             Sales|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br><span class="line">|  count|              200|               200|               200|               200|</span><br><span class="line">|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|</span><br><span class="line">| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|</span><br><span class="line">|    min|              0.7|               0.0|               0.3|               1.6|</span><br><span class="line">|    max|            296.4|              49.6|             114.0|              27.0|</span><br><span class="line">+-------+-----------------+------------------+------------------+------------------+</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量（<strong>特征</strong>和<strong>标签</strong>）</p>
<blockquote>
<p>注意</p>
<p>强烈建议您尝试使用我的<code>get_dummy</code>函数来处理数据集中的分类数据。</p>
</blockquote>
<p>监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<p>无监督学习版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">    :param df: the dataframe</span><br><span class="line">    :param categoricalCols: the name list of the categorical data</span><br><span class="line">    :param continuousCols:  the name list of the numerical data</span><br><span class="line">    :return k: feature matrix</span><br><span class="line"></span><br><span class="line">    :author: Wenqiang Feng</span><br><span class="line">    :email:  von198@gmail.com</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    return data.select(indexCol,&apos;features&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># convert the data to dense vector</span><br><span class="line">#def transData(row):</span><br><span class="line">#    return Row(label=row[&quot;Sales&quot;],</span><br><span class="line">#               features=Vectors.dense([row[&quot;TV&quot;],</span><br><span class="line">#                                       row[&quot;Radio&quot;],</span><br><span class="line">#                                       row[&quot;Newspaper&quot;]]))</span><br><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<p>将数据转换为密集向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed= transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+</span><br><span class="line">|         features|label|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|</span><br><span class="line">+-----------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>处理类别变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.regression import GBTRegressor</span><br><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line">from pyspark.ml.evaluation import RegressionEvaluator</span><br><span class="line"></span><br><span class="line">featureIndexer = VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                               outputCol=&quot;indexedFeatures&quot;,\</span><br><span class="line">                               maxCategories=4).fit(transformed)</span><br><span class="line"></span><br><span class="line">data = featureIndexer.transform(transformed)</span><br><span class="line">data.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|         features|label|  indexedFeatures|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|</span><br><span class="line">| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|</span><br><span class="line">| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|</span><br><span class="line">|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|</span><br><span class="line">|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|</span><br><span class="line">+-----------------+-----+-----------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>将数据分割为训练和测试集（留出 40% 用于测试）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-----+----------------+</span><br><span class="line">|        features|label| indexedFeatures|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">|  [0.7,39.6,8.7]|  1.6|  [0.7,39.6,8.7]|</span><br><span class="line">|   [8.6,2.1,1.0]|  4.8|   [8.6,2.1,1.0]|</span><br><span class="line">| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|</span><br><span class="line">|[11.7,36.9,45.2]|  7.3|[11.7,36.9,45.2]|</span><br><span class="line">|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|</span><br><span class="line">+----------------+-----+----------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">|       features|label|indexedFeatures|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|</span><br><span class="line">| [5.4,29.9,9.4]|  5.3| [5.4,29.9,9.4]|</span><br><span class="line">|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|</span><br><span class="line">|[7.8,38.9,50.6]|  6.6|[7.8,38.9,50.6]|</span><br><span class="line">| [8.4,27.2,2.1]|  5.7| [8.4,27.2,2.1]|</span><br><span class="line">+---------------+-----+---------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>拟合梯度提升树模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Import LinearRegression class</span><br><span class="line">from pyspark.ml.regression import GBTRegressor</span><br><span class="line"></span><br><span class="line"># Define LinearRegression algorithm</span><br><span class="line">rf = GBTRegressor() #numTrees=2, maxDepth=2, seed=42</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意</p>
<p>如果你决定使用<code>indexedFeatures</code>特征，你需要添加参数<code>featuresCol=&quot;indexedFeatures&quot;</code>。</p>
</blockquote>
<p>流水线架构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexer and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, rf])</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<p>做出预测</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;, &quot;prediction&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+----------------+-----+------------------+</span><br><span class="line">|        features|label|        prediction|</span><br><span class="line">+----------------+-----+------------------+</span><br><span class="line">| [7.8,38.9,50.6]|  6.6| 6.836040343319862|</span><br><span class="line">|   [8.6,2.1,1.0]|  4.8| 5.652202764688849|</span><br><span class="line">| [8.7,48.9,75.0]|  7.2| 6.908750296855572|</span><br><span class="line">| [13.1,0.4,25.6]|  5.3| 5.784020210692574|</span><br><span class="line">|[19.6,20.1,17.0]|  7.6|6.8678921062629295|</span><br><span class="line">+----------------+-----+------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<p>评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = RegressionEvaluator(</span><br><span class="line">    labelCol=&quot;label&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;rmse&quot;)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Root Mean Squared Error (RMSE) on test data = %g&quot; % rmse)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Root Mean Squared Error (RMSE) on test data = 1.36939</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sklearn.metrics</span><br><span class="line">r2_score = sklearn.metrics.r2_score(y_true, y_pred)</span><br><span class="line">print(&apos;r2_score: &#123;:4.3f&#125;&apos;.format(r2_score))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_score: 0.932</span><br></pre></td></tr></table></figure>

<p>特征重要性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.stages[-1].featureImportances</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparseVector(3, &#123;0: 0.3716, 1: 0.3525, 2: 0.2759&#125;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.stages[-1].trees</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[DecisionTreeRegressionModel (uid=dtr_7f5cd2ef7cb6) of depth 5 with 61 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_ef3ab6baeac9) of depth 5 with 39 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_07c6e3cf3819) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_ce724af79a2b) of depth 5 with 47 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_d149ecc71658) of depth 5 with 55 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_d3a79bdea516) of depth 5 with 43 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_7abc1a337844) of depth 5 with 51 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_480834b46d8f) of depth 5 with 33 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_0cbd1eaa3874) of depth 5 with 39 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_8088ac71a204) of depth 5 with 57 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_2ceb9e8deb45) of depth 5 with 47 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_cc334e84e9a2) of depth 5 with 57 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_a665c562929e) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_2999b1ffd2dc) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_29965cbe8cfc) of depth 5 with 55 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_731df51bf0ad) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_354cf33424da) of depth 5 with 51 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_4230f200b1c0) of depth 5 with 41 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_3279cdc1ce1d) of depth 5 with 45 nodes,</span><br><span class="line"> DecisionTreeRegressionModel (uid=dtr_f474a99ff06e) of depth 5 with 55 nodes]</span><br></pre></td></tr></table></figure>

<h1 id="10-Classification"><a href="#10-Classification" class="headerlink" title="10. Classification"></a>10. Classification</h1><p>Chinese proverb</p>
<p><strong>Birds of a feather folock together.</strong> – old Chinese proverb</p>
<h2 id="10-1-Binomial-logistic-regression"><a href="#10-1-Binomial-logistic-regression" class="headerlink" title="10.1. Binomial logistic regression"></a>10.1. Binomial logistic regression</h2><h3 id="10-1-1-Introduction"><a href="#10-1-1-Introduction" class="headerlink" title="10.1.1. Introduction"></a>10.1.1. Introduction</h3><h3 id="10-1-2-Demo"><a href="#10-1-2-Demo" class="headerlink" title="10.1.2. Demo"></a>10.1.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/logisticRegression.ipynb">Logistic Regression</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.BinaryLogisticRegressionSummary.html" target="_blank" rel="noopener">Logistic Regression API</a> .</li>
</ul>
<p>Note</p>
<p>In this demo, I introduced a new function <code>get_dummy</code> to deal with the categorical data. I highly recommend you to use my <code>get_dummy</code> function in the other cases. This function will save a lot of time for you.</p>
<ol>
<li>Set up spark context and SparkSession</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">        spark = SparkSession \</span><br><span class="line">            .builder \</span><br><span class="line">            .appName(&quot;Python Spark Logistic Regression example&quot;) \</span><br><span class="line">            .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">            .getOrCreate()</span><br></pre></td></tr></table></figure>

<ol>
<li>Load dataset</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;) \</span><br><span class="line">            .options(header=&apos;true&apos;, inferschema=&apos;true&apos;) \</span><br><span class="line">            .load(&quot;./data/bank.csv&quot;,header=True);</span><br><span class="line">df.drop(&apos;day&apos;,&apos;month&apos;,&apos;poutcome&apos;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---+------------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+---+</span><br><span class="line">|age|         job|marital|education|default|balance|housing|loan|contact|duration|campaign|pdays|previous|  y|</span><br><span class="line">+---+------------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+---+</span><br><span class="line">| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|     261|       1|   -1|       0| no|</span><br><span class="line">| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|     151|       1|   -1|       0| no|</span><br><span class="line">| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|      76|       1|   -1|       0| no|</span><br><span class="line">| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|      92|       1|   -1|       0| no|</span><br><span class="line">| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|     198|       1|   -1|       0| no|</span><br><span class="line">+---+------------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+---+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- age: integer (nullable = true)</span><br><span class="line"> |-- job: string (nullable = true)</span><br><span class="line"> |-- marital: string (nullable = true)</span><br><span class="line"> |-- education: string (nullable = true)</span><br><span class="line"> |-- default: string (nullable = true)</span><br><span class="line"> |-- balance: integer (nullable = true)</span><br><span class="line"> |-- housing: string (nullable = true)</span><br><span class="line"> |-- loan: string (nullable = true)</span><br><span class="line"> |-- contact: string (nullable = true)</span><br><span class="line"> |-- day: integer (nullable = true)</span><br><span class="line"> |-- month: string (nullable = true)</span><br><span class="line"> |-- duration: integer (nullable = true)</span><br><span class="line"> |-- campaign: integer (nullable = true)</span><br><span class="line"> |-- pdays: integer (nullable = true)</span><br><span class="line"> |-- previous: integer (nullable = true)</span><br><span class="line"> |-- poutcome: string (nullable = true)</span><br><span class="line"> |-- y: string (nullable = true)</span><br></pre></td></tr></table></figure>

<p>Note</p>
<p>You are strongly encouraged to try my <code>get_dummy</code> function for dealing with the categorical data in complex dataset.</p>
<p>Supervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line">&gt; </span><br><span class="line">&gt;  from pyspark.ml import Pipeline</span><br><span class="line">&gt;  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">&gt;  from pyspark.sql.functions import col</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>Unsupervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt;  Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">&gt;  :param df: the dataframe</span><br><span class="line">&gt;  :param categoricalCols: the name list of the categorical data</span><br><span class="line">&gt;  :param continuousCols:  the name list of the numerical data</span><br><span class="line">&gt;  :return k: feature matrix</span><br><span class="line">&gt; </span><br><span class="line">&gt;  :author: Wenqiang Feng</span><br><span class="line">&gt;  :email:  von198@gmail.com</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with categorical data and Convert the data to dense vector</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">catcols = [&apos;job&apos;,&apos;marital&apos;,&apos;education&apos;,&apos;default&apos;,</span><br><span class="line">           &apos;housing&apos;,&apos;loan&apos;,&apos;contact&apos;,&apos;poutcome&apos;]</span><br><span class="line"></span><br><span class="line">num_cols = [&apos;balance&apos;, &apos;duration&apos;,&apos;campaign&apos;,&apos;pdays&apos;,&apos;previous&apos;,]</span><br><span class="line">labelCol = &apos;y&apos;</span><br><span class="line"></span><br><span class="line">data = get_dummy(df,catcols,num_cols,labelCol)</span><br><span class="line">data.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+</span><br><span class="line">|            features|label|</span><br><span class="line">+--------------------+-----+</span><br><span class="line">|(29,[1,11,14,16,1...|   no|</span><br><span class="line">|(29,[2,12,13,16,1...|   no|</span><br><span class="line">|(29,[7,11,13,16,1...|   no|</span><br><span class="line">|(29,[0,11,16,17,1...|   no|</span><br><span class="line">|(29,[12,16,18,20,...|   no|</span><br><span class="line">+--------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with Categorical Label and Variables</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.feature import StringIndexer</span><br><span class="line"># Index labels, adding metadata to the label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&apos;label&apos;,</span><br><span class="line">                             outputCol=&apos;indexedLabel&apos;).fit(data)</span><br><span class="line">labelIndexer.transform(data).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+------------+</span><br><span class="line">|            features|label|indexedLabel|</span><br><span class="line">+--------------------+-----+------------+</span><br><span class="line">|(29,[1,11,14,16,1...|   no|         0.0|</span><br><span class="line">|(29,[2,12,13,16,1...|   no|         0.0|</span><br><span class="line">|(29,[7,11,13,16,1...|   no|         0.0|</span><br><span class="line">|(29,[0,11,16,17,1...|   no|         0.0|</span><br><span class="line">|(29,[12,16,18,20,...|   no|         0.0|</span><br><span class="line">+--------------------+-----+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.feature import VectorIndexer</span><br><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line">featureIndexer =VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                                  outputCol=&quot;indexedFeatures&quot;, \</span><br><span class="line">                                  maxCategories=4).fit(data)</span><br><span class="line">featureIndexer.transform(data).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">|            features|label|     indexedFeatures|</span><br><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">|(29,[1,11,14,16,1...|   no|(29,[1,11,14,16,1...|</span><br><span class="line">|(29,[2,12,13,16,1...|   no|(29,[2,12,13,16,1...|</span><br><span class="line">|(29,[7,11,13,16,1...|   no|(29,[7,11,13,16,1...|</span><br><span class="line">|(29,[0,11,16,17,1...|   no|(29,[0,11,16,17,1...|</span><br><span class="line">|(29,[12,16,18,20,...|   no|(29,[12,16,18,20,...|</span><br><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Split the data to training and test data sets</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5,False)</span><br><span class="line">testData.show(5,False)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">|features                                                                                         |label|</span><br><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-731.0,401.0,4.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-723.0,112.0,2.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-626.0,205.0,1.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-498.0,357.0,1.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-477.0,473.0,2.0,-1.0])|no   |</span><br><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">|features                                                                                         |label|</span><br><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-648.0,280.0,2.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-596.0,147.0,1.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-529.0,416.0,4.0,-1.0])|no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-518.0,46.0,5.0,-1.0]) |no   |</span><br><span class="line">|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-470.0,275.0,2.0,-1.0])|no   |</span><br><span class="line">+-------------------------------------------------------------------------------------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Fit Logistic Regression Model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import LogisticRegression</span><br><span class="line">logr = LogisticRegression(featuresCol=&apos;indexedFeatures&apos;, labelCol=&apos;indexedLabel&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Pipeline Architecture</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Convert indexed labels back to original labels.</span><br><span class="line">labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexers and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, logr,labelConverter])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Train model.  This also runs the indexers.</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<ol>
<li>Make predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+--------------+</span><br><span class="line">|            features|label|predictedLabel|</span><br><span class="line">+--------------------+-----+--------------+</span><br><span class="line">|(29,[0,11,13,16,1...|   no|            no|</span><br><span class="line">|(29,[0,11,13,16,1...|   no|            no|</span><br><span class="line">|(29,[0,11,13,16,1...|   no|            no|</span><br><span class="line">|(29,[0,11,13,16,1...|   no|            no|</span><br><span class="line">|(29,[0,11,13,16,1...|   no|            no|</span><br><span class="line">+--------------------+-----+--------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Evaluation</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %g&quot; % (1.0 - accuracy))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.0987688</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">lrModel = model.stages[2]</span><br><span class="line">trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line"># Obtain the objective per iteration</span><br><span class="line"># objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line"># print(&quot;objectiveHistory:&quot;)</span><br><span class="line"># for objective in objectiveHistory:</span><br><span class="line">#     print(objective)</span><br><span class="line"></span><br><span class="line"># Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.</span><br><span class="line">trainingSummary.roc.show(5)</span><br><span class="line">print(&quot;areaUnderROC: &quot; + str(trainingSummary.areaUnderROC))</span><br><span class="line"></span><br><span class="line"># Set the model threshold to maximize F-Measure</span><br><span class="line">fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">maxFMeasure = fMeasure.groupBy().max(&apos;F-Measure&apos;).select(&apos;max(F-Measure)&apos;).head(5)</span><br><span class="line"># bestThreshold = fMeasure.where(fMeasure[&apos;F-Measure&apos;] == maxFMeasure[&apos;max(F-Measure)&apos;]) \</span><br><span class="line">#     .select(&apos;threshold&apos;).head()[&apos;threshold&apos;]</span><br><span class="line"># lr.setThreshold(bestThreshold)</span><br></pre></td></tr></table></figure>

<p>You can use <code>z.show()</code> to get the data and plot the ROC curves:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc_z.png"></p>
<p>You can also register a TempTable <code>data.registerTempTable(&#39;roc_data&#39;)</code> and then use <code>sql</code> to plot the ROC curve:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc.png"></p>
<ol>
<li>visualization</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">def plot_confusion_matrix(cm, classes,</span><br><span class="line">                          normalize=False,</span><br><span class="line">                          title=&apos;Confusion matrix&apos;,</span><br><span class="line">                          cmap=plt.cm.Blues):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    This function prints and plots the confusion matrix.</span><br><span class="line">    Normalization can be applied by setting `normalize=True`.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if normalize:</span><br><span class="line">        cm = cm.astype(&apos;float&apos;) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line">        print(&quot;Normalized confusion matrix&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line"></span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.imshow(cm, interpolation=&apos;nearest&apos;, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=45)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    fmt = &apos;.2f&apos; if normalize else &apos;d&apos;</span><br><span class="line">    thresh = cm.max() / 2.</span><br><span class="line">    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):</span><br><span class="line">        plt.text(j, i, format(cm[i, j], fmt),</span><br><span class="line">                 horizontalalignment=&quot;center&quot;,</span><br><span class="line">                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(&apos;True label&apos;)</span><br><span class="line">    plt.xlabel(&apos;Predicted label&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class_temp = predictions.select(&quot;label&quot;).groupBy(&quot;label&quot;)\</span><br><span class="line">                        .count().sort(&apos;count&apos;, ascending=False).toPandas()</span><br><span class="line">class_temp = class_temp[&quot;label&quot;].values.tolist()</span><br><span class="line">class_names = map(str, class_temp)</span><br><span class="line"># # # print(class_name)</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;no&apos;, &apos;yes&apos;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = predictions.select(&quot;label&quot;)</span><br><span class="line">y_true = y_true.toPandas()</span><br><span class="line"></span><br><span class="line">y_pred = predictions.select(&quot;predictedLabel&quot;)</span><br><span class="line">y_pred = y_pred.toPandas()</span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)</span><br><span class="line">cnf_matrix</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[15657,   379],</span><br><span class="line">       [ 1410,   667]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Plot non-normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names,</span><br><span class="line">                      title=&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Confusion matrix, without normalization</span><br><span class="line">[[15657   379]</span><br><span class="line"> [ 1410   667]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/7bb886fc0ea7d5d1144002edd99e0c7f.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/logr_b1.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Plot normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span><br><span class="line">                      title=&apos;Normalized confusion matrix&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Normalized confusion matrix</span><br><span class="line">[[ 0.97636568  0.02363432]</span><br><span class="line"> [ 0.67886375  0.32113625]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/86176a13e0a00622dbc982348d7ca623.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/logr_b2.png"></p>
<h2 id="10-2-Multinomial-logistic-regression"><a href="#10-2-Multinomial-logistic-regression" class="headerlink" title="10.2. Multinomial logistic regression"></a>10.2. Multinomial logistic regression</h2><h3 id="10-2-1-Introduction"><a href="#10-2-1-Introduction" class="headerlink" title="10.2.1. Introduction"></a>10.2.1. Introduction</h3><h3 id="10-2-2-Demo"><a href="#10-2-2-Demo" class="headerlink" title="10.2.2. Demo"></a>10.2.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/logisticRegression.ipynb">Logistic Regression</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.BinaryLogisticRegressionSummary.html" target="_blank" rel="noopener">Logistic Regression API</a> .</li>
</ul>
<p>Note</p>
<p>In this demo, I introduced a new function <code>get_dummy</code> to deal with the categorical data. I highly recommend you to use my <code>get_dummy</code> function in the other cases. This function will save a lot of time for you.</p>
<ol>
<li>Set up spark context and SparkSession</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark MultinomialLogisticRegression classification&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<ol>
<li>Load dataset</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;) \</span><br><span class="line">            .options(header=&apos;true&apos;, inferschema=&apos;true&apos;) \</span><br><span class="line">            .load(&quot;./data/WineData2.csv&quot;,header=True);</span><br><span class="line">df.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8|      5|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8|      5|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8|      6|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Convert to float format</span><br><span class="line">def string_to_float(x):</span><br><span class="line">    return float(x)</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">def condition(r):</span><br><span class="line">    if (0&lt;= r &lt;= 4):</span><br><span class="line">        label = &quot;low&quot;</span><br><span class="line">    elif(4&lt; r &lt;= 6):</span><br><span class="line">        label = &quot;medium&quot;</span><br><span class="line">    else:</span><br><span class="line">        label = &quot;high&quot;</span><br><span class="line">    return label</span><br><span class="line"></span><br><span class="line">from pyspark.sql.functions import udf</span><br><span class="line">from pyspark.sql.types import StringType, DoubleType</span><br><span class="line">string_to_float_udf = udf(string_to_float, DoubleType())</span><br><span class="line">quality_udf = udf(lambda x: condition(x), StringType())</span><br><span class="line"></span><br><span class="line">df = df.withColumn(&quot;quality&quot;, quality_udf(&quot;quality&quot;))</span><br><span class="line"></span><br><span class="line">df.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8| medium|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8| medium|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8| medium|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with categorical data and Convert the data to dense vector</li>
</ol>
<p>Note</p>
<p>You are strongly encouraged to try my <code>get_dummy</code> function for dealing with the categorical data in complex dataset.</p>
<p>Supervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line">&gt; </span><br><span class="line">&gt;  from pyspark.ml import Pipeline</span><br><span class="line">&gt;  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">&gt;  from pyspark.sql.functions import col</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>Unsupervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt;  Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">&gt;  :param df: the dataframe</span><br><span class="line">&gt;  :param categoricalCols: the name list of the categorical data</span><br><span class="line">&gt;  :param continuousCols:  the name list of the numerical data</span><br><span class="line">&gt;  :return k: feature matrix</span><br><span class="line">&gt; </span><br><span class="line">&gt;  :author: Wenqiang Feng</span><br><span class="line">&gt;  :email:  von198@gmail.com</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Transform the dataset to DataFrame</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.linalg import Vectors # !!!!caution: not from pyspark.mllib.linalg import Vectors</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.tuning import CrossValidator, ParamGridBuilder</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line">def transData(data):</span><br><span class="line">return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed = transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with Categorical Label and Variables</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Index labels, adding metadata to the label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&apos;label&apos;,</span><br><span class="line">                             outputCol=&apos;indexedLabel&apos;).fit(transformed)</span><br><span class="line">labelIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+------------+</span><br><span class="line">|            features| label|indexedLabel|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|         0.0|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|         0.0|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|         0.0|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line">featureIndexer =VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                              outputCol=&quot;indexedFeatures&quot;, \</span><br><span class="line">                              maxCategories=4).fit(transformed)</span><br><span class="line">featureIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|            features| label|     indexedFeatures|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|[7.8,0.88,0.0,2.6...|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|[7.8,0.76,0.04,2....|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|[11.2,0.28,0.56,1...|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Split the data to training and test data sets</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5,False)</span><br><span class="line">testData.show(5,False)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">|features                                                 |label |</span><br><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">|[4.7,0.6,0.17,2.3,0.058,17.0,106.0,0.9932,3.85,0.6,12.9] |medium|</span><br><span class="line">|[5.0,0.38,0.01,1.6,0.048,26.0,60.0,0.99084,3.7,0.75,14.0]|medium|</span><br><span class="line">|[5.0,0.4,0.5,4.3,0.046,29.0,80.0,0.9902,3.49,0.66,13.6]  |medium|</span><br><span class="line">|[5.0,0.74,0.0,1.2,0.041,16.0,46.0,0.99258,4.01,0.59,12.5]|medium|</span><br><span class="line">|[5.1,0.42,0.0,1.8,0.044,18.0,88.0,0.99157,3.68,0.73,13.6]|high  |</span><br><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">|features                                                 |label |</span><br><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">|[4.6,0.52,0.15,2.1,0.054,8.0,65.0,0.9934,3.9,0.56,13.1]  |low   |</span><br><span class="line">|[4.9,0.42,0.0,2.1,0.048,16.0,42.0,0.99154,3.71,0.74,14.0]|high  |</span><br><span class="line">|[5.0,0.42,0.24,2.0,0.06,19.0,50.0,0.9917,3.72,0.74,14.0] |high  |</span><br><span class="line">|[5.0,1.02,0.04,1.4,0.045,41.0,85.0,0.9938,3.75,0.48,10.5]|low   |</span><br><span class="line">|[5.0,1.04,0.24,1.6,0.05,32.0,96.0,0.9934,3.74,0.62,11.5] |medium|</span><br><span class="line">+---------------------------------------------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Fit Multinomial logisticRegression Classification Model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import LogisticRegression</span><br><span class="line">logr = LogisticRegression(featuresCol=&apos;indexedFeatures&apos;, labelCol=&apos;indexedLabel&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Pipeline Architecture</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Convert indexed labels back to original labels.</span><br><span class="line">labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexers and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, logr,labelConverter])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Train model.  This also runs the indexers.</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<ol>
<li>Make predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------+</span><br><span class="line">|            features| label|predictedLabel|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">|[4.6,0.52,0.15,2....|   low|        medium|</span><br><span class="line">|[4.9,0.42,0.0,2.1...|  high|          high|</span><br><span class="line">|[5.0,0.42,0.24,2....|  high|          high|</span><br><span class="line">|[5.0,1.02,0.04,1....|   low|        medium|</span><br><span class="line">|[5.0,1.04,0.24,1....|medium|        medium|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Evaluation</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %g&quot; % (1.0 - accuracy))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.181287</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">lrModel = model.stages[2]</span><br><span class="line">trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line"># Obtain the objective per iteration</span><br><span class="line"># objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line"># print(&quot;objectiveHistory:&quot;)</span><br><span class="line"># for objective in objectiveHistory:</span><br><span class="line">#     print(objective)</span><br><span class="line"></span><br><span class="line"># Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.</span><br><span class="line">trainingSummary.roc.show(5)</span><br><span class="line">print(&quot;areaUnderROC: &quot; + str(trainingSummary.areaUnderROC))</span><br><span class="line"></span><br><span class="line"># Set the model threshold to maximize F-Measure</span><br><span class="line">fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">maxFMeasure = fMeasure.groupBy().max(&apos;F-Measure&apos;).select(&apos;max(F-Measure)&apos;).head(5)</span><br><span class="line"># bestThreshold = fMeasure.where(fMeasure[&apos;F-Measure&apos;] == maxFMeasure[&apos;max(F-Measure)&apos;]) \</span><br><span class="line">#     .select(&apos;threshold&apos;).head()[&apos;threshold&apos;]</span><br><span class="line"># lr.setThreshold(bestThreshold)</span><br></pre></td></tr></table></figure>

<p>You can use <code>z.show()</code> to get the data and plot the ROC curves:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc_z.png"></p>
<p>You can also register a TempTable <code>data.registerTempTable(&#39;roc_data&#39;)</code> and then use <code>sql</code> to plot the ROC curve:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc.png"></p>
<ol>
<li>visualization</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">def plot_confusion_matrix(cm, classes,</span><br><span class="line">                          normalize=False,</span><br><span class="line">                          title=&apos;Confusion matrix&apos;,</span><br><span class="line">                          cmap=plt.cm.Blues):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    This function prints and plots the confusion matrix.</span><br><span class="line">    Normalization can be applied by setting `normalize=True`.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if normalize:</span><br><span class="line">        cm = cm.astype(&apos;float&apos;) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line">        print(&quot;Normalized confusion matrix&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line"></span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.imshow(cm, interpolation=&apos;nearest&apos;, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=45)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    fmt = &apos;.2f&apos; if normalize else &apos;d&apos;</span><br><span class="line">    thresh = cm.max() / 2.</span><br><span class="line">    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):</span><br><span class="line">        plt.text(j, i, format(cm[i, j], fmt),</span><br><span class="line">                 horizontalalignment=&quot;center&quot;,</span><br><span class="line">                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(&apos;True label&apos;)</span><br><span class="line">    plt.xlabel(&apos;Predicted label&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class_temp = predictions.select(&quot;label&quot;).groupBy(&quot;label&quot;)\</span><br><span class="line">                        .count().sort(&apos;count&apos;, ascending=False).toPandas()</span><br><span class="line">class_temp = class_temp[&quot;label&quot;].values.tolist()</span><br><span class="line">class_names = map(str, class_temp)</span><br><span class="line"># # # print(class_name)</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;medium&apos;, &apos;high&apos;, &apos;low&apos;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = predictions.select(&quot;label&quot;)</span><br><span class="line">y_true = y_true.toPandas()</span><br><span class="line"></span><br><span class="line">y_pred = predictions.select(&quot;predictedLabel&quot;)</span><br><span class="line">y_pred = y_pred.toPandas()</span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)</span><br><span class="line">cnf_matrix</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[526,  11,   2],</span><br><span class="line">       [ 73,  33,   0],</span><br><span class="line">       [ 38,   0,   1]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Plot non-normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names,</span><br><span class="line">                      title=&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Confusion matrix, without normalization</span><br><span class="line">[[526  11   2]</span><br><span class="line"> [ 73  33   0]</span><br><span class="line"> [ 38   0   1]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/189ce8661099fd6f1118f978d53cf85b.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/mlrconfu1.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Plot normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span><br><span class="line">                      title=&apos;Normalized confusion matrix&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Normalized confusion matrix</span><br><span class="line">[[0.97588126 0.02040816 0.00371058]</span><br><span class="line"> [0.68867925 0.31132075 0\.        ]</span><br><span class="line"> [0.97435897 0\.         0.02564103]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/1c57212c22a6a7777decfa1971418148.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/mlrconfu2.png"></p>
<h2 id="10-3-Decision-tree-Classification"><a href="#10-3-Decision-tree-Classification" class="headerlink" title="10.3. Decision tree Classification"></a>10.3. Decision tree Classification</h2><h3 id="10-3-1-Introduction"><a href="#10-3-1-Introduction" class="headerlink" title="10.3.1. Introduction"></a>10.3.1. Introduction</h3><h3 id="10-3-2-Demo"><a href="#10-3-2-Demo" class="headerlink" title="10.3.2. Demo"></a>10.3.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/DecisionTreeC.ipynb">Decision Tree Classification</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.DecisionTreeClassifier.html" target="_blank" rel="noopener">DecisionTreeClassifier API</a> .</li>
</ul>
<ol>
<li>Set up spark context and SparkSession</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">        spark = SparkSession \</span><br><span class="line">            .builder \</span><br><span class="line">            .appName(&quot;Python Spark Decision Tree classification&quot;) \</span><br><span class="line">            .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">            .getOrCreate()</span><br></pre></td></tr></table></figure>

<ol>
<li>Load dataset</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                               options(header=&apos;true&apos;, \</span><br><span class="line">                               inferschema=&apos;true&apos;) \</span><br><span class="line">                .load(&quot;../data/WineData2.csv&quot;,header=True);</span><br><span class="line">df.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8|      5|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8|      5|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8|      6|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Convert to float format</span><br><span class="line">def string_to_float(x):</span><br><span class="line">    return float(x)</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">def condition(r):</span><br><span class="line">    if (0&lt;= r &lt;= 4):</span><br><span class="line">        label = &quot;low&quot;</span><br><span class="line">    elif(4&lt; r &lt;= 6):</span><br><span class="line">        label = &quot;medium&quot;</span><br><span class="line">    else:</span><br><span class="line">        label = &quot;high&quot;</span><br><span class="line">    return label</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql.functions import udf</span><br><span class="line">from pyspark.sql.types import StringType, DoubleType</span><br><span class="line">string_to_float_udf = udf(string_to_float, DoubleType())</span><br><span class="line">quality_udf = udf(lambda x: condition(x), StringType())</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(&quot;quality&quot;, quality_udf(&quot;quality&quot;))</span><br><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8| medium|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8| medium|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8| medium|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<ol>
<li>Convert the data to dense vector</li>
</ol>
<p>Note</p>
<p>You are strongly encouraged to try my <code>get_dummy</code> function for dealing with the categorical data in complex dataset.</p>
<p>Supervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line">&gt; </span><br><span class="line">&gt;  from pyspark.ml import Pipeline</span><br><span class="line">&gt;  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">&gt;  from pyspark.sql.functions import col</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>Unsupervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt;  Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">&gt;  :param df: the dataframe</span><br><span class="line">&gt;  :param categoricalCols: the name list of the categorical data</span><br><span class="line">&gt;  :param continuousCols:  the name list of the numerical data</span><br><span class="line">&gt;  :return k: feature matrix</span><br><span class="line">&gt; </span><br><span class="line">&gt;  :author: Wenqiang Feng</span><br><span class="line">&gt;  :email:  von198@gmail.com</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># !!!!caution: not from pyspark.mllib.linalg import Vectors</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.tuning import CrossValidator, ParamGridBuilder</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<ol>
<li>Transform the dataset to DataFrame</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed = transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with Categorical Label and Variables</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Index labels, adding metadata to the label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&apos;label&apos;,</span><br><span class="line">                             outputCol=&apos;indexedLabel&apos;).fit(transformed)</span><br><span class="line">labelIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+------------+</span><br><span class="line">|            features| label|indexedLabel|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|         0.0|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|         0.0|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|         0.0|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    # Automatically identify categorical features, and index them.</span><br><span class="line">    # Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line">    featureIndexer =VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                                  outputCol=&quot;indexedFeatures&quot;, \</span><br><span class="line">                                  maxCategories=4).fit(transformed)</span><br><span class="line">featureIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|            features| label|     indexedFeatures|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|[7.8,0.88,0.0,2.6...|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|[7.8,0.76,0.04,2....|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|[11.2,0.28,0.56,1...|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Split the data to training and test data sets</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = transformed.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[4.6,0.52,0.15,2....|   low|</span><br><span class="line">|[4.7,0.6,0.17,2.3...|medium|</span><br><span class="line">|[5.0,1.02,0.04,1....|   low|</span><br><span class="line">|[5.0,1.04,0.24,1....|medium|</span><br><span class="line">|[5.1,0.585,0.0,1....|  high|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[4.9,0.42,0.0,2.1...|  high|</span><br><span class="line">|[5.0,0.38,0.01,1....|medium|</span><br><span class="line">|[5.0,0.4,0.5,4.3,...|medium|</span><br><span class="line">|[5.0,0.42,0.24,2....|  high|</span><br><span class="line">|[5.0,0.74,0.0,1.2...|medium|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Fit Decision Tree Classification Model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"># Train a DecisionTree model</span><br><span class="line">dTree = DecisionTreeClassifier(labelCol=&apos;indexedLabel&apos;, featuresCol=&apos;indexedFeatures&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Pipeline Architecture</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Convert indexed labels back to original labels.</span><br><span class="line">labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexers and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dTree,labelConverter])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Train model.  This also runs the indexers.</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<ol>
<li>Make predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------+</span><br><span class="line">|            features| label|predictedLabel|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">|[4.9,0.42,0.0,2.1...|  high|          high|</span><br><span class="line">|[5.0,0.38,0.01,1....|medium|        medium|</span><br><span class="line">|[5.0,0.4,0.5,4.3,...|medium|        medium|</span><br><span class="line">|[5.0,0.42,0.24,2....|  high|        medium|</span><br><span class="line">|[5.0,0.74,0.0,1.2...|medium|        medium|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Evaluation</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %g&quot; % (1.0 - accuracy))</span><br><span class="line"></span><br><span class="line">rfModel = model.stages[-2]</span><br><span class="line">print(rfModel)  # summary only</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.45509</span><br><span class="line">DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4545ac8dca9c8438ef2a)</span><br><span class="line">of depth 5 with 59 nodes</span><br></pre></td></tr></table></figure>

<ol>
<li>visualization</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">def plot_confusion_matrix(cm, classes,</span><br><span class="line">                          normalize=False,</span><br><span class="line">                          title=&apos;Confusion matrix&apos;,</span><br><span class="line">                          cmap=plt.cm.Blues):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    This function prints and plots the confusion matrix.</span><br><span class="line">    Normalization can be applied by setting `normalize=True`.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if normalize:</span><br><span class="line">        cm = cm.astype(&apos;float&apos;) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line">        print(&quot;Normalized confusion matrix&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line"></span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.imshow(cm, interpolation=&apos;nearest&apos;, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=45)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    fmt = &apos;.2f&apos; if normalize else &apos;d&apos;</span><br><span class="line">    thresh = cm.max() / 2.</span><br><span class="line">    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):</span><br><span class="line">        plt.text(j, i, format(cm[i, j], fmt),</span><br><span class="line">                 horizontalalignment=&quot;center&quot;,</span><br><span class="line">                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(&apos;True label&apos;)</span><br><span class="line">    plt.xlabel(&apos;Predicted label&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class_temp = predictions.select(&quot;label&quot;).groupBy(&quot;label&quot;)\</span><br><span class="line">                        .count().sort(&apos;count&apos;, ascending=False).toPandas()</span><br><span class="line">class_temp = class_temp[&quot;label&quot;].values.tolist()</span><br><span class="line">class_names = map(str, class_temp)</span><br><span class="line"># # # print(class_name)</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;medium&apos;, &apos;high&apos;, &apos;low&apos;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = predictions.select(&quot;label&quot;)</span><br><span class="line">y_true = y_true.toPandas()</span><br><span class="line"></span><br><span class="line">y_pred = predictions.select(&quot;predictedLabel&quot;)</span><br><span class="line">y_pred = y_pred.toPandas()</span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)</span><br><span class="line">cnf_matrix</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[497,  29,   7],</span><br><span class="line">       [ 40,  42,   0],</span><br><span class="line">       [ 22,   0,   2]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Plot non-normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names,</span><br><span class="line">                      title=&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Confusion matrix, without normalization</span><br><span class="line">[[497  29   7]</span><br><span class="line"> [ 40  42   0]</span><br><span class="line"> [ 22   0   2]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/94b77459ef6ab620703ddb014430c700.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/dt_cm_c3.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Plot normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span><br><span class="line">                      title=&apos;Normalized confusion matrix&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Normalized confusion matrix</span><br><span class="line">[[ 0.93245779  0.05440901  0.01313321]</span><br><span class="line"> [ 0.48780488  0.51219512  0\.        ]</span><br><span class="line"> [ 0.91666667  0\.          0.08333333]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/94b77459ef6ab620703ddb014430c700.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/dt_cm_c3.png"></p>
<h2 id="10-4-Random-forest-Classification"><a href="#10-4-Random-forest-Classification" class="headerlink" title="10.4. Random forest Classification"></a>10.4. Random forest Classification</h2><h3 id="10-4-1-Introduction"><a href="#10-4-1-Introduction" class="headerlink" title="10.4.1. Introduction"></a>10.4.1. Introduction</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/2Mg8QD0F1dQ" frameborder="0" allowfullscreen></iframe>

<h3 id="10-4-2-Demo"><a href="#10-4-2-Demo" class="headerlink" title="10.4.2. Demo"></a>10.4.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/RandomForestC3.ipynb">Random forest Classification</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.RandomForestClassifier.html" target="_blank" rel="noopener">RandomForestClassifier API</a> .</li>
</ul>
<ol>
<li>Set up spark context and SparkSession</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">        spark = SparkSession \</span><br><span class="line">            .builder \</span><br><span class="line">            .appName(&quot;Python Spark Decision Tree classification&quot;) \</span><br><span class="line">            .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">            .getOrCreate()</span><br></pre></td></tr></table></figure>

<ol>
<li>Load dataset</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;).\</span><br><span class="line">                               options(header=&apos;true&apos;, \</span><br><span class="line">                               inferschema=&apos;true&apos;) \</span><br><span class="line">                .load(&quot;../data/WineData2.csv&quot;,header=True);</span><br><span class="line">df.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8|      5|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8|      5|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8|      6|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Convert to float format</span><br><span class="line">def string_to_float(x):</span><br><span class="line">    return float(x)</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">def condition(r):</span><br><span class="line">    if (0&lt;= r &lt;= 4):</span><br><span class="line">        label = &quot;low&quot;</span><br><span class="line">    elif(4&lt; r &lt;= 6):</span><br><span class="line">        label = &quot;medium&quot;</span><br><span class="line">    else:</span><br><span class="line">        label = &quot;high&quot;</span><br><span class="line">    return label</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql.functions import udf</span><br><span class="line">from pyspark.sql.types import StringType, DoubleType</span><br><span class="line">string_to_float_udf = udf(string_to_float, DoubleType())</span><br><span class="line">quality_udf = udf(lambda x: condition(x), StringType())</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(&quot;quality&quot;, quality_udf(&quot;quality&quot;))</span><br><span class="line">df.show(5,True)</span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8| medium|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8| medium|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8| medium|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<ol>
<li>Convert the data to dense vector</li>
</ol>
<p>Note</p>
<p>You are strongly encouraged to try my <code>get_dummy</code> function for dealing with the categorical data in complex dataset.</p>
<p>Supervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line">&gt; </span><br><span class="line">&gt;  from pyspark.ml import Pipeline</span><br><span class="line">&gt;  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">&gt;  from pyspark.sql.functions import col</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>Unsupervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt;  Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">&gt;  :param df: the dataframe</span><br><span class="line">&gt;  :param categoricalCols: the name list of the categorical data</span><br><span class="line">&gt;  :param continuousCols:  the name list of the numerical data</span><br><span class="line">&gt;  :return k: feature matrix</span><br><span class="line">&gt; </span><br><span class="line">&gt;  :author: Wenqiang Feng</span><br><span class="line">&gt;  :email:  von198@gmail.com</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># !!!!caution: not from pyspark.mllib.linalg import Vectors</span><br><span class="line">from pyspark.ml.linalg import Vectors</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.tuning import CrossValidator, ParamGridBuilder</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def transData(data):</span><br><span class="line">    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<ol>
<li>Transform the dataset to DataFrame</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed = transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with Categorical Label and Variables</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Index labels, adding metadata to the label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&apos;label&apos;,</span><br><span class="line">                             outputCol=&apos;indexedLabel&apos;).fit(transformed)</span><br><span class="line">labelIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+------------+</span><br><span class="line">|            features| label|indexedLabel|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|         0.0|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|         0.0|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|         0.0|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|         0.0|</span><br><span class="line">+--------------------+------+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    # Automatically identify categorical features, and index them.</span><br><span class="line">    # Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line">    featureIndexer =VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                                  outputCol=&quot;indexedFeatures&quot;, \</span><br><span class="line">                                  maxCategories=4).fit(transformed)</span><br><span class="line">featureIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|            features| label|     indexedFeatures|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|medium|[7.8,0.88,0.0,2.6...|</span><br><span class="line">|[7.8,0.76,0.04,2....|medium|[7.8,0.76,0.04,2....|</span><br><span class="line">|[11.2,0.28,0.56,1...|medium|[11.2,0.28,0.56,1...|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|medium|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">+--------------------+------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Split the data to training and test data sets</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = transformed.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5)</span><br><span class="line">testData.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[4.6,0.52,0.15,2....|   low|</span><br><span class="line">|[4.7,0.6,0.17,2.3...|medium|</span><br><span class="line">|[5.0,1.02,0.04,1....|   low|</span><br><span class="line">|[5.0,1.04,0.24,1....|medium|</span><br><span class="line">|[5.1,0.585,0.0,1....|  high|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+--------------------+------+</span><br><span class="line">|            features| label|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|[4.9,0.42,0.0,2.1...|  high|</span><br><span class="line">|[5.0,0.38,0.01,1....|medium|</span><br><span class="line">|[5.0,0.4,0.5,4.3,...|medium|</span><br><span class="line">|[5.0,0.42,0.24,2....|  high|</span><br><span class="line">|[5.0,0.74,0.0,1.2...|medium|</span><br><span class="line">+--------------------+------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Fit Random Forest Classification Model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import RandomForestClassifier</span><br><span class="line"></span><br><span class="line"># Train a RandomForest model.</span><br><span class="line">rf = RandomForestClassifier(labelCol=&quot;indexedLabel&quot;, featuresCol=&quot;indexedFeatures&quot;, numTrees=10)</span><br></pre></td></tr></table></figure>

<ol>
<li>Pipeline Architecture</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Convert indexed labels back to original labels.</span><br><span class="line">labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexers and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf,labelConverter])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Train model.  This also runs the indexers.</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<ol>
<li>Make predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------+--------------+</span><br><span class="line">|            features| label|predictedLabel|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">|[4.9,0.42,0.0,2.1...|  high|          high|</span><br><span class="line">|[5.0,0.38,0.01,1....|medium|        medium|</span><br><span class="line">|[5.0,0.4,0.5,4.3,...|medium|        medium|</span><br><span class="line">|[5.0,0.42,0.24,2....|  high|        medium|</span><br><span class="line">|[5.0,0.74,0.0,1.2...|medium|        medium|</span><br><span class="line">+--------------------+------+--------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Evaluation</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %g&quot; % (1.0 - accuracy))</span><br><span class="line"></span><br><span class="line">rfModel = model.stages[-2]</span><br><span class="line">print(rfModel)  # summary only</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.173502</span><br><span class="line">RandomForestClassificationModel (uid=rfc_a3395531f1d2) with 10 trees</span><br></pre></td></tr></table></figure>

<ol>
<li>visualization</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">def plot_confusion_matrix(cm, classes,</span><br><span class="line">                          normalize=False,</span><br><span class="line">                          title=&apos;Confusion matrix&apos;,</span><br><span class="line">                          cmap=plt.cm.Blues):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    This function prints and plots the confusion matrix.</span><br><span class="line">    Normalization can be applied by setting `normalize=True`.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if normalize:</span><br><span class="line">        cm = cm.astype(&apos;float&apos;) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line">        print(&quot;Normalized confusion matrix&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line"></span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.imshow(cm, interpolation=&apos;nearest&apos;, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=45)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    fmt = &apos;.2f&apos; if normalize else &apos;d&apos;</span><br><span class="line">    thresh = cm.max() / 2.</span><br><span class="line">    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):</span><br><span class="line">        plt.text(j, i, format(cm[i, j], fmt),</span><br><span class="line">                 horizontalalignment=&quot;center&quot;,</span><br><span class="line">                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(&apos;True label&apos;)</span><br><span class="line">    plt.xlabel(&apos;Predicted label&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class_temp = predictions.select(&quot;label&quot;).groupBy(&quot;label&quot;)\</span><br><span class="line">                        .count().sort(&apos;count&apos;, ascending=False).toPandas()</span><br><span class="line">class_temp = class_temp[&quot;label&quot;].values.tolist()</span><br><span class="line">class_names = map(str, class_temp)</span><br><span class="line"># # # print(class_name)</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;medium&apos;, &apos;high&apos;, &apos;low&apos;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = predictions.select(&quot;label&quot;)</span><br><span class="line">y_true = y_true.toPandas()</span><br><span class="line"></span><br><span class="line">y_pred = predictions.select(&quot;predictedLabel&quot;)</span><br><span class="line">y_pred = y_pred.toPandas()</span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)</span><br><span class="line">cnf_matrix</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[502,   9,   0],</span><br><span class="line">       [ 73,  22,   0],</span><br><span class="line">       [ 28,   0,   0]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Plot non-normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names,</span><br><span class="line">                      title=&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Confusion matrix, without normalization</span><br><span class="line">[[502   9   0]</span><br><span class="line"> [ 73  22   0]</span><br><span class="line"> [ 28   0   0]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/3c62f7e72a479ae0b82768c51bdc2830.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/rf_cm_c3.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Plot normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span><br><span class="line">                      title=&apos;Normalized confusion matrix&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Normalized confusion matrix</span><br><span class="line">[[ 0.98238748  0.01761252  0\.        ]</span><br><span class="line"> [ 0.76842105  0.23157895  0\.        ]</span><br><span class="line"> [ 1\.          0\.          0\.        ]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/3c62f7e72a479ae0b82768c51bdc2830.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/rf_cm_c3.png"></p>
<h2 id="10-5-Gradient-boosted-tree-Classification"><a href="#10-5-Gradient-boosted-tree-Classification" class="headerlink" title="10.5. Gradient-boosted tree Classification"></a>10.5. Gradient-boosted tree Classification</h2><h3 id="10-5-1-Introduction"><a href="#10-5-1-Introduction" class="headerlink" title="10.5.1. Introduction"></a>10.5.1. Introduction</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/GM3CDQfQ4sw" frameborder="0" allowfullscreen></iframe>

<h3 id="10-5-2-Demo"><a href="#10-5-2-Demo" class="headerlink" title="10.5.2. Demo"></a>10.5.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/gbtC3.ipynb">Gradient boosted tree Classification</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.GBTClassifier.html" target="_blank" rel="noopener">GBTClassifier API</a> .</li>
</ul>
<p>Warning</p>
<p>Unfortunately, the GBTClassifier currently only supports binary labels.</p>
<h2 id="10-6-XGBoost-Gradient-boosted-tree-Classification"><a href="#10-6-XGBoost-Gradient-boosted-tree-Classification" class="headerlink" title="10.6. XGBoost: Gradient-boosted tree Classification"></a>10.6. XGBoost: Gradient-boosted tree Classification</h2><h3 id="10-6-1-Introduction"><a href="#10-6-1-Introduction" class="headerlink" title="10.6.1. Introduction"></a>10.6.1. Introduction</h3><h3 id="10-6-2-Demo"><a href="#10-6-2-Demo" class="headerlink" title="10.6.2. Demo"></a>10.6.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/gbtC3.ipynb">Gradient boosted tree Classification</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.GBTClassifier.html" target="_blank" rel="noopener">GBTClassifier API</a> .</li>
</ul>
<p>Warning</p>
<p>Unfortunately, I didn’t find a good way to setup the XGBoost directly in Spark. But I do get the XGBoost work with <code>pysparkling</code> on my machine.</p>
<ol>
<li>Start H2O cluster inside the Spark environment</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pysparkling import *</span><br><span class="line">hc = H2OContext.getOrCreate(spark)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Connecting to H2O server at http://192.168.0.102:54323... successful.</span><br><span class="line">H2O cluster uptime:     07 secs</span><br><span class="line">H2O cluster timezone:   America/Chicago</span><br><span class="line">H2O data parsing timezone:      UTC</span><br><span class="line">H2O cluster version:    3.22.1.3</span><br><span class="line">H2O cluster version age:        20 days</span><br><span class="line">H2O cluster name:       sparkling-water-dt216661_local-1550259209801</span><br><span class="line">H2O cluster total nodes:        1</span><br><span class="line">H2O cluster free memory:        848 Mb</span><br><span class="line">H2O cluster total cores:        8</span><br><span class="line">H2O cluster allowed cores:      8</span><br><span class="line">H2O cluster status:     accepting new members, healthy</span><br><span class="line">H2O connection url:     http://192.168.0.102:54323</span><br><span class="line">H2O connection proxy:   None</span><br><span class="line">H2O internal security:  False</span><br><span class="line">H2O API Extensions:     XGBoost, Algos, AutoML, Core V3, Core V4</span><br><span class="line">Python version: 3.7.1 final</span><br><span class="line"></span><br><span class="line">Sparkling Water Context:</span><br><span class="line"> * H2O name: sparkling-water-dt216661_local-1550259209801</span><br><span class="line"> * cluster size: 1</span><br><span class="line"> * list of used nodes:</span><br><span class="line">  (executorId, host, port)</span><br><span class="line">  ------------------------</span><br><span class="line">  (driver,192.168.0.102,54323)</span><br><span class="line">  ------------------------</span><br><span class="line"></span><br><span class="line">  Open H2O Flow in browser: http://192.168.0.102:54323 (CMD + click in Mac OSX)</span><br></pre></td></tr></table></figure>

<ol>
<li>Parse the data using H2O and convert them to Spark Frame</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import h2o</span><br><span class="line">frame = h2o.import_file(&quot;https://raw.githubusercontent.com/h2oai/sparkling-water/master/examples/smalldata/prostate/prostate.csv&quot;)</span><br><span class="line">spark_frame = hc.as_spark_frame(frame)</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/aed7e56b0a3e63a84e53c79df4f79b0e.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/sparling_process.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark_frame.show(4)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+---+-------+---+----+-----+-----+----+----+-------+</span><br><span class="line">| ID|CAPSULE|AGE|RACE|DPROS|DCAPS| PSA| VOL|GLEASON|</span><br><span class="line">+---+-------+---+----+-----+-----+----+----+-------+</span><br><span class="line">|  1|      0| 65|   1|    2|    1| 1.4| 0.0|      6|</span><br><span class="line">|  2|      0| 72|   1|    3|    2| 6.7| 0.0|      7|</span><br><span class="line">|  3|      0| 70|   1|    1|    2| 4.9| 0.0|      6|</span><br><span class="line">|  4|      0| 76|   2|    2|    1|51.2|20.0|      7|</span><br><span class="line">+---+-------+---+----+-----+-----+----+----+-------+</span><br><span class="line">only showing top 4 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Train the model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from pysparkling.ml import H2OXGBoost</span><br><span class="line">estimator = H2OXGBoost(predictionCol=&quot;AGE&quot;)</span><br><span class="line">model = estimator.fit(spark_frame)</span><br></pre></td></tr></table></figure>

<ol>
<li>Run Predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.transform(spark_frame)</span><br><span class="line">predictions.show(4)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+---+-------+---+----+-----+-----+----+----+-------+-------------------+</span><br><span class="line">| ID|CAPSULE|AGE|RACE|DPROS|DCAPS| PSA| VOL|GLEASON|  prediction_output|</span><br><span class="line">+---+-------+---+----+-----+-----+----+----+-------+-------------------+</span><br><span class="line">|  1|      0| 65|   1|    2|    1| 1.4| 0.0|      6|[64.85852813720703]|</span><br><span class="line">|  2|      0| 72|   1|    3|    2| 6.7| 0.0|      7| [72.0611801147461]|</span><br><span class="line">|  3|      0| 70|   1|    1|    2| 4.9| 0.0|      6|[70.26496887207031]|</span><br><span class="line">|  4|      0| 76|   2|    2|    1|51.2|20.0|      7|[75.26521301269531]|</span><br><span class="line">+---+-------+---+----+-----+-----+----+----+-------+-------------------+</span><br><span class="line">only showing top 4 rows</span><br></pre></td></tr></table></figure>

<h2 id="10-7-Naive-Bayes-Classification"><a href="#10-7-Naive-Bayes-Classification" class="headerlink" title="10.7. Naive Bayes Classification"></a>10.7. Naive Bayes Classification</h2><h3 id="10-7-1-Introduction"><a href="#10-7-1-Introduction" class="headerlink" title="10.7.1. Introduction"></a>10.7.1. Introduction</h3><h3 id="10-7-2-Demo"><a href="#10-7-2-Demo" class="headerlink" title="10.7.2. Demo"></a>10.7.2. Demo</h3><ul>
<li>The Jupyter notebook can be download from <a href="_static/NaiveBayes.ipynb">Naive Bayes Classification</a>.</li>
<li>For more details, please visit <a href="http://takwatanabe.me/pyspark/generated/generated/ml.classification.NaiveBayes.html" target="_blank" rel="noopener">NaiveBayes API</a> .</li>
</ul>
<ol>
<li>Set up spark context and SparkSession</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;Python Spark  Naive Bayes classification&quot;) \</span><br><span class="line">    .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;) \</span><br><span class="line">    .getOrCreate()</span><br></pre></td></tr></table></figure>

<ol>
<li>Load dataset</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.format(&apos;com.databricks.spark.csv&apos;) \</span><br><span class="line">            .options(header=&apos;true&apos;, inferschema=&apos;true&apos;) \</span><br><span class="line">            .load(&quot;./data/WineData2.csv&quot;,header=True);</span><br><span class="line">df.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8|      5|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8|      5|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8|      6|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4|      5|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Convert to float format</span><br><span class="line">def string_to_float(x):</span><br><span class="line">    return float(x)</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">def condition(r):</span><br><span class="line">    if (0&lt;= r &lt;= 6):</span><br><span class="line">        label = &quot;low&quot;</span><br><span class="line">    else:</span><br><span class="line">        label = &quot;high&quot;</span><br><span class="line">    return label</span><br><span class="line"></span><br><span class="line">from pyspark.sql.functions import udf</span><br><span class="line">from pyspark.sql.types import StringType, DoubleType</span><br><span class="line">string_to_float_udf = udf(string_to_float, DoubleType())</span><br><span class="line">quality_udf = udf(lambda x: condition(x), StringType())</span><br><span class="line"></span><br><span class="line">df = df.withColumn(&quot;quality&quot;, quality_udf(&quot;quality&quot;))</span><br><span class="line"></span><br><span class="line">df.show(5,True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|fixed|volatile|citric|sugar|chlorides|free|total|density|  pH|sulphates|alcohol|quality|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">|  7.8|    0.88|   0.0|  2.6|    0.098|25.0| 67.0| 0.9968| 3.2|     0.68|    9.8| medium|</span><br><span class="line">|  7.8|    0.76|  0.04|  2.3|    0.092|15.0| 54.0|  0.997|3.26|     0.65|    9.8| medium|</span><br><span class="line">| 11.2|    0.28|  0.56|  1.9|    0.075|17.0| 60.0|  0.998|3.16|     0.58|    9.8| medium|</span><br><span class="line">|  7.4|     0.7|   0.0|  1.9|    0.076|11.0| 34.0| 0.9978|3.51|     0.56|    9.4| medium|</span><br><span class="line">+-----+--------+------+-----+---------+----+-----+-------+----+---------+-------+-------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- fixed: double (nullable = true)</span><br><span class="line"> |-- volatile: double (nullable = true)</span><br><span class="line"> |-- citric: double (nullable = true)</span><br><span class="line"> |-- sugar: double (nullable = true)</span><br><span class="line"> |-- chlorides: double (nullable = true)</span><br><span class="line"> |-- free: double (nullable = true)</span><br><span class="line"> |-- total: double (nullable = true)</span><br><span class="line"> |-- density: double (nullable = true)</span><br><span class="line"> |-- pH: double (nullable = true)</span><br><span class="line"> |-- sulphates: double (nullable = true)</span><br><span class="line"> |-- alcohol: double (nullable = true)</span><br><span class="line"> |-- quality: string (nullable = true)</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with categorical data and Convert the data to dense vector</li>
</ol>
<p>Note</p>
<p>You are strongly encouraged to try my <code>get_dummy</code> function for dealing with the categorical data in complex dataset.</p>
<p>Supervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):</span><br><span class="line">&gt; </span><br><span class="line">&gt;  from pyspark.ml import Pipeline</span><br><span class="line">&gt;  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">&gt;  from pyspark.sql.functions import col</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;,&apos;label&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>Unsupervised learning version:</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; def get_dummy(df,indexCol,categoricalCols,continuousCols):</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt;  Get dummy variables and concat with continuous variables for unsupervised learning.</span><br><span class="line">&gt;  :param df: the dataframe</span><br><span class="line">&gt;  :param categoricalCols: the name list of the categorical data</span><br><span class="line">&gt;  :param continuousCols:  the name list of the numerical data</span><br><span class="line">&gt;  :return k: feature matrix</span><br><span class="line">&gt; </span><br><span class="line">&gt;  :author: Wenqiang Feng</span><br><span class="line">&gt;  :email:  von198@gmail.com</span><br><span class="line">&gt;  &apos;&apos;&apos;</span><br><span class="line">&gt; </span><br><span class="line">&gt;  indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">&gt;               for c in categoricalCols ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  # default setting: dropLast=True</span><br><span class="line">&gt;  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">&gt;               outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">&gt;               for indexer in indexers ]</span><br><span class="line">&gt; </span><br><span class="line">&gt;  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">&gt;                                 + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line">&gt; </span><br><span class="line">&gt;     model=pipeline.fit(df)</span><br><span class="line">&gt;     data = model.transform(df)</span><br><span class="line">&gt; </span><br><span class="line">&gt;     return data.select(indexCol,&apos;features&apos;)</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def get_dummy(df,categoricalCols,continuousCols,labelCol):</span><br><span class="line"></span><br><span class="line">    from pyspark.ml import Pipeline</span><br><span class="line">    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler</span><br><span class="line">    from pyspark.sql.functions import col</span><br><span class="line"></span><br><span class="line">    indexers = [ StringIndexer(inputCol=c, outputCol=&quot;&#123;0&#125;_indexed&quot;.format(c))</span><br><span class="line">                 for c in categoricalCols ]</span><br><span class="line"></span><br><span class="line">    # default setting: dropLast=True</span><br><span class="line">    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),</span><br><span class="line">                 outputCol=&quot;&#123;0&#125;_encoded&quot;.format(indexer.getOutputCol()))</span><br><span class="line">                 for indexer in indexers ]</span><br><span class="line"></span><br><span class="line">    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]</span><br><span class="line">                                + continuousCols, outputCol=&quot;features&quot;)</span><br><span class="line"></span><br><span class="line">    pipeline = Pipeline(stages=indexers + encoders + [assembler])</span><br><span class="line"></span><br><span class="line">    model=pipeline.fit(df)</span><br><span class="line">    data = model.transform(df)</span><br><span class="line"></span><br><span class="line">    data = data.withColumn(&apos;label&apos;,col(labelCol))</span><br><span class="line"></span><br><span class="line">    return data.select(&apos;features&apos;,&apos;label&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Transform the dataset to DataFrame</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.linalg import Vectors # !!!!caution: not from pyspark.mllib.linalg import Vectors</span><br><span class="line">from pyspark.ml import Pipeline</span><br><span class="line">from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer</span><br><span class="line">from pyspark.ml.tuning import CrossValidator, ParamGridBuilder</span><br><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line">def transData(data):</span><br><span class="line">return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF([&apos;features&apos;,&apos;label&apos;])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transformed = transData(df)</span><br><span class="line">transformed.show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+</span><br><span class="line">|            features|label|</span><br><span class="line">+--------------------+-----+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|  low|</span><br><span class="line">|[7.8,0.76,0.04,2....|  low|</span><br><span class="line">|[11.2,0.28,0.56,1...|  low|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|</span><br><span class="line">+--------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Deal with Categorical Label and Variables</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Index labels, adding metadata to the label column</span><br><span class="line">labelIndexer = StringIndexer(inputCol=&apos;label&apos;,</span><br><span class="line">                             outputCol=&apos;indexedLabel&apos;).fit(transformed)</span><br><span class="line">labelIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+------------+</span><br><span class="line">|            features|label|indexedLabel|</span><br><span class="line">+--------------------+-----+------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|         0.0|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|  low|         0.0|</span><br><span class="line">|[7.8,0.76,0.04,2....|  low|         0.0|</span><br><span class="line">|[11.2,0.28,0.56,1...|  low|         0.0|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|         0.0|</span><br><span class="line">+--------------------+-----+------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Automatically identify categorical features, and index them.</span><br><span class="line"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span><br><span class="line">featureIndexer =VectorIndexer(inputCol=&quot;features&quot;, \</span><br><span class="line">                              outputCol=&quot;indexedFeatures&quot;, \</span><br><span class="line">                              maxCategories=4).fit(transformed)</span><br><span class="line">featureIndexer.transform(transformed).show(5, True)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">|            features|label|     indexedFeatures|</span><br><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">|[7.8,0.88,0.0,2.6...|  low|[7.8,0.88,0.0,2.6...|</span><br><span class="line">|[7.8,0.76,0.04,2....|  low|[7.8,0.76,0.04,2....|</span><br><span class="line">|[11.2,0.28,0.56,1...|  low|[11.2,0.28,0.56,1...|</span><br><span class="line">|[7.4,0.7,0.0,1.9,...|  low|[7.4,0.7,0.0,1.9,...|</span><br><span class="line">+--------------------+-----+--------------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Split the data to training and test data sets</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Split the data into training and test sets (40% held out for testing)</span><br><span class="line">(trainingData, testData) = data.randomSplit([0.6, 0.4])</span><br><span class="line"></span><br><span class="line">trainingData.show(5,False)</span><br><span class="line">testData.show(5,False)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">|features                                                 |label|</span><br><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">|[5.0,0.38,0.01,1.6,0.048,26.0,60.0,0.99084,3.7,0.75,14.0]|low  |</span><br><span class="line">|[5.0,0.42,0.24,2.0,0.06,19.0,50.0,0.9917,3.72,0.74,14.0] |high |</span><br><span class="line">|[5.0,0.74,0.0,1.2,0.041,16.0,46.0,0.99258,4.01,0.59,12.5]|low  |</span><br><span class="line">|[5.0,1.02,0.04,1.4,0.045,41.0,85.0,0.9938,3.75,0.48,10.5]|low  |</span><br><span class="line">|[5.0,1.04,0.24,1.6,0.05,32.0,96.0,0.9934,3.74,0.62,11.5] |low  |</span><br><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">|features                                                 |label|</span><br><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">|[4.6,0.52,0.15,2.1,0.054,8.0,65.0,0.9934,3.9,0.56,13.1]  |low  |</span><br><span class="line">|[4.7,0.6,0.17,2.3,0.058,17.0,106.0,0.9932,3.85,0.6,12.9] |low  |</span><br><span class="line">|[4.9,0.42,0.0,2.1,0.048,16.0,42.0,0.99154,3.71,0.74,14.0]|high |</span><br><span class="line">|[5.0,0.4,0.5,4.3,0.046,29.0,80.0,0.9902,3.49,0.66,13.6]  |low  |</span><br><span class="line">|[5.2,0.49,0.26,2.3,0.09,23.0,74.0,0.9953,3.71,0.62,12.2] |low  |</span><br><span class="line">+---------------------------------------------------------+-----+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Fit Naive Bayes Classification Model</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import NaiveBayes</span><br><span class="line">nb = NaiveBayes(featuresCol=&apos;indexedFeatures&apos;, labelCol=&apos;indexedLabel&apos;)</span><br></pre></td></tr></table></figure>

<ol>
<li>Pipeline Architecture</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Convert indexed labels back to original labels.</span><br><span class="line">labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Chain indexers and tree in a Pipeline</span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, nb,labelConverter])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Train model.  This also runs the indexers.</span><br><span class="line">model = pipeline.fit(trainingData)</span><br></pre></td></tr></table></figure>

<ol>
<li>Make predictions</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Make predictions.</span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"># Select example rows to display.</span><br><span class="line">predictions.select(&quot;features&quot;,&quot;label&quot;,&quot;predictedLabel&quot;).show(5)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+-----+--------------+</span><br><span class="line">|            features|label|predictedLabel|</span><br><span class="line">+--------------------+-----+--------------+</span><br><span class="line">|[4.6,0.52,0.15,2....|  low|           low|</span><br><span class="line">|[4.7,0.6,0.17,2.3...|  low|           low|</span><br><span class="line">|[4.9,0.42,0.0,2.1...| high|           low|</span><br><span class="line">|[5.0,0.4,0.5,4.3,...|  low|           low|</span><br><span class="line">|[5.2,0.49,0.26,2....|  low|           low|</span><br><span class="line">+--------------------+-----+--------------+</span><br><span class="line">only showing top 5 rows</span><br></pre></td></tr></table></figure>

<ol>
<li>Evaluation</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><br><span class="line"></span><br><span class="line"># Select (prediction, true label) and compute test error</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=&quot;indexedLabel&quot;, predictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(&quot;Test Error = %g&quot; % (1.0 - accuracy))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test Error = 0.307339</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">lrModel = model.stages[2]</span><br><span class="line">trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line"># Obtain the objective per iteration</span><br><span class="line"># objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line"># print(&quot;objectiveHistory:&quot;)</span><br><span class="line"># for objective in objectiveHistory:</span><br><span class="line">#     print(objective)</span><br><span class="line"></span><br><span class="line"># Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.</span><br><span class="line">trainingSummary.roc.show(5)</span><br><span class="line">print(&quot;areaUnderROC: &quot; + str(trainingSummary.areaUnderROC))</span><br><span class="line"></span><br><span class="line"># Set the model threshold to maximize F-Measure</span><br><span class="line">fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">maxFMeasure = fMeasure.groupBy().max(&apos;F-Measure&apos;).select(&apos;max(F-Measure)&apos;).head(5)</span><br><span class="line"># bestThreshold = fMeasure.where(fMeasure[&apos;F-Measure&apos;] == maxFMeasure[&apos;max(F-Measure)&apos;]) \</span><br><span class="line">#     .select(&apos;threshold&apos;).head()[&apos;threshold&apos;]</span><br><span class="line"># lr.setThreshold(bestThreshold)</span><br></pre></td></tr></table></figure>

<p>You can use <code>z.show()</code> to get the data and plot the ROC curves:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/4ae661a05a9586c4ce7b5eabf4bab417.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc_z.png"></p>
<p>You can also register a TempTable <code>data.registerTempTable(&#39;roc_data&#39;)</code> and then use <code>sql</code> to plot the ROC curve:</p>
<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/b7d7ca35788d7bfb804b5b230a76af8c.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/roc.png"></p>
<ol>
<li>visualization</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">def plot_confusion_matrix(cm, classes,</span><br><span class="line">                          normalize=False,</span><br><span class="line">                          title=&apos;Confusion matrix&apos;,</span><br><span class="line">                          cmap=plt.cm.Blues):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    This function prints and plots the confusion matrix.</span><br><span class="line">    Normalization can be applied by setting `normalize=True`.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if normalize:</span><br><span class="line">        cm = cm.astype(&apos;float&apos;) / cm.sum(axis=1)[:, np.newaxis]</span><br><span class="line">        print(&quot;Normalized confusion matrix&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line"></span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    plt.imshow(cm, interpolation=&apos;nearest&apos;, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=45)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    fmt = &apos;.2f&apos; if normalize else &apos;d&apos;</span><br><span class="line">    thresh = cm.max() / 2.</span><br><span class="line">    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):</span><br><span class="line">        plt.text(j, i, format(cm[i, j], fmt),</span><br><span class="line">                 horizontalalignment=&quot;center&quot;,</span><br><span class="line">                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(&apos;True label&apos;)</span><br><span class="line">    plt.xlabel(&apos;Predicted label&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class_temp = predictions.select(&quot;label&quot;).groupBy(&quot;label&quot;)\</span><br><span class="line">                        .count().sort(&apos;count&apos;, ascending=False).toPandas()</span><br><span class="line">class_temp = class_temp[&quot;label&quot;].values.tolist()</span><br><span class="line">class_names = map(str, class_temp)</span><br><span class="line"># # # print(class_name)</span><br><span class="line">class_names</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;low&apos;, &apos;high&apos;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = predictions.select(&quot;label&quot;)</span><br><span class="line">y_true = y_true.toPandas()</span><br><span class="line"></span><br><span class="line">y_pred = predictions.select(&quot;predictedLabel&quot;)</span><br><span class="line">y_pred = y_pred.toPandas()</span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)</span><br><span class="line">cnf_matrix</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[392, 169],</span><br><span class="line">       [ 32,  61]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Plot non-normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names,</span><br><span class="line">                      title=&apos;Confusion matrix, without normalization&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Confusion matrix, without normalization</span><br><span class="line">[[392 169]</span><br><span class="line"> [ 32  61]]</span><br></pre></td></tr></table></figure>

<p><img src="G:/PYthonLearning/learning-pyspark-zh-master/docs/img/0e33aec96020afa0297be6d91db0d5d8.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/nb_c1.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Plot normalized confusion matrix</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span><br><span class="line">                      title=&apos;Normalized confusion matrix&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Normalized confusion matrix</span><br><span class="line">[[0.69875223 0.30124777]</span><br><span class="line"> [0.34408602 0.65591398]]</span><br></pre></td></tr></table></figure>

<p><img src="img/9b41f0fbb97ef7ddd6383753e6ad1c26.jpg" alt="https://runawayhorse001.github.io/LearningApacheSpark/_images/nb_c2.png"></p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/PySpark/" rel="tag"><i class="fa fa-tag"></i> PySpark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/04/11/天池-饿了么/" rel="next" title="天池-饿了么智慧物流">
                <i class="fa fa-chevron-left"></i> 天池-饿了么智慧物流
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/touxiang.jpg" alt="Shiwei-Yan">
  
  <p class="site-author-name" itemprop="name">Shiwei-Yan</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>







  <div class="links-of-author motion-element">
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/Yanin-dpdt" title="GitHub &rarr; https://github.com/Yanin-dpdt" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:Yanin-dpdt@foxmail.com" title="E-Mail &rarr; mailto:Yanin-dpdt@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>







          
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-前言"><span class="nav-number">1.</span> <span class="nav-text">1. 前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-为什么是-Spark-和-Python"><span class="nav-number">2.</span> <span class="nav-text">2. 为什么是 Spark 和 Python</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-为什么是-Spark"><span class="nav-number">2.1.</span> <span class="nav-text">2.1. 为什么是 Spark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-为什么是-PySpark"><span class="nav-number">2.2.</span> <span class="nav-text">2.2. 为什么是 PySpark?</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-配置运行平台"><span class="nav-number">3.</span> <span class="nav-text">3. 配置运行平台</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-在-Databricks-社区云上运行"><span class="nav-number">3.1.</span> <span class="nav-text">3.1. 在 Databricks 社区云上运行</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-在-Mac-和-Ubuntu-上配置-Spark"><span class="nav-number">3.2.</span> <span class="nav-text">3.2. 在 Mac 和 Ubuntu 上配置 Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-安装先决条件"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1. 安装先决条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-安装-Java"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2. 安装 Java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-安装-JRE"><span class="nav-number">3.2.3.</span> <span class="nav-text">3.2.3. 安装 JRE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-安装-Apache-Spark"><span class="nav-number">3.2.4.</span> <span class="nav-text">3.2.4. 安装 Apache Spark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-5-配置-Spark"><span class="nav-number">3.2.5.</span> <span class="nav-text">3.2.5. 配置 Spark</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-在-Windows-上配置-Spark"><span class="nav-number">3.3.</span> <span class="nav-text">3.3. 在 Windows 上配置 Spark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-PySpark-和文本编辑器或-IDE"><span class="nav-number">3.4.</span> <span class="nav-text">3.4. PySpark 和文本编辑器或 IDE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-1-PySpark-和-Jupyter-笔记本"><span class="nav-number">3.4.1.</span> <span class="nav-text">3.4.1. PySpark 和 Jupyter 笔记本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-2-PySpark-和-Apache-Zeppelin"><span class="nav-number">3.4.2.</span> <span class="nav-text">3.4.2. PySpark 和 Apache Zeppelin</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-3-PySpark-和-Sublime-Text"><span class="nav-number">3.4.3.</span> <span class="nav-text">3.4.3. PySpark 和 Sublime Text</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-4-PySpark-和-Eclipse"><span class="nav-number">3.4.4.</span> <span class="nav-text">3.4.4. PySpark 和 Eclipse</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-PySparkling-水-Spark-H2O"><span class="nav-number">3.5.</span> <span class="nav-text">3.5. PySparkling 水: Spark + H2O</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-6-在云上配置-Spark"><span class="nav-number">3.6.</span> <span class="nav-text">3.6. 在云上配置 Spark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-7-这一节的示例代码"><span class="nav-number">3.7.</span> <span class="nav-text">3.7. 这一节的示例代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Apache-Spark-入门"><span class="nav-number">4.</span> <span class="nav-text">4. Apache Spark 入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-核心概念"><span class="nav-number">4.1.</span> <span class="nav-text">4.1. 核心概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Spark-组件"><span class="nav-number">4.2.</span> <span class="nav-text">4.2. Spark 组件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-架构"><span class="nav-number">4.3.</span> <span class="nav-text">4.3. 架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-Spark-的工作原理"><span class="nav-number">4.4.</span> <span class="nav-text">4.4. Spark 的工作原理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-使用-RDD-的编程"><span class="nav-number">5.</span> <span class="nav-text">5. 使用 RDD 的编程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-创建-RDD"><span class="nav-number">5.1.</span> <span class="nav-text">5.1. 创建 RDD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Spark-操作"><span class="nav-number">5.2.</span> <span class="nav-text">5.2. Spark 操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-1-Spark-转换"><span class="nav-number">5.2.1.</span> <span class="nav-text">5.2.1. Spark 转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-2-Spark-动作"><span class="nav-number">5.2.2.</span> <span class="nav-text">5.2.2. Spark 动作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-rdd-DataFrame-VS-pd-DataFrame"><span class="nav-number">5.3.</span> <span class="nav-text">5.3. rdd.DataFrame VS pd.DataFrame</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-1-创建DataFrame"><span class="nav-number">5.3.1.</span> <span class="nav-text">5.3.1. 创建DataFrame</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-2-加载DataFrame"><span class="nav-number">5.3.2.</span> <span class="nav-text">5.3.2. 加载DataFrame</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-3-前n行"><span class="nav-number">5.3.3.</span> <span class="nav-text">5.3.3. 前n行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-4-列名"><span class="nav-number">5.3.4.</span> <span class="nav-text">5.3.4. 列名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-5-数据类型"><span class="nav-number">5.3.5.</span> <span class="nav-text">5.3.5. 数据类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-6-填充空值"><span class="nav-number">5.3.6.</span> <span class="nav-text">5.3.6. 填充空值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-7-替换值"><span class="nav-number">5.3.7.</span> <span class="nav-text">5.3.7. 替换值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-8-重命名列"><span class="nav-number">5.3.8.</span> <span class="nav-text">5.3.8. 重命名列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-9-丢弃列"><span class="nav-number">5.3.9.</span> <span class="nav-text">5.3.9. 丢弃列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-10-过滤"><span class="nav-number">5.3.10.</span> <span class="nav-text">5.3.10. 过滤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-11-添加新列"><span class="nav-number">5.3.11.</span> <span class="nav-text">5.3.11. 添加新列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-12-连接"><span class="nav-number">5.3.12.</span> <span class="nav-text">5.3.12. 连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-13-连接列"><span class="nav-number">5.3.13.</span> <span class="nav-text">5.3.13. 连接列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-14-分组"><span class="nav-number">5.3.14.</span> <span class="nav-text">5.3.14. 分组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-15-透视"><span class="nav-number">5.3.15.</span> <span class="nav-text">5.3.15. 透视</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-16-窗口"><span class="nav-number">5.3.16.</span> <span class="nav-text">5.3.16. 窗口</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-17-rank-VS-dense-rank"><span class="nav-number">5.3.17.</span> <span class="nav-text">5.3.17. rank VS dense_rank</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-统计与线性代数预备"><span class="nav-number">6.</span> <span class="nav-text">6. 统计与线性代数预备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-表示法"><span class="nav-number">6.1.</span> <span class="nav-text">6.1. 表示法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-线性代数预备"><span class="nav-number">6.2.</span> <span class="nav-text">6.2. 线性代数预备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-测量公式"><span class="nav-number">6.3.</span> <span class="nav-text">6.3. 测量公式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-1-平均绝对误差"><span class="nav-number">6.3.1.</span> <span class="nav-text">6.3.1. 平均绝对误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-2-均方误差"><span class="nav-number">6.3.2.</span> <span class="nav-text">6.3.2. 均方误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-3-均方根误差"><span class="nav-number">6.3.3.</span> <span class="nav-text">6.3.3. 均方根误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-4-总体平方和"><span class="nav-number">6.3.4.</span> <span class="nav-text">6.3.4. 总体平方和</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-5-解释平方和"><span class="nav-number">6.3.5.</span> <span class="nav-text">6.3.5. 解释平方和</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-6-残差平方和"><span class="nav-number">6.3.6.</span> <span class="nav-text">6.3.6. 残差平方和</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-7-判定系数"><span class="nav-number">6.3.7.</span> <span class="nav-text">6.3.7. 判定系数 </span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-混淆矩阵"><span class="nav-number">6.4.</span> <span class="nav-text">6.4. 混淆矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-1-召回率"><span class="nav-number">6.4.1.</span> <span class="nav-text">6.4.1. 召回率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-2-精确率"><span class="nav-number">6.4.2.</span> <span class="nav-text">6.4.2. 精确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-3-准确率"><span class="nav-number">6.4.3.</span> <span class="nav-text">6.4.3. 准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-4-F1-得分"><span class="nav-number">6.4.4.</span> <span class="nav-text">6.4.4. F1 得分</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-统计检验"><span class="nav-number">6.5.</span> <span class="nav-text">6.5. 统计检验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-1-互相关检验"><span class="nav-number">6.5.1.</span> <span class="nav-text">6.5.1. 互相关检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-2-均值检验的比较"><span class="nav-number">6.5.2.</span> <span class="nav-text">6.5.2. 均值检验的比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-3-非配对检验"><span class="nav-number">6.5.3.</span> <span class="nav-text">6.5.3. 非配对检验</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-数据探索"><span class="nav-number">7.</span> <span class="nav-text">7. 数据探索</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-单变量分析"><span class="nav-number">7.1.</span> <span class="nav-text">7.1. 单变量分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-1-数值变量"><span class="nav-number">7.1.1.</span> <span class="nav-text">7.1.1. 数值变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-2-类别变量"><span class="nav-number">7.1.2.</span> <span class="nav-text">7.1.2. 类别变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-多变量分析"><span class="nav-number">7.2.</span> <span class="nav-text">7.2. 多变量分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-1-数值-VS-数值"><span class="nav-number">7.2.1.</span> <span class="nav-text">7.2.1. 数值 VS 数值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-2-类别-VS-类别"><span class="nav-number">7.2.2.</span> <span class="nav-text">7.2.2. 类别 VS 类别</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-回归"><span class="nav-number">8.</span> <span class="nav-text">8. 回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-1-线性回归"><span class="nav-number">8.1.</span> <span class="nav-text">8.1. 线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-1-简介"><span class="nav-number">8.1.1.</span> <span class="nav-text">8.1.1. 简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-2-如何求解"><span class="nav-number">8.1.2.</span> <span class="nav-text">8.1.2. 如何求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-3-普通最小二乘"><span class="nav-number">8.1.3.</span> <span class="nav-text">8.1.3. 普通最小二乘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-4-梯度下降"><span class="nav-number">8.1.4.</span> <span class="nav-text">8.1.4. 梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-5-损失函数"><span class="nav-number">8.1.5.</span> <span class="nav-text">8.1.5. 损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-6-批量梯度下降"><span class="nav-number">8.1.6.</span> <span class="nav-text">8.1.6. 批量梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-7-随机梯度下降"><span class="nav-number">8.1.7.</span> <span class="nav-text">8.1.7. 随机梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-8-小批量梯度下降"><span class="nav-number">8.1.8.</span> <span class="nav-text">8.1.8. 小批量梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-9-示例"><span class="nav-number">8.1.9.</span> <span class="nav-text">8.1.9. 示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-2-广义线性回归"><span class="nav-number">8.2.</span> <span class="nav-text">8.2. 广义线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-1-介绍"><span class="nav-number">8.2.1.</span> <span class="nav-text">8.2.1. 介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-2-如何求解"><span class="nav-number">8.2.2.</span> <span class="nav-text">8.2.2. 如何求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-3-示例"><span class="nav-number">8.2.3.</span> <span class="nav-text">8.2.3. 示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-3-决策树回归"><span class="nav-number">8.3.</span> <span class="nav-text">8.3. 决策树回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-1-介绍"><span class="nav-number">8.3.1.</span> <span class="nav-text">8.3.1. 介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-2-如何求解"><span class="nav-number">8.3.2.</span> <span class="nav-text">8.3.2. 如何求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-3-示例"><span class="nav-number">8.3.3.</span> <span class="nav-text">8.3.3. 示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-4-随机森林回归"><span class="nav-number">8.4.</span> <span class="nav-text">8.4. 随机森林回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-1-简介"><span class="nav-number">8.4.1.</span> <span class="nav-text">8.4.1. 简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-2-如何求解"><span class="nav-number">8.4.2.</span> <span class="nav-text">8.4.2. 如何求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-3-示例"><span class="nav-number">8.4.3.</span> <span class="nav-text">8.4.3. 示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-5-梯度提升树回归"><span class="nav-number">8.5.</span> <span class="nav-text">8.5. 梯度提升树回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-1-简介"><span class="nav-number">8.5.1.</span> <span class="nav-text">8.5.1. 简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-2-如何求解"><span class="nav-number">8.5.2.</span> <span class="nav-text">8.5.2. 如何求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-3-示例"><span class="nav-number">8.5.3.</span> <span class="nav-text">8.5.3. 示例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-Classification"><span class="nav-number">9.</span> <span class="nav-text">10. Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#10-1-Binomial-logistic-regression"><span class="nav-number">9.1.</span> <span class="nav-text">10.1. Binomial logistic regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-1-Introduction"><span class="nav-number">9.1.1.</span> <span class="nav-text">10.1.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-2-Demo"><span class="nav-number">9.1.2.</span> <span class="nav-text">10.1.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-2-Multinomial-logistic-regression"><span class="nav-number">9.2.</span> <span class="nav-text">10.2. Multinomial logistic regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-1-Introduction"><span class="nav-number">9.2.1.</span> <span class="nav-text">10.2.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-2-Demo"><span class="nav-number">9.2.2.</span> <span class="nav-text">10.2.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-3-Decision-tree-Classification"><span class="nav-number">9.3.</span> <span class="nav-text">10.3. Decision tree Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-1-Introduction"><span class="nav-number">9.3.1.</span> <span class="nav-text">10.3.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-2-Demo"><span class="nav-number">9.3.2.</span> <span class="nav-text">10.3.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-4-Random-forest-Classification"><span class="nav-number">9.4.</span> <span class="nav-text">10.4. Random forest Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-1-Introduction"><span class="nav-number">9.4.1.</span> <span class="nav-text">10.4.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-2-Demo"><span class="nav-number">9.4.2.</span> <span class="nav-text">10.4.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-5-Gradient-boosted-tree-Classification"><span class="nav-number">9.5.</span> <span class="nav-text">10.5. Gradient-boosted tree Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-5-1-Introduction"><span class="nav-number">9.5.1.</span> <span class="nav-text">10.5.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-5-2-Demo"><span class="nav-number">9.5.2.</span> <span class="nav-text">10.5.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-6-XGBoost-Gradient-boosted-tree-Classification"><span class="nav-number">9.6.</span> <span class="nav-text">10.6. XGBoost: Gradient-boosted tree Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-6-1-Introduction"><span class="nav-number">9.6.1.</span> <span class="nav-text">10.6.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-6-2-Demo"><span class="nav-number">9.6.2.</span> <span class="nav-text">10.6.2. Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-7-Naive-Bayes-Classification"><span class="nav-number">9.7.</span> <span class="nav-text">10.7. Naive Bayes Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-7-1-Introduction"><span class="nav-number">9.7.1.</span> <span class="nav-text">10.7.1. Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-7-2-Demo"><span class="nav-number">9.7.2.</span> <span class="nav-text">10.7.2. Demo</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shiwei-Yan</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">507k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">7:41</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.2.0</div>




<div class="powered-by">
  <i class="fa fa-user-md"></i>
  <span id="busuanzi_container_site_uv">
    本站总访客数:<span id="busuanzi_value_site_uv"></span>&nbsp;&nbsp;| 
  </span>
  <span id="busuanzi_container_site_pv">
      &nbsp;本站总访问量<span id="busuanzi_value_site_pv"></span>次
  </span>
  </div>
  </div>



<script>
      var now = new Date(); 
      function createtime() { 
          var grt= new Date("07/23/2019 12:00:00");//此处修改你的建站时间或者网站上线时间 
          now.setTime(now.getTime()+250); 
          days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
          hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
          if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
          mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
          seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
          snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
          document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
          document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
      } 
  setInterval("createtime()",250);
  </script>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </footer></div>
    

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
















  
  



  
    
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>







  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  
  

  
  

  











  








  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>














<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>








  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
